{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9051529",
   "metadata": {
    "papermill": {
     "duration": 0.007333,
     "end_time": "2025-11-10T16:43:49.944371",
     "exception": false,
     "start_time": "2025-11-10T16:43:49.937038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project Overview\n",
    "\n",
    "This project focuses on **text summarization** using two approaches: a traditional **Seq2Seq model** with LSTM and a **Transformer-based model**. The goal is to see how each model performs and understand the difference between step-by-step sequence processing and attention-based processing.\n",
    "\n",
    "### Steps in the Project\n",
    "1. **Dataset Preparation**  \n",
    "   - Load the XSum dataset with articles and summaries.  \n",
    "   - Tokenize and pad sequences so they can be fed into the models.\n",
    "\n",
    "2. **Seq2Seq Model (LSTM)**  \n",
    "   - Build an encoder-decoder model without attention.\n",
    "   - Train it to generate summaries from the input articles.  \n",
    "\n",
    "3. **Transformer Model**  \n",
    "   - Build a Transformer-based encoder-decoder model.  \n",
    "   - Use self-attention to capture relationships between all tokens.  \n",
    "   - Train on the same dataset to generate summaries.\n",
    "\n",
    "4. **Comparison**  \n",
    "   - Compare the two models using metrics like ROUGE.  \n",
    "   - Look at differences in summary quality, speed, and how well they handle long sequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5b3a5",
   "metadata": {
    "papermill": {
     "duration": 0.005612,
     "end_time": "2025-11-10T16:43:49.956062",
     "exception": false,
     "start_time": "2025-11-10T16:43:49.950450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seq2Seq and Encoder-Decoder\n",
    "\n",
    "## What is a Seq2Seq Model\n",
    "A sequence-to-sequence (Seq2Seq) model is designed to take an input sequence and produce an output sequence. It’s widely used in tasks like machine translation, text summarization, and chatbots.\n",
    "\n",
    "**Example:**  \n",
    "Input: \"Hello, how are you?\"  \n",
    "Output: \"Ciao, come stai?\"\n",
    "\n",
    "---\n",
    "\n",
    "## Encoder-Decoder Architecture (Expanded)\n",
    "\n",
    "A typical Seq2Seq model has two main parts: the **encoder** and the **decoder**. The design allows the model to process sequences of variable length.  \n",
    "\n",
    "### Encoder\n",
    "The encoder reads the input sequence and compresses it into a set of hidden states or a context vector. This vector captures the important information from the input and has a fixed size, though it does not need to match the decoder's size. The hidden states can either be passed as a whole to the decoder or connected at every decoding step.  \n",
    "\n",
    "At each step, the encoder updates its hidden state based on the previous hidden state and the current input. In mathematical terms, for a simple RNN:\n",
    "\n",
    "$$\n",
    "H_t^{encoder} = \\phi(W_{HH} \\cdot H_{t-1}^{encoder} + W_{HX} \\cdot X_t)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $H_t^{encoder}$ = hidden state at time $t$ in the encoder  \n",
    "- $X_t$ = input at time $t$  \n",
    "- $W_{HH}$ = weight matrix connecting hidden states  \n",
    "- $W_{HX}$ = weight matrix connecting input to hidden states  \n",
    "- $\\phi$ = activation function (e.g., tanh or ReLU)\n",
    "\n",
    "---\n",
    "\n",
    "### Decoder\n",
    "The decoder generates the output sequence one token at a time. Its initial hidden state is set to the final hidden state of the encoder. For a simple RNN decoder:\n",
    "\n",
    "$$\n",
    "H_t^{decoder} = \\phi(W_{HH} \\cdot H_{t-1}^{decoder} + W_{HY} \\cdot Y_{t-1})\n",
    "$$\n",
    "\n",
    "The output at each step is computed as:\n",
    "\n",
    "$$\n",
    "Y_t = W_{HY} \\cdot H_t^{decoder}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $H_t^{decoder}$ = hidden state at time $t$ in the decoder  \n",
    "- $Y_t$ = output at time $t$  \n",
    "- $W_{HY}$ = weight matrix connecting decoder hidden state to output  \n",
    "\n",
    "### Implementation Notes\n",
    "- Encoders and decoders are typically implemented with **RNNs, LSTMs, or GRUs**.  \n",
    "- The input and output vectors are of fixed size, but the encoder and decoder can have different hidden dimensions.  \n",
    "- During training, **teacher forcing** is often used, providing the correct previous token to the decoder instead of its own prediction.  \n",
    "\n",
    "---\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "Before feeding text into a Seq2Seq or Transformer model, the raw text must be converted into numerical form.  \n",
    "This is done through **tokenization**, which splits text into smaller units (tokens) such as words or subwords.  \n",
    "\n",
    "Each token is then mapped to a unique integer using a **vocabulary** built from the dataset.  \n",
    "The model processes these integers rather than the raw text.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Input text: `\"Transformers improve summarization.\"`  \n",
    "Tokens: `[\"transformers\", \"improve\", \"summarization\", \".\"]`  \n",
    "Token IDs: `[201, 57, 1342, 4]`\n",
    "\n",
    "### Why Tokenization Matters\n",
    "- Converts variable-length text into consistent, model-readable sequences.  \n",
    "- Helps capture word frequency and context relationships.  \n",
    "- Reduces vocabulary size when using subword tokenization (e.g., Byte Pair Encoding).  \n",
    "\n",
    "In this project, tokenization is part of preprocessing and includes:\n",
    "- **Lowercasing** the text  \n",
    "- **Removing special characters and URLs**  \n",
    "- **Splitting into tokens by spaces**  \n",
    "- Adding **start (`sostok`)** and **end (`eostok`)** tokens to mark summary boundaries  \n",
    "\n",
    "After tokenization, sequences will later be converted to integer IDs, padded or truncated to a fixed length\n",
    "\n",
    "---\n",
    "\n",
    "# Transformers\n",
    "Transformers can be seen as an evolution of Seq2Seq models. Instead of processing sequences step by step like LSTMs or GRUs, they rely entirely on **attention mechanisms** to process all tokens in parallel and capture relationships between them.\n",
    "\n",
    "### Attention in Transformers\n",
    "Attention is the core mechanism that allows Transformers to focus on relevant parts of the input sequence when producing a representation for each token. It works by comparing each token to all others and weighting them according to importance.\n",
    "\n",
    "#### How Attention Works\n",
    "Each token in the sequence is represented by three vectors:\n",
    "- **Query (Q):** what this token is looking for  \n",
    "- **Key (K):** what information this token contains  \n",
    "- **Value (V):** the actual information of the token  \n",
    "\n",
    "The attention score between two tokens is computed as the similarity between the Query of one token and the Key of another. This determines how much attention one token should pay to another. Mathematically, the attention weights are computed using a scaled dot-product:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\Big(\\frac{QK^T}{\\sqrt{d_k}}\\Big) V\n",
    "$$\n",
    "\n",
    "Where $d_k$ is the dimensionality of the Key vectors.\n",
    "\n",
    "- The **softmax** ensures that the weights sum to 1.  \n",
    "- Each token’s output is a weighted sum of all Value vectors, allowing it to incorporate context from the entire sequence.\n",
    "\n",
    "#### Multi-Head Attention\n",
    "Instead of computing attention just once, Transformers use **multiple attention heads** in parallel. Each head can learn to focus on different types of relationships, such as:\n",
    "- Syntactic relationships (e.g., subject-verb connections)  \n",
    "- Semantic relationships (e.g., synonyms or related concepts)  \n",
    "\n",
    "The outputs of all heads are concatenated and projected to form the final representation for each token.\n",
    "\n",
    "#### Intuition\n",
    "Imagine reading a sentence and highlighting all the words that are important for understanding each token. Each word “attends” to other words in the sentence that matter most for its meaning. Multi-head attention lets the model do this from multiple perspectives simultaneously.\n",
    "\n",
    "### Key Components of Transformers\n",
    "- **Encoder-Decoder Structure:** Like Seq2Seq models, Transformers have an encoder that processes the input and a decoder that generates the output. Both use layers of self-attention and feed-forward networks.  \n",
    "- **Positional Encoding:** Since Transformers don’t process tokens sequentially, they add positional information so the model knows the order of tokens.  \n",
    "- **Feed-Forward Layers:** After attention, each token passes through fully connected layers for additional transformation.\n",
    "\n",
    "### Advantages over LSTM/GRU Seq2Seq\n",
    "- Processes sequences **in parallel**, speeding up training.  \n",
    "- Handles **long sequences** more effectively with attention.  \n",
    "- Captures **complex relationships** between tokens regardless of distance.  \n",
    "- Scales easily to **very deep models** and large datasets.\n",
    "\n",
    "### Use Cases\n",
    "Transformers are the backbone of many state-of-the-art models for tasks such as:\n",
    "- Machine translation (e.g., T5, MarianMT)  \n",
    "- Text summarization (e.g., BART, Pegasus)  \n",
    "- Question answering and chatbots (e.g., GPT, BERT-based models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260b461e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:49.968752Z",
     "iopub.status.busy": "2025-11-10T16:43:49.968469Z",
     "iopub.status.idle": "2025-11-10T16:43:49.975843Z",
     "shell.execute_reply": "2025-11-10T16:43:49.975116Z"
    },
    "papermill": {
     "duration": 0.015226,
     "end_time": "2025-11-10T16:43:49.977078",
     "exception": false,
     "start_time": "2025-11-10T16:43:49.961852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2587ee",
   "metadata": {
    "papermill": {
     "duration": 0.005729,
     "end_time": "2025-11-10T16:43:49.989353",
     "exception": false,
     "start_time": "2025-11-10T16:43:49.983624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "Prepare and clean the dataset for the summarization model:\n",
    "\n",
    "- **Load datasets:** Read two CSV files containing news articles and their summaries.\n",
    "- **Combine datasets:** Merge datasets while selecting relevant `text` and `summary` columns.\n",
    "- **Text cleaning:**  \n",
    "  - Convert text to lowercase.  \n",
    "  - Remove special characters.  \n",
    "  - Replace URLs with domain names.  \n",
    "  - Reduce multiple spaces.\n",
    "- **Tokenization:** Split cleaned text into tokens (words) and add `_START_` and `_END_` tokens for summaries.\n",
    "- **Handle missing values:** Drop rows with missing `text` values.\n",
    "- **Analyze sequence lengths:** Calculate word counts for texts and summaries.\n",
    "- **Limit sequence lengths:** Restrict `text` to 100 words and `summary` to 15 words.\n",
    "- **Add model tokens:** Prepend `sostok` and append `eostok` to all summaries to mark start and end for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5acfde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:50.001900Z",
     "iopub.status.busy": "2025-11-10T16:43:50.001697Z",
     "iopub.status.idle": "2025-11-10T16:43:52.413672Z",
     "shell.execute_reply": "2025-11-10T16:43:52.412766Z"
    },
    "papermill": {
     "duration": 2.420248,
     "end_time": "2025-11-10T16:43:52.415374",
     "exception": false,
     "start_time": "2025-11-10T16:43:49.995126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4514, 6)\n",
      "(98401, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "summary = pd.read_csv('/kaggle/input/news-summary/news_summary.csv', encoding='iso-8859-1')\n",
    "summary_more = pd.read_csv('/kaggle/input/news-summary/news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "print(summary.shape)\n",
    "print(summary_more.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50dca1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:52.431927Z",
     "iopub.status.busy": "2025-11-10T16:43:52.431213Z",
     "iopub.status.idle": "2025-11-10T16:43:52.450027Z",
     "shell.execute_reply": "2025-11-10T16:43:52.449318Z"
    },
    "papermill": {
     "duration": 0.027233,
     "end_time": "2025-11-10T16:43:52.451144",
     "exception": false,
     "start_time": "2025-11-10T16:43:52.423911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in offices order</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/rakshabandhan-compulsory-in-daman-and-diu-women-employees-to-tie-rakhis-to-male-colleagues/story-E5h5U1ZDJii5zFpLXWRkhJ.html?utm_source=inshorts&amp;utm_medium=referral&amp;utm_campaign=fullarticle</td>\n",
       "      <td>The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.</td>\n",
       "      <td>The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media.The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace.?It has been decided to celebrate the festival of Rakshabandhan on August 7. In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said.To ensure that no one skipped office, an attendance report was to be sent to the government the next evening.The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart. The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms.?The circular is ridiculous. There are sensitivities involved. How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day. She refused to be identified.The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said.Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies.In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?. The RSS is the ideological parent of the ruling BJP.Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers. A year before, all cabinet ministers were asked to go to their constituencies for the festival.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                  date  \\\n",
       "0  Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "\n",
       "                                                      headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in offices order   \n",
       "\n",
       "                                                                                                                                                                                                                                 read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/rakshabandhan-compulsory-in-daman-and-diu-women-employees-to-tie-rakhis-to-male-colleagues/story-E5h5U1ZDJii5zFpLXWRkhJ.html?utm_source=inshorts&utm_medium=referral&utm_campaign=fullarticle    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "0  The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ctext  \n",
       "0  The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media.The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace.?It has been decided to celebrate the festival of Rakshabandhan on August 7. In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said.To ensure that no one skipped office, an attendance report was to be sent to the government the next evening.The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart. The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms.?The circular is ridiculous. There are sensitivities involved. How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day. She refused to be identified.The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said.Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies.In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?. The RSS is the ideological parent of the ruling BJP.Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers. A year before, all cabinet ministers were asked to go to their constituencies for the festival.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f388e018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:52.464355Z",
     "iopub.status.busy": "2025-11-10T16:43:52.464166Z",
     "iopub.status.idle": "2025-11-10T16:43:52.470178Z",
     "shell.execute_reply": "2025-11-10T16:43:52.469630Z"
    },
    "papermill": {
     "duration": 0.013858,
     "end_time": "2025-11-10T16:43:52.471239",
     "exception": false,
     "start_time": "2025-11-10T16:43:52.457381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summary_more.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da4675e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:52.485538Z",
     "iopub.status.busy": "2025-11-10T16:43:52.485076Z",
     "iopub.status.idle": "2025-11-10T16:43:52.535365Z",
     "shell.execute_reply": "2025-11-10T16:43:52.534582Z"
    },
    "papermill": {
     "duration": 0.058944,
     "end_time": "2025-11-10T16:43:52.537025",
     "exception": false,
     "start_time": "2025-11-10T16:43:52.478081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102915, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.   \n",
       "1                              Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.   \n",
       "\n",
       "                                                             summary  \n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike  \n",
       "1       Delhi techie wins free food from Swiggy for one year on CRED  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summary.iloc[:, 0:6]\n",
    "summary_more = summary_more.iloc[:, 0:2]\n",
    "\n",
    "# To increase the intake of possible text values to build a reliable model\n",
    "summary['text'] = (\n",
    "    summary['author'] + ' ' +\n",
    "    summary['date'] + ' ' +\n",
    "    summary['read_more'] + ' ' +\n",
    "    summary['text'] + ' ' +\n",
    "    summary['ctext']\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['text'] = pd.concat([summary_more['text'], summary['text']], ignore_index=True)\n",
    "df['summary'] = pd.concat([summary_more['headlines'], summary['headlines']], ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d7b7e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:52.551738Z",
     "iopub.status.busy": "2025-11-10T16:43:52.551507Z",
     "iopub.status.idle": "2025-11-10T16:43:57.177381Z",
     "shell.execute_reply": "2025-11-10T16:43:57.176863Z"
    },
    "papermill": {
     "duration": 4.634339,
     "end_time": "2025-11-10T16:43:57.178769",
     "exception": false,
     "start_time": "2025-11-10T16:43:52.544430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'https?://\\S+', '', text) \n",
    "    text = re.sub(r'[^a-z0-9\\s\\']', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Tokenization: split text by spaces\n",
    "def tokenize_texts(texts):\n",
    "    return [' '.join(clean_text(t).split()) for t in texts]\n",
    "\n",
    "\n",
    "processed_text = tokenize_texts(df['text'])\n",
    "#processed_summary = ['_START_ ' + s + ' _END_' for s in tokenize_texts(df['summary'])]\n",
    "processed_summary = ['sostok ' + s + ' eostok' for s in tokenize_texts(df['summary'])]\n",
    "\n",
    "\n",
    "df['cleaned_text'] = pd.Series(processed_text)\n",
    "df['cleaned_summary'] = pd.Series(processed_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0c0dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:57.192952Z",
     "iopub.status.busy": "2025-11-10T16:43:57.192722Z",
     "iopub.status.idle": "2025-11-10T16:43:57.275326Z",
     "shell.execute_reply": "2025-11-10T16:43:57.274425Z"
    },
    "papermill": {
     "duration": 0.090912,
     "end_time": "2025-11-10T16:43:57.276566",
     "exception": false,
     "start_time": "2025-11-10T16:43:57.185654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN dropped: 118\n",
      "(102915, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"NaN dropped: {df.isna().sum().sum()}\")\n",
    "\n",
    "#df = df.dropna(subset=['text'])\n",
    "df = df.dropna(subset=['cleaned_text', 'cleaned_summary'])\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6702f856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:57.290566Z",
     "iopub.status.busy": "2025-11-10T16:43:57.290340Z",
     "iopub.status.idle": "2025-11-10T16:43:57.297738Z",
     "shell.execute_reply": "2025-11-10T16:43:57.297045Z"
    },
    "papermill": {
     "duration": 0.01556,
     "end_time": "2025-11-10T16:43:57.298777",
     "exception": false,
     "start_time": "2025-11-10T16:43:57.283217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit b's pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad's 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad's online power learning has powered 3 lakh careers</td>\n",
       "      <td>sostok upgrad learner switches to career in ml al with 90 salary hike eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>kunal shah's credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more</td>\n",
       "      <td>sostok delhi techie wins free food from swiggy for one year on cred eostok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.   \n",
       "1                              Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.   \n",
       "\n",
       "                                                             summary  \\\n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1       Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                       cleaned_text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit b's pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad's 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad's online power learning has powered 3 lakh careers   \n",
       "1                                  kunal shah's credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more   \n",
       "\n",
       "                                                                cleaned_summary  \n",
       "0  sostok upgrad learner switches to career in ml al with 90 salary hike eostok  \n",
       "1    sostok delhi techie wins free food from swiggy for one year on cred eostok  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b85146a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:57.313026Z",
     "iopub.status.busy": "2025-11-10T16:43:57.312434Z",
     "iopub.status.idle": "2025-11-10T16:43:58.237410Z",
     "shell.execute_reply": "2025-11-10T16:43:58.236880Z"
    },
    "papermill": {
     "duration": 0.933489,
     "end_time": "2025-11-10T16:43:58.238670",
     "exception": false,
     "start_time": "2025-11-10T16:43:57.305181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_count = []\n",
    "summary_count = []\n",
    "\n",
    "for sent in df['cleaned_text']:\n",
    "    text_count.append(len(sent.split()))\n",
    "    \n",
    "for sent in df['cleaned_summary']:\n",
    "    summary_count.append(len(sent.split()))\n",
    "\n",
    "graph_df = pd.DataFrame() \n",
    "\n",
    "graph_df['text'] = text_count\n",
    "graph_df['summary'] = summary_count\n",
    "\n",
    "graph_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b0a42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:58.254080Z",
     "iopub.status.busy": "2025-11-10T16:43:58.253874Z",
     "iopub.status.idle": "2025-11-10T16:43:58.628960Z",
     "shell.execute_reply": "2025-11-10T16:43:58.628194Z"
    },
    "papermill": {
     "duration": 0.383908,
     "end_time": "2025-11-10T16:43:58.630129",
     "exception": false,
     "start_time": "2025-11-10T16:43:58.246221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of texts with less than 100 words : 0.9577515425351018\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in df['cleaned_text']:\n",
    "    if len(i.split()) <= 100:\n",
    "        cnt = cnt + 1\n",
    "print(f\"Percentage of texts with less than 100 words : {cnt / len(df['cleaned_text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97227c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:43:58.645762Z",
     "iopub.status.busy": "2025-11-10T16:43:58.645355Z",
     "iopub.status.idle": "2025-11-10T16:44:00.270708Z",
     "shell.execute_reply": "2025-11-10T16:44:00.269953Z"
    },
    "papermill": {
     "duration": 1.634139,
     "end_time": "2025-11-10T16:44:00.271845",
     "exception": false,
     "start_time": "2025-11-10T16:43:58.637706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit b's pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad's 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad's online power learning has powered 3 lakh careers</td>\n",
       "      <td>sostok sostok upgrad learner switches to career in ml al with 90 salary hike eostok eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>kunal shah's credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more</td>\n",
       "      <td>sostok sostok delhi techie wins free food from swiggy for one year on cred eostok eostok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.   \n",
       "1                              Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.   \n",
       "\n",
       "                                                             summary  \\\n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1       Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                       cleaned_text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit b's pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad's 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad's online power learning has powered 3 lakh careers   \n",
       "1                                  kunal shah's credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more   \n",
       "\n",
       "                                                                              cleaned_summary  \n",
       "0  sostok sostok upgrad learner switches to career in ml al with 90 salary hike eostok eostok  \n",
       "1    sostok sostok delhi techie wins free food from swiggy for one year on cred eostok eostok  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_len = 100\n",
    "max_summary_len = 20\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].astype(str)\n",
    "df['cleaned_summary'] = df['cleaned_summary'].astype(str)\n",
    "\n",
    "mask = (df['cleaned_text'].str.split().str.len() <= max_text_len) & \\\n",
    "       (df['cleaned_summary'].str.split().str.len() <= max_summary_len)\n",
    "\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# Add start and end tokens to each summary\n",
    "df['cleaned_summary'] = df['cleaned_summary'].apply(lambda x: 'sostok ' + x + ' eostok')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aae893",
   "metadata": {
    "papermill": {
     "duration": 0.007006,
     "end_time": "2025-11-10T16:44:00.286413",
     "exception": false,
     "start_time": "2025-11-10T16:44:00.279407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Tokenization**\n",
    "\n",
    "This block prepares the text data for a sequence-to-sequence model:\n",
    "\n",
    "- **Split dataset**: Separates `text` and `summary` into training and validation sets to evaluate model performance on unseen data.  \n",
    "- **Initialize tokenizers**: Converts words into integer indices, which neural networks can process.  \n",
    "- **Analyze rare words**: Computes the percentage of words appearing less than `thresh` times to identify infrequent words that might add noise.  \n",
    "- **Limit vocabulary to frequent words**: Reduces vocabulary size by ignoring rare words, which improves training efficiency and prevents overfitting.  \n",
    "- **Convert texts to sequences**: Maps each word in the texts to its corresponding integer index.  \n",
    "- **Pad sequences**: Ensures all sequences have the same length, necessary for batch processing in neural networks.  \n",
    "- **Compute final vocabulary size**: Includes the padding token to correctly define the input dimension for the model embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3108b667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:00.301584Z",
     "iopub.status.busy": "2025-11-10T16:44:00.301187Z",
     "iopub.status.idle": "2025-11-10T16:44:17.921155Z",
     "shell.execute_reply": "2025-11-10T16:44:17.920290Z"
    },
    "papermill": {
     "duration": 17.629188,
     "end_time": "2025-11-10T16:44:17.922676",
     "exception": false,
     "start_time": "2025-11-10T16:44:00.293488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 16:44:02.798903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762793042.973403      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762793043.025246      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    np.array(df[\"cleaned_text\"]),\n",
    "    np.array(df[\"cleaned_summary\"]),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd96098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:17.939273Z",
     "iopub.status.busy": "2025-11-10T16:44:17.938780Z",
     "iopub.status.idle": "2025-11-10T16:44:17.976335Z",
     "shell.execute_reply": "2025-11-10T16:44:17.975771Z"
    },
    "papermill": {
     "duration": 0.046776,
     "end_time": "2025-11-10T16:44:17.977428",
     "exception": false,
     "start_time": "2025-11-10T16:44:17.930652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in X vocabulary: 54.59%\n",
      "% of rare words in Y vocabulary: 55.62%\n"
     ]
    }
   ],
   "source": [
    "thresh = 3\n",
    "\n",
    "def rare_word_stats(tokenizer, thresh):\n",
    "    \"\"\"Return total and rare word counts for a given tokenizer.\"\"\"\n",
    "    total_cnt = len(tokenizer.word_counts)\n",
    "    rare_cnt = sum(1 for word, count in tokenizer.word_counts.items() if count < thresh)\n",
    "    return total_cnt, rare_cnt\n",
    "\n",
    "\n",
    "x_tot_cnt, x_cnt = rare_word_stats(x_tokenizer, thresh)\n",
    "y_tot_cnt, y_cnt = rare_word_stats(y_tokenizer, thresh)\n",
    "\n",
    "print(f\"% of rare words in X vocabulary: {(x_cnt / x_tot_cnt) * 100:.2f}%\")\n",
    "print(f\"% of rare words in Y vocabulary: {(y_cnt / y_tot_cnt) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c755aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:17.992702Z",
     "iopub.status.busy": "2025-11-10T16:44:17.992453Z",
     "iopub.status.idle": "2025-11-10T16:44:26.315977Z",
     "shell.execute_reply": "2025-11-10T16:44:26.315093Z"
    },
    "papermill": {
     "duration": 8.332683,
     "end_time": "2025-11-10T16:44:26.317335",
     "exception": false,
     "start_time": "2025-11-10T16:44:17.984652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 42519\n",
      "Size of vocabulary in Y = 18531\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizers considering only frequent words\n",
    "x_tokenizer = Tokenizer(num_words = x_tot_cnt - x_cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=y_tot_cnt-y_cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "x_train_seq = x_tokenizer.texts_to_sequences(x_train) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "# Pad sequences\n",
    "x_train = pad_sequences(x_train_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "y_train = pad_sequences(y_train_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Vocab. size (+1 for padding token)\n",
    "x_voc_size = x_tokenizer.num_words + 1\n",
    "y_voc_size = y_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc_size))\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c425afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:26.333060Z",
     "iopub.status.busy": "2025-11-10T16:44:26.332832Z",
     "iopub.status.idle": "2025-11-10T16:44:26.376170Z",
     "shell.execute_reply": "2025-11-10T16:44:26.375583Z"
    },
    "papermill": {
     "duration": 0.052423,
     "end_time": "2025-11-10T16:44:26.377471",
     "exception": false,
     "start_time": "2025-11-10T16:44:26.325048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally remove from the dataset empty summaries that contain only the 'START' and 'END' tokens\n",
    "\n",
    "x_train = x_train[np.sum(y_train != 0, axis=1) > 2]\n",
    "y_train = y_train[np.sum(y_train != 0, axis=1) > 2]\n",
    "\n",
    "x_val = x_val[np.sum(y_val != 0, axis=1) > 2]\n",
    "y_val = y_val[np.sum(y_val != 0, axis=1) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169d8996",
   "metadata": {
    "papermill": {
     "duration": 0.007174,
     "end_time": "2025-11-10T16:44:26.392342",
     "exception": false,
     "start_time": "2025-11-10T16:44:26.385168",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Seq2seq model using LSTM**\n",
    "\n",
    "### Encoder-Decoder Architecture with LSTM\n",
    "\n",
    "During training, the model takes **two inputs**:  \n",
    "1. The encoder input (`text`) – the original text sequence.  \n",
    "2. The decoder input (`summary`) – the summary shifted by one token (so that the model learns to predict the next word).  \n",
    "\n",
    "The **target output** is the summary sequence shifted forward by one token. The model learns to predict the next word in the summary based on the previous words. During inference, the trained model generates summaries one word at a time, using the previously predicted words as input.\n",
    "\n",
    "---\n",
    "\n",
    "**Encoder**  \n",
    "- The encoder accepts sequences of text with a fixed length (`max_text_len`).  \n",
    "- The text is first passed through an **Embedding layer** that maps each word index to a dense vector of size `(embedding_dim)`.  \n",
    "- The embedded sequence is then processed by **three stacked LSTM layers**:  \n",
    "  - Each layer outputs the **full sequence of hidden states** (for possible attention or stacking) and the **last hidden and cell states**.  \n",
    "  - The last hidden and cell states from the final LSTM are used to initialize the decoder.  \n",
    "- Stacking multiple LSTMs allows the encoder to **capture both local patterns and long-range dependencies** in the text.\n",
    "\n",
    "---\n",
    "\n",
    "**Decoder**  \n",
    "- The decoder input (shifted summary) is passed through an **Embedding layer** of size `(summary vocabulary size x embedding_dim)`.  \n",
    "- A single **LSTM** processes the embedded sequence, using the **encoder's last hidden and cell states** as its initial state.  \n",
    "- The LSTM output is passed through a **TimeDistributed Dense layer** with **softmax activation**, which predicts the probability of each word in the vocabulary at each time step.  \n",
    "\n",
    "This architecture ensures that the decoder can generate the summary step by step, **learning the sequence of words conditioned on the input text**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca71034",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:26.407974Z",
     "iopub.status.busy": "2025-11-10T16:44:26.407702Z",
     "iopub.status.idle": "2025-11-10T16:44:28.481495Z",
     "shell.execute_reply": "2025-11-10T16:44:28.480969Z"
    },
    "papermill": {
     "duration": 2.083095,
     "end_time": "2025-11-10T16:44:28.482609",
     "exception": false,
     "start_time": "2025-11-10T16:44:26.399514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762793067.053370      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,503,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,706,200</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,577,831</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18531</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m200\u001b[0m)  │  \u001b[38;5;34m8,503,800\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m601,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m721,200\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │  \u001b[38;5;34m3,706,200\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m721,200\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m601,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m5,577,831\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m18531\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,432,631</span> (77.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,432,631\u001b[0m (77.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,432,631</span> (77.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,432,631\u001b[0m (77.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len, ))\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb = Embedding(x_voc_size, embedding_dim,\n",
    "                    trainable=True)(encoder_inputs)\n",
    "\n",
    "# Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_voc_size, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0.2)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111c05a8",
   "metadata": {
    "papermill": {
     "duration": 0.050341,
     "end_time": "2025-11-10T16:44:28.541451",
     "exception": false,
     "start_time": "2025-11-10T16:44:28.491110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Training the model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae7b10a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:28.558713Z",
     "iopub.status.busy": "2025-11-10T16:44:28.558134Z",
     "iopub.status.idle": "2025-11-10T16:44:29.951874Z",
     "shell.execute_reply": "2025-11-10T16:44:29.951292Z"
    },
    "papermill": {
     "duration": 1.403979,
     "end_time": "2025-11-10T16:44:29.953309",
     "exception": false,
     "start_time": "2025-11-10T16:44:28.549330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_lstm = x_train\n",
    "x_val_lstm = x_val\n",
    "y_train_lstm = y_train\n",
    "y_val_lstm = y_val\n",
    "\n",
    "MODEL_INPUT_PATH = \"/kaggle/input/lstm-keras-summarization/keras/default/1/model_lstm.keras\" \n",
    "MODEL_PATH = \"/kaggle/working/model_lstm.keras\" \n",
    "\n",
    "# retrain the model\n",
    "if os.path.exists(MODEL_INPUT_PATH):\n",
    "    model = load_model(MODEL_INPUT_PATH)\n",
    "\n",
    "else:\n",
    "    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "    history = model.fit(\n",
    "        [x_train, y_train[:, :-1]],\n",
    "        y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "        epochs=50,\n",
    "        callbacks=[es],\n",
    "        batch_size=128,\n",
    "        validation_data=(\n",
    "            [x_val, y_val[:, :-1]],\n",
    "            y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a700b",
   "metadata": {
    "papermill": {
     "duration": 0.007798,
     "end_time": "2025-11-10T16:44:29.969410",
     "exception": false,
     "start_time": "2025-11-10T16:44:29.961612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Predict**\n",
    "\n",
    "Once the Seq2Seq model has been trained, we can use it to **generate summaries** for new input texts.  \n",
    "This stage is known as **inference**, the model no longer learns, but uses its learned parameters to predict the most likely output sequence (summary).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Preparing the Mapping Dictionaries\n",
    "Before generating predictions, we rebuild the word–token mappings from the tokenizers:\n",
    "- `reverse_x_word_index`: converts article tokens → words  \n",
    "- `reverse_y_word_index`: converts summary tokens → words  \n",
    "- `y_word_index`: converts summary words → tokens  \n",
    "\n",
    "These dictionaries let us translate between the model’s numeric predictions and readable text.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Building Inference Models\n",
    "During training, the encoder and decoder work together in a single model.  \n",
    "At inference time, we separate them:\n",
    "\n",
    "- The **encoder model** processes the input text once and produces context vectors (`encoder_outputs`, `state_h`, `state_c`) — a compressed representation of the input.  \n",
    "- The **decoder model** generates the summary **one word at a time**, taking as input the previous word and its previous internal states.\n",
    "\n",
    "This setup allows the decoder to iteratively predict each next token until the end-of-sequence marker (`eostok`) is reached.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. The Decoding Process\n",
    "The function `decode_sequence()` handles the actual text generation:\n",
    "\n",
    "1. **Encode the input sequence** using the encoder model to obtain its internal states.  \n",
    "2. **Initialize** the decoder with the special start token (`sostok`).  \n",
    "3. **Iteratively predict** the next word:\n",
    "   - Feed the previous word and the latest decoder states into the model.\n",
    "   - Pick the word with the highest probability (`argmax`).\n",
    "   - Stop when the `eostok` token is predicted or the maximum summary length is reached.\n",
    "4. **Concatenate** all predicted tokens into a readable summary.\n",
    "\n",
    "This process simulates how the model “writes” one word at a time, using its internal memory to maintain context.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Converting Sequences to Text\n",
    "Two helper functions make the predictions human-readable:\n",
    "- `seq2text()` converts numeric article sequences back into words.\n",
    "- `seq2summary()` converts numeric summary sequences back into words, excluding special tokens (`sostok`, `eostok`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d310d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:29.986259Z",
     "iopub.status.busy": "2025-11-10T16:44:29.986031Z",
     "iopub.status.idle": "2025-11-10T16:44:29.989594Z",
     "shell.execute_reply": "2025-11-10T16:44:29.989017Z"
    },
    "papermill": {
     "duration": 0.01326,
     "end_time": "2025-11-10T16:44:29.990566",
     "exception": false,
     "start_time": "2025-11-10T16:44:29.977306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reverse_y_word_index: summary token → word\n",
    "# reverse_x_word_index: article token → word\n",
    "# y_word_index: summary word → token\n",
    "\n",
    "reverse_y_word_index = y_tokenizer.index_word\n",
    "reverse_x_word_index = x_tokenizer.index_word\n",
    "y_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38691671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:30.007317Z",
     "iopub.status.busy": "2025-11-10T16:44:30.007111Z",
     "iopub.status.idle": "2025-11-10T16:44:30.017369Z",
     "shell.execute_reply": "2025-11-10T16:44:30.016865Z"
    },
    "papermill": {
     "duration": 0.019813,
     "end_time": "2025-11-10T16:44:30.018312",
     "exception": false,
     "start_time": "2025-11-10T16:44:29.998499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference Models\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
    "                      state_h, state_c])\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02a1633f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:30.034608Z",
     "iopub.status.busy": "2025-11-10T16:44:30.034414Z",
     "iopub.status.idle": "2025-11-10T16:44:30.040519Z",
     "shell.execute_reply": "2025-11-10T16:44:30.040057Z"
    },
    "papermill": {
     "duration": 0.01537,
     "end_time": "2025-11-10T16:44:30.041481",
     "exception": false,
     "start_time": "2025-11-10T16:44:30.026111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert sequence to summary\n",
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != y_word_index['sostok'] and i \\\n",
    "            != y_word_index['eostok']:\n",
    "            newString = newString + reverse_y_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "# Convert sequence to text\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + reverse_x_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    y_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    y_seq[0, 0] = y_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([y_seq]\n",
    "                + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_y_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find the stop word.\n",
    "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
    "            >= max_summary_len - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        y_seq = np.zeros((1, 1))\n",
    "        y_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac8cd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:30.057848Z",
     "iopub.status.busy": "2025-11-10T16:44:30.057610Z",
     "iopub.status.idle": "2025-11-10T16:44:42.335801Z",
     "shell.execute_reply": "2025-11-10T16:44:42.335058Z"
    },
    "papermill": {
     "duration": 12.287886,
     "end_time": "2025-11-10T16:44:42.337241",
     "exception": false,
     "start_time": "2025-11-10T16:44:30.049355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: a total of five jawans of the special task force were injured on saturday in an encounter with the maoists in chhattisgarh's sukma district while the jawans have been taken to a hospital for treatment the encounter is still underway notably as many as 25 crpf personnel were killed and six others injured in sukma in april \n",
      "Original summary: 5 jawans injured in encounter with maoists in chhattisgarh \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted summary:  haryanvi commutes trials error monitoring error 146 lieutenant equipment rating rivers syringe mercy nizamuddin karan patni black styles marlboro\n",
      "\n",
      "\n",
      "Review: uk's largest supplier of household energy british gas has paid out 2 65 million 24 crore after regulators found that it overcharged more than 94 000 customers due to a system error british gas charged customers its more expensive tariff rate after they decided to switch to a new supplier it also wrongly informed 2 5 million customers that exit fees were chargeable \n",
      "Original summary: british gas pays out for overcharging 94 000 customers \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted summary:  haryanvi commutes trials error monitoring error 146 lieutenant equipment rating rivers syringe mercy nizamuddin karan patni black styles marlboro\n",
      "\n",
      "\n",
      "Review: the central industrial security force cisf will be conducting a week long trial to stop the stamping of hand baggage at six more airports between april 24 to april 30 the airports included in the list are chennai patna guwahati thiruvananthapuram jaipur and lucknow earlier hand baggage stamping was stopped at seven airports including delhi kolkata bengaluru and mumbai \n",
      "Original summary: trial to stop hand baggage stamping at 6 more airports \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  haryanvi commutes trials error monitoring error 146 lieutenant equipment rating rivers syringe mercy nizamuddin karan patni black styles marlboro\n",
      "\n",
      "\n",
      "Review: smartphone maker oneplus has admitted that credit card information of up to 40 000 customers on its website has been compromised a malicious script was running on one of its payment processing servers affecting users who entered their credit card details since mid november 2017 it clarified that customers who paid using saved credit cards or paypal were not affected \n",
      "Original summary: oneplus confirms 40 000 users' credit card data leaked \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Predicted summary:  haryanvi commutes trials error monitoring error 146 lieutenant equipment rating rivers syringe mercy nizamuddin karan patni black styles marlboro\n",
      "\n",
      "\n",
      "Review: former kingfisher airlines employees have said their main concern is the recovery of their unpaid salaries and extradition of vijay mallya our main concern is that the government should get him to india and we should get our dues they said according to an open letter written last year mallya owes 300 crore as salary dues to over 3 000 employees \n",
      "Original summary: ex kingfisher staff worried over unpaid wages on mallya row \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted summary:  haryanvi commutes trials error monitoring error 146 lieutenant equipment rating rivers syringe mercy nizamuddin karan patni black styles marlboro\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print ('Review:', seq2text(x_train[i]))\n",
    "    print ('Original summary:', seq2summary(y_train[i]))\n",
    "    print ('Predicted summary:', decode_sequence(x_train[i].reshape(1, max_text_len)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ed69a",
   "metadata": {
    "papermill": {
     "duration": 0.016275,
     "end_time": "2025-11-10T16:44:42.371338",
     "exception": false,
     "start_time": "2025-11-10T16:44:42.355063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Model with Self-Attention\n",
    "\n",
    "Similar to the Seq2Seq architecture, the Transformer follows an **encoder–decoder structure**, but instead of recurrent layers it relies entirely on **Multi-Head Self-Attention**.  \n",
    "This allows the model to process all tokens **in parallel** and learn relationships between words regardless of their distance in the sequence.\n",
    "\n",
    "During training, the model takes **two inputs**:  \n",
    "1. The encoder input (`text`) – the tokenized article.  \n",
    "2. The decoder input (`summary`) – the summary shifted by one token.  \n",
    "\n",
    "The **target output** is the summary shifted forward by one position. The decoder learns to predict each word based on the previously generated ones and the encoded representation of the full text.\n",
    "\n",
    "---\n",
    "\n",
    "**Encoder**  \n",
    "- The input article sequence (`max_text_len`) is first transformed using an **Embedding layer**.  \n",
    "- A **Positional Encoding** is added to preserve the order of words (since attention has no notion of sequence order by itself).  \n",
    "- The embedded input is processed by one or more **Multi-Head Self-Attention** blocks:\n",
    "  - Each word attends to **all other words** in the input\n",
    "  - Relationships between distant tokens are captured more effectively than in RNNs  \n",
    "- A **Feed-Forward Network** (FFN) refines the contextual representations.\n",
    "- **Residual connections** and **Layer Normalization** improve gradient flow and training stability.\n",
    "\n",
    "---\n",
    "\n",
    "**Decoder**  \n",
    "- Similar positional embeddings are applied to the shifted summary tokens.  \n",
    "- The decoder uses two attention mechanisms:\n",
    "  1. **Masked Self-Attention**: ensures the model cannot “peek” at future words when predicting the next token.\n",
    "  2. **Encoder-Decoder Attention**: allows the decoder to focus on relevant parts of the input article.\n",
    "- A **Feed-Forward Network** further processes the attended features.\n",
    "- A final **Dense layer with Softmax** outputs a probability distribution over all words in the vocabulary at each time step.\n",
    "\n",
    "---\n",
    "\n",
    "**sostok and eostok**  \n",
    "In sequence-to-sequence tasks such as abstractive text summarization, **special tokens** are essential for controlling how a model generates text:\n",
    "\n",
    "- `<sostok>` → marks the **start** of the output sequence  \n",
    "- `<eostok>` → marks the **end** of the sequence  \n",
    "\n",
    "However, these tokens **do not** play the same role during training across different architectures.\n",
    "\n",
    "Transformers use **masked self-attention** in the decoder, meaning that at time *t* the model can only attend to **previous tokens**.\n",
    "Therefore:\n",
    "\n",
    "- `<sostok>` must be present **only in the decoder input**  \n",
    "- `<sostok>` must be removed from the decoder target  \n",
    "\n",
    "Predicting a start token would make no sense and causes failure modes such as:\n",
    "\n",
    "- the model repeatedly outputting `<sostok>`\n",
    "- inability to begin sequences with meaningful content\n",
    "\n",
    "The EOS token **must remain in the targets**, because:\n",
    "\n",
    "- it teaches the model **when to stop writing**\n",
    "- without it, generation may become too long or infinite\n",
    "\n",
    "LSTM encoder-decoder models:\n",
    "\n",
    "- receive the final hidden state as initial context\n",
    "- do **not** use masked attention\n",
    "- often ignore the first timestep in loss computation\n",
    "\n",
    "So `<sostok>` in targets is less harmful there.\n",
    "\n",
    "---\n",
    "\n",
    "Thanks to the Self-Attention mechanism, Transformers **capture global context efficiently** and typically produce **more coherent and fluent summaries**, especially for longer texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c77cd5",
   "metadata": {
    "papermill": {
     "duration": 0.016569,
     "end_time": "2025-11-10T16:44:42.404229",
     "exception": false,
     "start_time": "2025-11-10T16:44:42.387660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preparing Transformer Inputs\n",
    "\n",
    "To train the Transformer in an encoder–decoder setup, we need to properly structure the input data:\n",
    "\n",
    "- The **encoder input** is the full tokenized article (`x_train`)\n",
    "- The **decoder input** is the summary sequence **shifted right**, starting with `<sostok>`\n",
    "- The **decoder target** is the same summary **shifted left**, ending with `<eostok>`\n",
    "\n",
    "This shifting ensures that at each timestep the decoder learns to predict the **next** word using:\n",
    "1. The previously processed summary tokens  \n",
    "2. Attention over the encoder output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c20ab3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:42.437694Z",
     "iopub.status.busy": "2025-11-10T16:44:42.437395Z",
     "iopub.status.idle": "2025-11-10T16:44:42.462377Z",
     "shell.execute_reply": "2025-11-10T16:44:42.461675Z"
    },
    "papermill": {
     "duration": 0.042953,
     "end_time": "2025-11-10T16:44:42.463523",
     "exception": false,
     "start_time": "2025-11-10T16:44:42.420570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS in decoder_input_data: 177416\n",
      "EOS in decoder_input_data: 177397\n",
      "SOS in decoder_target_data: 0\n",
      "EOS in decoder_target_data: 177420\n"
     ]
    }
   ],
   "source": [
    "sos = y_tokenizer.word_index[\"sostok\"]\n",
    "eos = y_tokenizer.word_index[\"eostok\"]\n",
    "\n",
    "\n",
    "x_train_trans = x_train\n",
    "x_val_trans = x_val\n",
    "y_train_trans = y_train\n",
    "y_val_trans = y_val\n",
    "\n",
    "\n",
    "encoder_input_data = x_train_trans\n",
    "encoder_input_val = x_val_trans\n",
    "\n",
    "decoder_input_data = y_train_trans[:, :-1]    \n",
    "decoder_target_data = y_train_trans[:, 1:]   \n",
    "\n",
    "decoder_input_val = y_val_trans[:, :-1]\n",
    "decoder_target_val = y_val_trans[:, 1:]\n",
    "\n",
    "# Remove SOS from target\n",
    "decoder_target_data = np.where(decoder_target_data == sos, 0, decoder_target_data)\n",
    "decoder_target_val = np.where(decoder_target_val == sos, 0, decoder_target_val)\n",
    "\n",
    "print(\"SOS in decoder_input_data:\", np.sum(decoder_input_data == sos))\n",
    "print(\"EOS in decoder_input_data:\", np.sum(decoder_input_data == eos))\n",
    "\n",
    "print(\"SOS in decoder_target_data:\", np.sum(decoder_target_data == sos))\n",
    "print(\"EOS in decoder_target_data:\", np.sum(decoder_target_data == eos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223ae47",
   "metadata": {
    "papermill": {
     "duration": 0.0158,
     "end_time": "2025-11-10T16:44:42.496038",
     "exception": false,
     "start_time": "2025-11-10T16:44:42.480238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Checks for Transformer \n",
    "\n",
    "Before training a Transformer for summarization, it’s important to verify the **preparation of your input and target sequences**. \n",
    "<br>These checks help ensure that special tokens and shapes are correct, preventing subtle bugs during training and inference.\n",
    "\n",
    "---\n",
    "\n",
    "**Special token indices**\n",
    "\n",
    "- `sos = y_tokenizer.word_index.get(\"sostok\")` → marks the **start of sequence**  \n",
    "- `eos = y_tokenizer.word_index.get(\"eostok\")` → marks the **end of sequence**  \n",
    "- `pad = 0` → used for **padding sequences** to a fixed length  \n",
    "\n",
    "These indices guide the model during training and inference:\n",
    "\n",
    "- The **decoder input** always starts with `<sostok>`  \n",
    "- The **decoder target** should **not include `<sostok>`**, but must include `<eostok>`  \n",
    "- `<pad>` tokens are ignored in attention and loss calculation\n",
    "\n",
    "---\n",
    "\n",
    "**Check occurrences of special tokens**\n",
    "\n",
    "- `np.sum(decoder_input_data == sos)` → number of `<sostok>` in decoder input  \n",
    "- `np.sum(decoder_input_data == eos)` → number of `<eostok>` in decoder input  \n",
    "- `np.sum(decoder_target_data == sos)` → should be **zero**, otherwise remove it  \n",
    "- `np.sum(decoder_target_data == eos)` → ensures EOS appears at the end of target sequences\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "- `<sostok>` must only appear in decoder input; predicting it in the target is meaningless  \n",
    "- `<eostok>` signals the model **when to stop generating**  \n",
    "- Incorrect placement leads to poor summaries or repeated tokens\n",
    "\n",
    "---\n",
    "\n",
    "**Check token ranges**\n",
    "\n",
    "- `np.min(encoder_input_data)` / `np.max(encoder_input_data)` → ensure all encoder tokens are within vocabulary  \n",
    "- `np.min(decoder_input_data)` / `np.max(decoder_input_data)` → ensure all decoder tokens are valid  \n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "- Out-of-range token IDs can crash the model or produce nonsense outputs  \n",
    "- Confirms tokenization and indexing worked correctly\n",
    "\n",
    "---\n",
    "\n",
    "**Check shapes of arrays**\n",
    "\n",
    "- `encoder_input_data.shape` → `(num_samples, max_text_len)`  \n",
    "- `decoder_input_data.shape` → `(num_samples, max_summary_len-1)`  \n",
    "- `decoder_target_data.shape` → `(num_samples, max_summary_len-1)`\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "- Shapes must match between encoder input, decoder input, and decoder target  \n",
    "- Prevents errors like **data cardinality mismatches** during training\n",
    "\n",
    "---\n",
    "\n",
    "**Visual check of first sequence**\n",
    "\n",
    "- `decoder_input_data[0]` → first decoder input sequence (should start with `<sostok>`)  \n",
    "- `decoder_target_data[0]` → first decoder target sequence (shifted, should contain `<eostok>` at the end)\n",
    "\n",
    "**Why it matters:**\n",
    "\n",
    "- Quick sanity check of sequence alignment  \n",
    "- Ensures the shift between input and target is correct for teacher forcing during training\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "Performing these checks ensures:\n",
    "\n",
    "1. **Special tokens** (`SOS`, `EOS`, `PAD`) are handled correctly  \n",
    "2. **Sequences** have the proper shapes for the Transformer  \n",
    "3. **Token ranges** are valid within the vocabulary  \n",
    "4. Early detection of issues that could lead to poor training or invalid inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dda74484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:42.544689Z",
     "iopub.status.busy": "2025-11-10T16:44:42.544399Z",
     "iopub.status.idle": "2025-11-10T16:44:42.572171Z",
     "shell.execute_reply": "2025-11-10T16:44:42.571399Z"
    },
    "papermill": {
     "duration": 0.05019,
     "end_time": "2025-11-10T16:44:42.573344",
     "exception": false,
     "start_time": "2025-11-10T16:44:42.523154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS index: 1\n",
      "EOS index: 2\n",
      "SOS occurrences in decoder_input_data: 177416\n",
      "EOS occurrences in decoder_input_data: 177397\n",
      "SOS occurrences in decoder_target_data: 0\n",
      "EOS occurrences in decoder_target_data: 177420\n",
      "Min token in X: 0\n",
      "Max token in X: 42517\n",
      "Min token in Y: 0\n",
      "Max token in Y: 18529\n",
      "Encoder input shape: (88710, 100)\n",
      "Decoder input shape: (88710, 19)\n",
      "Decoder target shape: (88710, 19)\n",
      "First decoder input sequence: [   1    1   46 1790  289    4 1733    8 2943    4 1149    2    2    0\n",
      "    0    0    0    0    0]\n",
      "First decoder target sequence: [   0   46 1790  289    4 1733    8 2943    4 1149    2    2    0    0\n",
      "    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(\"SOS index:\", sos)\n",
    "print(\"EOS index:\", eos)\n",
    "\n",
    "\n",
    "print(\"SOS occurrences in decoder_input_data:\", np.sum(decoder_input_data == sos))\n",
    "print(\"EOS occurrences in decoder_input_data:\", np.sum(decoder_input_data == eos))\n",
    "\n",
    "print(\"SOS occurrences in decoder_target_data:\", np.sum(decoder_target_data == sos))\n",
    "print(\"EOS occurrences in decoder_target_data:\", np.sum(decoder_target_data == eos))\n",
    "\n",
    "\n",
    "print(\"Min token in X:\", np.min(encoder_input_data))\n",
    "print(\"Max token in X:\", np.max(encoder_input_data))\n",
    "\n",
    "print(\"Min token in Y:\", np.min(decoder_input_data))\n",
    "print(\"Max token in Y:\", np.max(decoder_input_data))\n",
    "\n",
    "\n",
    "print(\"Encoder input shape:\", encoder_input_data.shape)\n",
    "print(\"Decoder input shape:\", decoder_input_data.shape)\n",
    "print(\"Decoder target shape:\", decoder_target_data.shape)\n",
    "\n",
    "print(\"First decoder input sequence:\", decoder_input_data[0])\n",
    "print(\"First decoder target sequence:\", decoder_target_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17a6f1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:42.606588Z",
     "iopub.status.busy": "2025-11-10T16:44:42.606363Z",
     "iopub.status.idle": "2025-11-10T16:44:44.600960Z",
     "shell.execute_reply": "2025-11-10T16:44:44.600367Z"
    },
    "papermill": {
     "duration": 2.012813,
     "end_time": "2025-11-10T16:44:44.602166",
     "exception": false,
     "start_time": "2025-11-10T16:44:42.589353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,041,856</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,005,760</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18531</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,762,467</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder (\u001b[38;5;33mEncoder\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │ \u001b[38;5;34m14,041,856\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │ \u001b[38;5;34m10,005,760\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m18531\u001b[0m) │  \u001b[38;5;34m4,762,467\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,810,083</span> (109.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,810,083\u001b[0m (109.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,810,083</span> (109.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,810,083\u001b[0m (109.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Embedding, Dense, LayerNormalization, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "d_model = 256 # embedding dimension\n",
    "num_heads = 4\n",
    "dff = 1024 # feed-forward hidden size\n",
    "num_layers = 2 # encoder/decoder layers\n",
    "dropout_rate = 0.3\n",
    "\n",
    "\n",
    "# Positional Encoding Layer\n",
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        pos = np.arange(max_len)[:, np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis, :]\n",
    "        angle_rates = 1 / np.power(10000, (2*(i//2))/np.float32(d_model))\n",
    "        angle_rads = pos * angle_rates\n",
    "        pos_encoding = np.zeros_like(angle_rads)\n",
    "        pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        self.pos_encoding = tf.cast(pos_encoding[np.newaxis, ...], tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        return x + self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "# Mak\n",
    "def create_padding_mask(seq):\n",
    "    mask = tf.cast(tf.equal(seq, 0), tf.float32)  # (batch, seq_len)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]     # (batch,1,1,seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask[tf.newaxis, tf.newaxis, :, :]     # (1,1,size,size) for broadcasting\n",
    "\n",
    "# --- Encoder Layer ---\n",
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(dff, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, padding_mask=None, training=False):\n",
    "        attn_output = self.mha(query=x, value=x, key=x, attention_mask=padding_mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.norm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.norm2(out1 + ffn_output)\n",
    "\n",
    "# --- Decoder Layer ---\n",
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(dff, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask=None, padding_mask=None, training=False):\n",
    "        # Masked self-attention\n",
    "        attn1 = self.mha1(query=x, value=x, key=x, attention_mask=look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.norm1(x + attn1)\n",
    "\n",
    "        # Cross-attention\n",
    "        attn2 = self.mha2(query=out1, value=enc_output, key=enc_output, attention_mask=padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.norm2(out1 + attn2)\n",
    "\n",
    "        # Feed-forward\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        return self.norm3(out2 + ffn_output)\n",
    "\n",
    "# --- Encoder (stack) ---\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, max_len, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(max_len, d_model)\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        padding_mask = create_padding_mask(x)  # (batch,1,1,seq_len)\n",
    "        x = self.embedding(x) * tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, padding_mask, training=training)\n",
    "        return x\n",
    "\n",
    "# --- Decoder ---\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size, max_len, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(max_len, d_model)\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def call(self, x, enc_output, enc_padding_mask=None, training=False):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # Look-ahead mask\n",
    "        look_ahead_mask = create_look_ahead_mask(seq_len)  # (1,1,seq_len,seq_len)\n",
    "\n",
    "        # Padding mask for the decoder self-attention\n",
    "        dec_padding_mask = create_padding_mask(x)          # (batch,1,1,seq_len)\n",
    "\n",
    "        x = self.embedding(x) * tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(\n",
    "                x, \n",
    "                enc_output, \n",
    "                look_ahead_mask=look_ahead_mask, \n",
    "                padding_mask=enc_padding_mask,  # <- qui passo la maschera dell'encoder\n",
    "                training=training\n",
    "            )\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_transformer(input_vocab_size, target_vocab_size, max_input_len, max_target_len):\n",
    "    enc_inputs = Input(shape=(max_input_len,))\n",
    "    dec_inputs = Input(shape=(max_target_len,))\n",
    "\n",
    "    encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, max_input_len, dropout_rate)\n",
    "    decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, max_target_len, dropout_rate)\n",
    "\n",
    "    enc_output = encoder(enc_inputs)  # encoder crea la sua maschera interna\n",
    "    dec_output = decoder(dec_inputs, enc_output)  # decoder crea look-ahead + usa enc_output\n",
    "    final_output = Dense(target_vocab_size, activation='softmax')(dec_output)\n",
    "\n",
    "    return Model([enc_inputs, dec_inputs], final_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build model\n",
    "#transformer, encoder_layer_obj, decoder_layer_obj = build_transformer(x_voc_size, y_voc_size, max_text_len, max_summary_len-1)\n",
    "transformer = build_transformer(x_voc_size, y_voc_size, max_text_len, max_summary_len-1)\n",
    "\n",
    "# Compile\n",
    "transformer.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8856d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T16:44:44.637477Z",
     "iopub.status.busy": "2025-11-10T16:44:44.637240Z",
     "iopub.status.idle": "2025-11-10T17:02:27.365284Z",
     "shell.execute_reply": "2025-11-10T17:02:27.364604Z"
    },
    "papermill": {
     "duration": 1062.746403,
     "end_time": "2025-11-10T17:02:27.366601",
     "exception": false,
     "start_time": "2025-11-10T16:44:44.620198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762793105.606958      57 service.cc:148] XLA service 0x7b29780fc740 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762793105.607506      57 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "W0000 00:00:1762793106.694672      57 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1762793107.582004      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   2/1387\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 78ms/step - accuracy: 0.0164 - loss: 9.7401       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762793119.314831      57 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1386/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 5.1037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762793218.191798      57 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5001 - loss: 5.1027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762793231.269360      60 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1762793235.194702      59 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 85ms/step - accuracy: 0.5001 - loss: 5.1017 - val_accuracy: 0.6900 - val_loss: 2.1469\n",
      "Epoch 2/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.7338 - loss: 2.0117 - val_accuracy: 0.8570 - val_loss: 1.0483\n",
      "Epoch 3/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 73ms/step - accuracy: 0.8651 - loss: 1.1075 - val_accuracy: 0.9305 - val_loss: 0.5553\n",
      "Epoch 4/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.9244 - loss: 0.6604 - val_accuracy: 0.9631 - val_loss: 0.3166\n",
      "Epoch 5/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 73ms/step - accuracy: 0.9531 - loss: 0.4194 - val_accuracy: 0.9794 - val_loss: 0.1919\n",
      "Epoch 6/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.9694 - loss: 0.2787 - val_accuracy: 0.9889 - val_loss: 0.1171\n",
      "Epoch 7/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.9798 - loss: 0.1883 - val_accuracy: 0.9955 - val_loss: 0.0706\n",
      "Epoch 8/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.9870 - loss: 0.1259 - val_accuracy: 0.9986 - val_loss: 0.0410\n",
      "Epoch 9/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.9921 - loss: 0.0854 - val_accuracy: 0.9998 - val_loss: 0.0223\n",
      "Epoch 10/10\n",
      "\u001b[1m1387/1387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 73ms/step - accuracy: 0.9959 - loss: 0.0561 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "MODEL_WEIGHTS = \"/kaggle/working/model_trans_weights.weights.h5aaa\"\n",
    "\n",
    "\n",
    "if os.path.exists(MODEL_WEIGHTS):\n",
    "    transformer.load_weights(MODEL_WEIGHTS)\n",
    "\n",
    "else:\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "\n",
    "    es = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = transformer.fit(\n",
    "        [encoder_input_data, decoder_input_data],\n",
    "        decoder_target_data,\n",
    "        validation_data=([encoder_input_val, decoder_input_val], decoder_target_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[es]\n",
    "    )\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    #transformer.save_weights(MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3cf328",
   "metadata": {
    "papermill": {
     "duration": 0.58517,
     "end_time": "2025-11-10T17:02:28.611705",
     "exception": false,
     "start_time": "2025-11-10T17:02:28.026535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In text summarization, token-level accuracy can be misleading because it only measures whether each predicted token matches the ground truth at the same position. It does not capture semantic meaning, fluency, word order, or relevance, and it can be inflated by common tokens like padding or start/end markers. A model can have high accuracy while producing poor summaries. Better evaluation uses metrics like ROUGE-1, ROUGE-2, and ROUGE-L, which measure overlap of unigrams, bigrams, and longest common subsequences between generated and reference summaries. During training, it is better to monitor validation loss and evaluate summaries qualitatively or with ROUGE rather than relying on token accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db9ac30",
   "metadata": {
    "papermill": {
     "duration": 0.639304,
     "end_time": "2025-11-10T17:02:29.880482",
     "exception": false,
     "start_time": "2025-11-10T17:02:29.241178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d869a6",
   "metadata": {
    "papermill": {
     "duration": 0.636073,
     "end_time": "2025-11-10T17:02:31.093895",
     "exception": false,
     "start_time": "2025-11-10T17:02:30.457822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note importanti:\n",
    "\n",
    "Look-ahead mask a inference non serve se generi un token alla volta (greedy decoding step-by-step).\n",
    "\n",
    "Padding mask dell’encoder serve al decoder per ignorare i pad token dell’input.\n",
    "\n",
    "Quando fai l’inference dovrai generare token uno per uno, aggiornando dec_input_inf ad ogni step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3832b262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:02:32.304412Z",
     "iopub.status.busy": "2025-11-10T17:02:32.303668Z",
     "iopub.status.idle": "2025-11-10T17:02:34.625131Z",
     "shell.execute_reply": "2025-11-10T17:02:34.624502Z"
    },
    "papermill": {
     "duration": 2.950651,
     "end_time": "2025-11-10T17:02:34.626491",
     "exception": false,
     "start_time": "2025-11-10T17:02:31.675840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# Encoder\n",
    "# Encoder inference model\n",
    "enc_input = Input(shape=(max_text_len,), name=\"encoder_input\")\n",
    "encoder_layer_obj = Encoder(num_layers, d_model, num_heads, dff, x_voc_size, max_text_len, dropout_rate)\n",
    "enc_output = encoder_layer_obj(enc_input, training=False)\n",
    "encoder_model = Model(enc_input, enc_output)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "dec_input_inf = Input(shape=(None,), name=\"decoder_input\")                  # sequenza parziale\n",
    "enc_out_inf_input = Input(shape=(max_text_len, d_model), name=\"encoder_output\")  # output encoder\n",
    "\n",
    "decoder_layer_inf = Decoder(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    vocab_size=y_voc_size,\n",
    "    max_len=max_summary_len,\n",
    "    dropout_rate=dropout_rate\n",
    ")\n",
    "\n",
    "\n",
    "dec_output_inf = decoder_layer_inf(dec_input_inf, enc_out_inf_input, training=False)\n",
    "\n",
    "\n",
    "final_logits = transformer.layers[-1](dec_output_inf)\n",
    "\n",
    "decoder_model = Model([dec_input_inf, enc_out_inf_input], final_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c22713ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:02:35.853190Z",
     "iopub.status.busy": "2025-11-10T17:02:35.852912Z",
     "iopub.status.idle": "2025-11-10T17:02:35.859364Z",
     "shell.execute_reply": "2025-11-10T17:02:35.858680Z"
    },
    "papermill": {
     "duration": 0.586541,
     "end_time": "2025-11-10T17:02:35.860519",
     "exception": false,
     "start_time": "2025-11-10T17:02:35.273978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_summary(article_seq, encoder_model, decoder_model, y_tokenizer, max_summary_len):\n",
    "    article_seq_batch = article_seq[np.newaxis, :]  # batch=1\n",
    "    encoder_output = encoder_model.predict(article_seq_batch)  # (1, seq_len, d_model)\n",
    "\n",
    "    # Se encoder_model ritorna tuple (enc_out, mask)\n",
    "    if isinstance(encoder_output, list) or isinstance(encoder_output, tuple):\n",
    "        enc_out = encoder_output[0]\n",
    "    else:\n",
    "        enc_out = encoder_output\n",
    "\n",
    "    # Crea maschera batch=1\n",
    "    enc_pad_mask = create_padding_mask(article_seq_batch)  # (1, seq_len)\n",
    "\n",
    "    sos = y_tokenizer.word_index[\"sostok\"]\n",
    "    eos = y_tokenizer.word_index[\"eostok\"]\n",
    "    summary_tokens = [sos]\n",
    "\n",
    "    for i in range(max_summary_len):\n",
    "        dec_input = np.array(summary_tokens)[np.newaxis, :]  # (1, cur_len)\n",
    "        logits = decoder_model.predict([dec_input, enc_out], verbose=0)\n",
    "        next_token = np.argmax(logits[0, -1, :])\n",
    "        summary_tokens.append(next_token)\n",
    "        if next_token == eos:\n",
    "            break\n",
    "\n",
    "    inv_tokenizer = {v: k for k, v in y_tokenizer.word_index.items()}\n",
    "    summary_words = [inv_tokenizer.get(t, \"\") for t in summary_tokens if t not in [sos, 0]]\n",
    "    summary_text = \" \".join(summary_words)\n",
    "    return summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b28727b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:02:37.069708Z",
     "iopub.status.busy": "2025-11-10T17:02:37.068864Z",
     "iopub.status.idle": "2025-11-10T17:02:37.077466Z",
     "shell.execute_reply": "2025-11-10T17:02:37.076759Z"
    },
    "papermill": {
     "duration": 0.587793,
     "end_time": "2025-11-10T17:02:37.078496",
     "exception": false,
     "start_time": "2025-11-10T17:02:36.490703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beam_search_summary(article_seq, encoder_model, decoder_model, y_tokenizer, max_summary_len, beam_width=3, length_penalty=0.7):\n",
    "    sos = y_tokenizer.word_index[\"sostok\"]\n",
    "    eos = y_tokenizer.word_index[\"eostok\"]\n",
    "\n",
    "    # Encode input\n",
    "    article_seq_batch = article_seq[np.newaxis, :]\n",
    "    enc_out = encoder_model.predict(article_seq_batch)\n",
    "    enc_pad_mask = create_padding_mask(article_seq_batch)\n",
    "\n",
    "    # Beam: list of tuples (sequence, score)\n",
    "    sequences = [([sos], 0.0)]\n",
    "\n",
    "    for _ in range(max_summary_len):\n",
    "        all_candidates = []\n",
    "        for seq, score in sequences:\n",
    "            if seq[-1] == eos:\n",
    "                all_candidates.append((seq, score))\n",
    "                continue\n",
    "\n",
    "            dec_input = np.array(seq)[np.newaxis, :]\n",
    "            # Pass encoder mask\n",
    "            logits = decoder_model.predict([dec_input, enc_out], verbose=0)\n",
    "            log_probs = tf.nn.log_softmax(logits[0, -1, :]).numpy()\n",
    "\n",
    "            # Expand with all tokens\n",
    "            for token_id, log_p in enumerate(log_probs):\n",
    "                # Optional: prevent immediate repetition\n",
    "                if len(seq) > 1 and seq[-1] == token_id:\n",
    "                    continue\n",
    "                new_seq = seq + [token_id]\n",
    "                # Apply length penalty\n",
    "                new_score = (score + log_p) / (len(new_seq) ** length_penalty)\n",
    "                all_candidates.append((new_seq, new_score))\n",
    "\n",
    "        # Keep top-k\n",
    "        sequences = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)[:beam_width]\n",
    "\n",
    "        # Stop if all beams ended\n",
    "        if all(seq[-1] == eos for seq, _ in sequences):\n",
    "            break\n",
    "\n",
    "    best_seq = sequences[0][0]\n",
    "    inv_tokenizer = {v: k for k, v in y_tokenizer.word_index.items()}\n",
    "    summary_words = [inv_tokenizer.get(t, \"\") for t in best_seq if t not in [sos, 0]]\n",
    "    return \" \".join(summary_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f254f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T17:02:38.343988Z",
     "iopub.status.busy": "2025-11-10T17:02:38.343190Z",
     "iopub.status.idle": "2025-11-10T17:03:00.457809Z",
     "shell.execute_reply": "2025-11-10T17:03:00.456874Z"
    },
    "papermill": {
     "duration": 22.753983,
     "end_time": "2025-11-10T17:03:00.459101",
     "exception": false,
     "start_time": "2025-11-10T17:02:37.705118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Original article:\n",
      " a thai woman whose husband broadcast the murder of their 11 month old daughter live on facebook before committing suicide has defended the social media major i am not angry at facebook or blaming them on this i understand that people shared the video because they were outraged she said facebook failed to take the video down for about 24 hours\n",
      "\n",
      "Real summary:\n",
      " woman defends facebook after husband kills kid on live video\n",
      "\n",
      "Generated summary: city bans court let bans kills being space run life kills suicide kills sale kills\n",
      "\n",
      "Generated beam search summary: bans court stops launches when leave go he being hospital driving leave kills new him\n"
     ]
    }
   ],
   "source": [
    "article_seq = x_val[0]\n",
    "real_summary_seq = y_val[0] \n",
    "\n",
    "generated_summary = generate_summary(article_seq, encoder_model, decoder_model, y_tokenizer, max_summary_len=15)\n",
    "beam_summary = beam_search_summary(article_seq, encoder_model, decoder_model, y_tokenizer, max_summary_len=15)\n",
    "\n",
    "\n",
    "inv_tokenizer = {v: k for k, v in y_tokenizer.word_index.items()}\n",
    "\n",
    "real_summary_text = \" \".join([inv_tokenizer.get(t, \"\") for t in real_summary_seq if t not in [0, y_tokenizer.word_index[\"sostok\"], y_tokenizer.word_index[\"eostok\"]]])\n",
    "\n",
    "x_inv_tokenizer = {v: k for k, v in x_tokenizer.word_index.items()}  # se hai un tokenizer per gli articoli\n",
    "article_text = \" \".join([x_inv_tokenizer.get(t, \"\") for t in article_seq if t != 0])\n",
    "\n",
    "print(\"Original article:\\n\", article_text)\n",
    "print(\"\\nReal summary:\\n\", real_summary_text)\n",
    "print(\"\\nGenerated summary:\", generated_summary)\n",
    "print(\"\\nGenerated beam search summary:\", beam_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7548aef",
   "metadata": {
    "papermill": {
     "duration": 0.634064,
     "end_time": "2025-11-10T17:03:01.675823",
     "exception": false,
     "start_time": "2025-11-10T17:03:01.041759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generated summary: ripete continuamente parole (cannot cannot cannot, power power power…) → questo è un loop di ripetizione, tipico dei modelli seq2seq che non hanno abbastanza regolarizzazione sulla generazione.\n",
    "\n",
    "Generated beam search summary: testo quasi completamente fuori tema → indica che il modello non ha appreso bene il contenuto semantico e il beam search amplifica le frasi che appaiono più “probabili” a livello di token, ma non corrette.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52956eab",
   "metadata": {
    "papermill": {
     "duration": 0.676521,
     "end_time": "2025-11-10T17:03:02.937384",
     "exception": false,
     "start_time": "2025-11-10T17:03:02.260863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credits\n",
    "\n",
    "- **\"Implementing Seq2Seq Models for Text Summarization With Keras\"**  \n",
    "  *by Samhita Alla* "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1895,
     "sourceId": 791838,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 477297,
     "modelInstanceId": 461540,
     "sourceId": 614196,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 496233,
     "modelInstanceId": 480580,
     "sourceId": 637458,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1160.953675,
   "end_time": "2025-11-10T17:03:06.991337",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-10T16:43:46.037662",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
