{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447d3969",
   "metadata": {
    "papermill": {
     "duration": 0.006089,
     "end_time": "2025-10-20T11:26:59.782938",
     "exception": false,
     "start_time": "2025-10-20T11:26:59.776849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project Overview\n",
    "\n",
    "This project focuses on **text summarization** using two approaches: a traditional **Seq2Seq model** with LSTM and a **Transformer-based model**. The goal is to see how each model performs and understand the difference between step-by-step sequence processing and attention-based processing.\n",
    "\n",
    "### Steps in the Project\n",
    "1. **Dataset Preparation**  \n",
    "   - Load the XSum dataset with articles and summaries.  \n",
    "   - Tokenize and pad sequences so they can be fed into the models.\n",
    "\n",
    "2. **Seq2Seq Model (LSTM)**  \n",
    "   - Build an encoder-decoder model without attention.\n",
    "   - Train it to generate summaries from the input articles.  \n",
    "\n",
    "3. **Transformer Model**  \n",
    "   - Build a Transformer-based encoder-decoder model.  \n",
    "   - Use self-attention to capture relationships between all tokens.  \n",
    "   - Train on the same dataset to generate summaries.\n",
    "\n",
    "4. **Comparison**  \n",
    "   - Compare the two models using metrics like ROUGE.  \n",
    "   - Look at differences in summary quality, speed, and how well they handle long sequences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c1c44",
   "metadata": {
    "papermill": {
     "duration": 0.004812,
     "end_time": "2025-10-20T11:26:59.793015",
     "exception": false,
     "start_time": "2025-10-20T11:26:59.788203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seq2Seq and Encoder-Decoder\n",
    "\n",
    "## What is a Seq2Seq Model\n",
    "A sequence-to-sequence (Seq2Seq) model is designed to take an input sequence and produce an output sequence. It’s widely used in tasks like machine translation, text summarization, and chatbots.\n",
    "\n",
    "**Example:**  \n",
    "Input: \"Hello, how are you?\"  \n",
    "Output: \"Ciao, come stai?\"\n",
    "\n",
    "---\n",
    "\n",
    "## Encoder-Decoder Architecture (Expanded)\n",
    "\n",
    "A typical Seq2Seq model has two main parts: the **encoder** and the **decoder**. The design allows the model to process sequences of variable length.  \n",
    "\n",
    "### Encoder\n",
    "The encoder reads the input sequence and compresses it into a set of hidden states or a context vector. This vector captures the important information from the input and has a fixed size, though it does not need to match the decoder's size. The hidden states can either be passed as a whole to the decoder or connected at every decoding step.  \n",
    "\n",
    "At each step, the encoder updates its hidden state based on the previous hidden state and the current input. In mathematical terms, for a simple RNN:\n",
    "\n",
    "$$\n",
    "H_t^{encoder} = \\phi(W_{HH} \\cdot H_{t-1}^{encoder} + W_{HX} \\cdot X_t)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $H_t^{encoder}$ = hidden state at time $t$ in the encoder  \n",
    "- $X_t$ = input at time $t$  \n",
    "- $W_{HH}$ = weight matrix connecting hidden states  \n",
    "- $W_{HX}$ = weight matrix connecting input to hidden states  \n",
    "- $\\phi$ = activation function (e.g., tanh or ReLU)\n",
    "\n",
    "---\n",
    "\n",
    "### Decoder\n",
    "The decoder generates the output sequence one token at a time. Its initial hidden state is set to the final hidden state of the encoder. For a simple RNN decoder:\n",
    "\n",
    "$$\n",
    "H_t^{decoder} = \\phi(W_{HH} \\cdot H_{t-1}^{decoder} + W_{HY} \\cdot Y_{t-1})\n",
    "$$\n",
    "\n",
    "The output at each step is computed as:\n",
    "\n",
    "$$\n",
    "Y_t = W_{HY} \\cdot H_t^{decoder}\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $H_t^{decoder}$ = hidden state at time $t$ in the decoder  \n",
    "- $Y_t$ = output at time $t$  \n",
    "- $W_{HY}$ = weight matrix connecting decoder hidden state to output  \n",
    "\n",
    "### Implementation Notes\n",
    "- Encoders and decoders are typically implemented with **RNNs, LSTMs, or GRUs**.  \n",
    "- The input and output vectors are of fixed size, but the encoder and decoder can have different hidden dimensions.  \n",
    "- During training, **teacher forcing** is often used, providing the correct previous token to the decoder instead of its own prediction.  \n",
    "\n",
    "---\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "Before feeding text into a Seq2Seq or Transformer model, the raw text must be converted into numerical form.  \n",
    "This is done through **tokenization**, which splits text into smaller units (tokens) such as words or subwords.  \n",
    "\n",
    "Each token is then mapped to a unique integer using a **vocabulary** built from the dataset.  \n",
    "The model processes these integers rather than the raw text.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Input text: `\"Transformers improve summarization.\"`  \n",
    "Tokens: `[\"transformers\", \"improve\", \"summarization\", \".\"]`  \n",
    "Token IDs: `[201, 57, 1342, 4]`\n",
    "\n",
    "### Why Tokenization Matters\n",
    "- Converts variable-length text into consistent, model-readable sequences.  \n",
    "- Helps capture word frequency and context relationships.  \n",
    "- Reduces vocabulary size when using subword tokenization (e.g., Byte Pair Encoding).  \n",
    "\n",
    "In this project, tokenization is part of preprocessing and includes:\n",
    "- **Lowercasing** the text  \n",
    "- **Removing special characters and URLs**  \n",
    "- **Splitting into tokens by spaces**  \n",
    "- Adding **start (`sostok`)** and **end (`eostok`)** tokens to mark summary boundaries  \n",
    "\n",
    "After tokenization, sequences will later be converted to integer IDs, padded or truncated to a fixed length\n",
    "\n",
    "---\n",
    "\n",
    "# Transformers\n",
    "Transformers can be seen as an evolution of Seq2Seq models. Instead of processing sequences step by step like LSTMs or GRUs, they rely entirely on **attention mechanisms** to process all tokens in parallel and capture relationships between them.\n",
    "\n",
    "### Attention in Transformers\n",
    "Attention is the core mechanism that allows Transformers to focus on relevant parts of the input sequence when producing a representation for each token. It works by comparing each token to all others and weighting them according to importance.\n",
    "\n",
    "#### How Attention Works\n",
    "Each token in the sequence is represented by three vectors:\n",
    "- **Query (Q):** what this token is looking for  \n",
    "- **Key (K):** what information this token contains  \n",
    "- **Value (V):** the actual information of the token  \n",
    "\n",
    "The attention score between two tokens is computed as the similarity between the Query of one token and the Key of another. This determines how much attention one token should pay to another. Mathematically, the attention weights are computed using a scaled dot-product:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\Big(\\frac{QK^T}{\\sqrt{d_k}}\\Big) V\n",
    "$$\n",
    "\n",
    "Where $d_k$ is the dimensionality of the Key vectors.\n",
    "\n",
    "- The **softmax** ensures that the weights sum to 1.  \n",
    "- Each token’s output is a weighted sum of all Value vectors, allowing it to incorporate context from the entire sequence.\n",
    "\n",
    "#### Multi-Head Attention\n",
    "Instead of computing attention just once, Transformers use **multiple attention heads** in parallel. Each head can learn to focus on different types of relationships, such as:\n",
    "- Syntactic relationships (e.g., subject-verb connections)  \n",
    "- Semantic relationships (e.g., synonyms or related concepts)  \n",
    "\n",
    "The outputs of all heads are concatenated and projected to form the final representation for each token.\n",
    "\n",
    "#### Intuition\n",
    "Imagine reading a sentence and highlighting all the words that are important for understanding each token. Each word “attends” to other words in the sentence that matter most for its meaning. Multi-head attention lets the model do this from multiple perspectives simultaneously.\n",
    "\n",
    "### Key Components of Transformers\n",
    "- **Encoder-Decoder Structure:** Like Seq2Seq models, Transformers have an encoder that processes the input and a decoder that generates the output. Both use layers of self-attention and feed-forward networks.  \n",
    "- **Positional Encoding:** Since Transformers don’t process tokens sequentially, they add positional information so the model knows the order of tokens.  \n",
    "- **Feed-Forward Layers:** After attention, each token passes through fully connected layers for additional transformation.\n",
    "\n",
    "### Advantages over LSTM/GRU Seq2Seq\n",
    "- Processes sequences **in parallel**, speeding up training.  \n",
    "- Handles **long sequences** more effectively with attention.  \n",
    "- Captures **complex relationships** between tokens regardless of distance.  \n",
    "- Scales easily to **very deep models** and large datasets.\n",
    "\n",
    "### Use Cases\n",
    "Transformers are the backbone of many state-of-the-art models for tasks such as:\n",
    "- Machine translation (e.g., T5, MarianMT)  \n",
    "- Text summarization (e.g., BART, Pegasus)  \n",
    "- Question answering and chatbots (e.g., GPT, BERT-based models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185a9a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:26:59.804560Z",
     "iopub.status.busy": "2025-10-20T11:26:59.804293Z",
     "iopub.status.idle": "2025-10-20T11:26:59.810615Z",
     "shell.execute_reply": "2025-10-20T11:26:59.809925Z"
    },
    "papermill": {
     "duration": 0.012804,
     "end_time": "2025-10-20T11:26:59.811799",
     "exception": false,
     "start_time": "2025-10-20T11:26:59.798995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e6d5a",
   "metadata": {
    "papermill": {
     "duration": 0.003935,
     "end_time": "2025-10-20T11:26:59.819931",
     "exception": false,
     "start_time": "2025-10-20T11:26:59.815996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "Prepare and clean the dataset for the summarization model:\n",
    "\n",
    "- **Load datasets:** Read two CSV files containing news articles and their summaries.\n",
    "- **Combine datasets:** Merge datasets while selecting relevant `text` and `summary` columns.\n",
    "- **Text cleaning:**  \n",
    "  - Convert text to lowercase.  \n",
    "  - Remove special characters.  \n",
    "  - Replace URLs with domain names.  \n",
    "  - Reduce multiple spaces.\n",
    "- **Tokenization:** Split cleaned text into tokens (words) and add `_START_` and `_END_` tokens for summaries.\n",
    "- **Handle missing values:** Drop rows with missing `text` values.\n",
    "- **Analyze sequence lengths:** Calculate word counts for texts and summaries.\n",
    "- **Limit sequence lengths:** Restrict `text` to 100 words and `summary` to 15 words.\n",
    "- **Add model tokens:** Prepend `sostok` and append `eostok` to all summaries to mark start and end for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f4f3a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:26:59.828773Z",
     "iopub.status.busy": "2025-10-20T11:26:59.828576Z",
     "iopub.status.idle": "2025-10-20T11:27:02.341552Z",
     "shell.execute_reply": "2025-10-20T11:27:02.340668Z"
    },
    "papermill": {
     "duration": 2.518876,
     "end_time": "2025-10-20T11:27:02.342813",
     "exception": false,
     "start_time": "2025-10-20T11:26:59.823937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4514, 6)\n",
      "(98401, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "summary = pd.read_csv('/kaggle/input/news-summary/news_summary.csv', encoding='iso-8859-1')\n",
    "summary_more = pd.read_csv('/kaggle/input/news-summary/news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "print(summary.shape)\n",
    "print(summary_more.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b6b8ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:02.352386Z",
     "iopub.status.busy": "2025-10-20T11:27:02.352166Z",
     "iopub.status.idle": "2025-10-20T11:27:02.371316Z",
     "shell.execute_reply": "2025-10-20T11:27:02.370643Z"
    },
    "papermill": {
     "duration": 0.025162,
     "end_time": "2025-10-20T11:27:02.372360",
     "exception": false,
     "start_time": "2025-10-20T11:27:02.347198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in offices order</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/rakshabandhan-compulsory-in-daman-and-diu-women-employees-to-tie-rakhis-to-male-colleagues/story-E5h5U1ZDJii5zFpLXWRkhJ.html?utm_source=inshorts&amp;utm_medium=referral&amp;utm_campaign=fullarticle</td>\n",
       "      <td>The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.</td>\n",
       "      <td>The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media.The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace.?It has been decided to celebrate the festival of Rakshabandhan on August 7. In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said.To ensure that no one skipped office, an attendance report was to be sent to the government the next evening.The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart. The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms.?The circular is ridiculous. There are sensitivities involved. How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day. She refused to be identified.The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said.Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies.In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?. The RSS is the ideological parent of the ruling BJP.Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers. A year before, all cabinet ministers were asked to go to their constituencies for the festival.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                  date  \\\n",
       "0  Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "\n",
       "                                                      headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in offices order   \n",
       "\n",
       "                                                                                                                                                                                                                                 read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/rakshabandhan-compulsory-in-daman-and-diu-women-employees-to-tie-rakhis-to-male-colleagues/story-E5h5U1ZDJii5zFpLXWRkhJ.html?utm_source=inshorts&utm_medium=referral&utm_campaign=fullarticle    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "0  The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ctext  \n",
       "0  The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media.The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace.?It has been decided to celebrate the festival of Rakshabandhan on August 7. In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said.To ensure that no one skipped office, an attendance report was to be sent to the government the next evening.The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart. The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms.?The circular is ridiculous. There are sensitivities involved. How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day. She refused to be identified.The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said.Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies.In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?. The RSS is the ideological parent of the ruling BJP.Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers. A year before, all cabinet ministers were asked to go to their constituencies for the festival.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4e1d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:02.382991Z",
     "iopub.status.busy": "2025-10-20T11:27:02.382784Z",
     "iopub.status.idle": "2025-10-20T11:27:02.388620Z",
     "shell.execute_reply": "2025-10-20T11:27:02.388023Z"
    },
    "papermill": {
     "duration": 0.012769,
     "end_time": "2025-10-20T11:27:02.389715",
     "exception": false,
     "start_time": "2025-10-20T11:27:02.376946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "summary_more.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10feeb98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:02.399705Z",
     "iopub.status.busy": "2025-10-20T11:27:02.399506Z",
     "iopub.status.idle": "2025-10-20T11:27:02.441641Z",
     "shell.execute_reply": "2025-10-20T11:27:02.441010Z"
    },
    "papermill": {
     "duration": 0.048521,
     "end_time": "2025-10-20T11:27:02.442838",
     "exception": false,
     "start_time": "2025-10-20T11:27:02.394317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102915, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.   \n",
       "1                              Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.   \n",
       "\n",
       "                                                             summary  \n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike  \n",
       "1       Delhi techie wins free food from Swiggy for one year on CRED  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summary.iloc[:, 0:6]\n",
    "summary_more = summary_more.iloc[:, 0:2]\n",
    "\n",
    "# To increase the intake of possible text values to build a reliable model\n",
    "summary['text'] = (\n",
    "    summary['author'] + ' ' +\n",
    "    summary['date'] + ' ' +\n",
    "    summary['read_more'] + ' ' +\n",
    "    summary['text'] + ' ' +\n",
    "    summary['ctext']\n",
    ")\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['text'] = pd.concat([summary_more['text'], summary['text']], ignore_index=True)\n",
    "df['summary'] = pd.concat([summary_more['headlines'], summary['headlines']], ignore_index=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23d62d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:02.453518Z",
     "iopub.status.busy": "2025-10-20T11:27:02.453293Z",
     "iopub.status.idle": "2025-10-20T11:27:06.585121Z",
     "shell.execute_reply": "2025-10-20T11:27:06.584588Z"
    },
    "papermill": {
     "duration": 4.138733,
     "end_time": "2025-10-20T11:27:06.586584",
     "exception": false,
     "start_time": "2025-10-20T11:27:02.447851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    - converts to lowercase\n",
    "    - removes special characters\n",
    "    - replaces URLs with domain names\n",
    "    - reduces multiple spaces\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'https?://([^/\\s]+).*', r'\\1', text)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Tokenization: split text by spaces\n",
    "def tokenize_texts(texts):\n",
    "    return [' '.join(clean_text(t).split()) for t in texts]\n",
    "\n",
    "\n",
    "processed_text = tokenize_texts(df['text'])\n",
    "processed_summary = ['_START_ ' + s + ' _END_' for s in tokenize_texts(df['summary'])]\n",
    "\n",
    "df['cleaned_text'] = pd.Series(processed_text)\n",
    "df['cleaned_summary'] = pd.Series(processed_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf2fb69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:06.597194Z",
     "iopub.status.busy": "2025-10-20T11:27:06.596984Z",
     "iopub.status.idle": "2025-10-20T11:27:06.664835Z",
     "shell.execute_reply": "2025-10-20T11:27:06.664006Z"
    },
    "papermill": {
     "duration": 0.07431,
     "end_time": "2025-10-20T11:27:06.666078",
     "exception": false,
     "start_time": "2025-10-20T11:27:06.591768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN dropped: 118\n",
      "(102797, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"NaN dropped: {df.isna().sum().sum()}\")\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a663976f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:06.677236Z",
     "iopub.status.busy": "2025-10-20T11:27:06.676580Z",
     "iopub.status.idle": "2025-10-20T11:27:06.683892Z",
     "shell.execute_reply": "2025-10-20T11:27:06.683297Z"
    },
    "papermill": {
     "duration": 0.013763,
     "end_time": "2025-10-20T11:27:06.684971",
     "exception": false,
     "start_time": "2025-10-20T11:27:06.671208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit b s pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad s 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad s online power learning has powered 3 lakh careers</td>\n",
       "      <td>_START_ upgrad learner switches to career in ml al with 90 salary hike _END_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>kunal shah s credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more</td>\n",
       "      <td>_START_ delhi techie wins free food from swiggy for one year on cred _END_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.   \n",
       "1                              Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.   \n",
       "\n",
       "                                                             summary  \\\n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1       Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                       cleaned_text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit b s pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad s 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad s online power learning has powered 3 lakh careers   \n",
       "1                                  kunal shah s credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more   \n",
       "\n",
       "                                                                cleaned_summary  \n",
       "0  _START_ upgrad learner switches to career in ml al with 90 salary hike _END_  \n",
       "1    _START_ delhi techie wins free food from swiggy for one year on cred _END_  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f5aa084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:06.695317Z",
     "iopub.status.busy": "2025-10-20T11:27:06.695143Z",
     "iopub.status.idle": "2025-10-20T11:27:07.565394Z",
     "shell.execute_reply": "2025-10-20T11:27:07.564783Z"
    },
    "papermill": {
     "duration": 0.876814,
     "end_time": "2025-10-20T11:27:07.566732",
     "exception": false,
     "start_time": "2025-10-20T11:27:06.689918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_count = []\n",
    "summary_count = []\n",
    "\n",
    "for sent in df['cleaned_text']:\n",
    "    text_count.append(len(sent.split()))\n",
    "    \n",
    "for sent in df['cleaned_summary']:\n",
    "    summary_count.append(len(sent.split()))\n",
    "\n",
    "graph_df = pd.DataFrame() \n",
    "\n",
    "graph_df['text'] = text_count\n",
    "graph_df['summary'] = summary_count\n",
    "\n",
    "graph_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ab2cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:07.580837Z",
     "iopub.status.busy": "2025-10-20T11:27:07.580212Z",
     "iopub.status.idle": "2025-10-20T11:27:07.939272Z",
     "shell.execute_reply": "2025-10-20T11:27:07.938655Z"
    },
    "papermill": {
     "duration": 0.366905,
     "end_time": "2025-10-20T11:27:07.940417",
     "exception": false,
     "start_time": "2025-10-20T11:27:07.573512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of texts with less than 100 words : 0.9988715623996809\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in df['cleaned_text']:\n",
    "    if len(i.split()) <= 100:\n",
    "        cnt = cnt + 1\n",
    "print(f\"Percentage of texts with less than 100 words : {cnt / len(df['cleaned_text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e28dc1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:07.951937Z",
     "iopub.status.busy": "2025-10-20T11:27:07.951753Z",
     "iopub.status.idle": "2025-10-20T11:27:09.394307Z",
     "shell.execute_reply": "2025-10-20T11:27:09.393472Z"
    },
    "papermill": {
     "duration": 1.449835,
     "end_time": "2025-10-20T11:27:09.395698",
     "exception": false,
     "start_time": "2025-10-20T11:27:07.945863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit b s pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad s 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad s online power learning has powered 3 lakh careers</td>\n",
       "      <td>sostok _START_ upgrad learner switches to career in ml al with 90 salary hike _END_ eostok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for one year on CRED</td>\n",
       "      <td>kunal shah s credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more</td>\n",
       "      <td>sostok _START_ delhi techie wins free food from swiggy for one year on cred _END_ eostok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.   \n",
       "1                              Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.   \n",
       "\n",
       "                                                             summary  \\\n",
       "0  upGrad learner switches to career in ML & Al with 90% salary hike   \n",
       "1       Delhi techie wins free food from Swiggy for one year on CRED   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                       cleaned_text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit b s pg program in machine learning and artificial intelligence was a sr systems engineer at infosys with almost 5 years of work experience the program and upgrad s 360 degree career support helped him transition to a data scientist at tech mahindra with 90 salary hike upgrad s online power learning has powered 3 lakh careers   \n",
       "1                                  kunal shah s credit card bill payment platform cred gave users a chance to win free food from swiggy for one year pranav kaushik a delhi techie bagged this reward after spending 2000 cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more   \n",
       "\n",
       "                                                                              cleaned_summary  \n",
       "0  sostok _START_ upgrad learner switches to career in ml al with 90 salary hike _END_ eostok  \n",
       "1    sostok _START_ delhi techie wins free food from swiggy for one year on cred _END_ eostok  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_text_len = 100\n",
    "max_summary_len = 15\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_text'].astype(str)\n",
    "df['cleaned_summary'] = df['cleaned_summary'].astype(str)\n",
    "\n",
    "mask = (df['cleaned_text'].str.split().str.len() <= max_text_len) & \\\n",
    "       (df['cleaned_summary'].str.split().str.len() <= max_summary_len)\n",
    "\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# Add start and end tokens to each summary\n",
    "df['cleaned_summary'] = df['cleaned_summary'].apply(lambda x: 'sostok ' + x + ' eostok')\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d95e45",
   "metadata": {
    "papermill": {
     "duration": 0.006096,
     "end_time": "2025-10-20T11:27:09.408953",
     "exception": false,
     "start_time": "2025-10-20T11:27:09.402857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Tokenization**\n",
    "\n",
    "This block prepares the text data for a sequence-to-sequence model:\n",
    "\n",
    "- **Split dataset**: Separates `text` and `summary` into training and validation sets to evaluate model performance on unseen data.  \n",
    "- **Initialize tokenizers**: Converts words into integer indices, which neural networks can process.  \n",
    "- **Analyze rare words**: Computes the percentage of words appearing less than `thresh` times to identify infrequent words that might add noise.  \n",
    "- **Limit vocabulary to frequent words**: Reduces vocabulary size by ignoring rare words, which improves training efficiency and prevents overfitting.  \n",
    "- **Convert texts to sequences**: Maps each word in the texts to its corresponding integer index.  \n",
    "- **Pad sequences**: Ensures all sequences have the same length, necessary for batch processing in neural networks.  \n",
    "- **Compute final vocabulary size**: Includes the padding token to correctly define the input dimension for the model embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c154856a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:09.421448Z",
     "iopub.status.busy": "2025-10-20T11:27:09.421190Z",
     "iopub.status.idle": "2025-10-20T11:27:27.530692Z",
     "shell.execute_reply": "2025-10-20T11:27:27.529902Z"
    },
    "papermill": {
     "duration": 18.117302,
     "end_time": "2025-10-20T11:27:27.532151",
     "exception": false,
     "start_time": "2025-10-20T11:27:09.414849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 11:27:12.049694: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760959632.256539      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760959632.327894      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    np.array(df[\"cleaned_text\"]),\n",
    "    np.array(df[\"cleaned_summary\"]),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd17fa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:27.544785Z",
     "iopub.status.busy": "2025-10-20T11:27:27.544121Z",
     "iopub.status.idle": "2025-10-20T11:27:27.573715Z",
     "shell.execute_reply": "2025-10-20T11:27:27.573062Z"
    },
    "papermill": {
     "duration": 0.036722,
     "end_time": "2025-10-20T11:27:27.574818",
     "exception": false,
     "start_time": "2025-10-20T11:27:27.538096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in X vocabulary: 61.60%\n",
      "% of rare words in Y vocabulary: 60.97%\n"
     ]
    }
   ],
   "source": [
    "thresh = 5\n",
    "\n",
    "def rare_word_stats(tokenizer, thresh):\n",
    "    \"\"\"Return total and rare word counts for a given tokenizer.\"\"\"\n",
    "    total_cnt = len(tokenizer.word_counts)\n",
    "    rare_cnt = sum(1 for word, count in tokenizer.word_counts.items() if count < thresh)\n",
    "    return total_cnt, rare_cnt\n",
    "\n",
    "\n",
    "x_tot_cnt, x_cnt = rare_word_stats(x_tokenizer, thresh)\n",
    "y_tot_cnt, y_cnt = rare_word_stats(y_tokenizer, thresh)\n",
    "\n",
    "print(f\"% of rare words in X vocabulary: {(x_cnt / x_tot_cnt) * 100:.2f}%\")\n",
    "print(f\"% of rare words in Y vocabulary: {(y_cnt / y_tot_cnt) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1645abe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:27.586668Z",
     "iopub.status.busy": "2025-10-20T11:27:27.586436Z",
     "iopub.status.idle": "2025-10-20T11:27:35.589450Z",
     "shell.execute_reply": "2025-10-20T11:27:35.588597Z"
    },
    "papermill": {
     "duration": 8.010238,
     "end_time": "2025-10-20T11:27:35.590614",
     "exception": false,
     "start_time": "2025-10-20T11:27:27.580376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 29238\n",
      "Size of vocabulary in Y = 13003\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizers considering only frequent words\n",
    "x_tokenizer = Tokenizer(num_words = x_tot_cnt - x_cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=y_tot_cnt-y_cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "x_train_seq = x_tokenizer.texts_to_sequences(x_train) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "# Pad sequences\n",
    "x_train = pad_sequences(x_train_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "y_train = pad_sequences(y_train_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Vocab. size (+1 for padding token)\n",
    "x_voc_size = x_tokenizer.num_words + 1\n",
    "y_voc_size = y_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc_size))\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8661259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:35.603002Z",
     "iopub.status.busy": "2025-10-20T11:27:35.602781Z",
     "iopub.status.idle": "2025-10-20T11:27:35.648529Z",
     "shell.execute_reply": "2025-10-20T11:27:35.647881Z"
    },
    "papermill": {
     "duration": 0.053465,
     "end_time": "2025-10-20T11:27:35.649906",
     "exception": false,
     "start_time": "2025-10-20T11:27:35.596441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally remove from the dataset empty summaries that contain only the 'START' and 'END' tokens\n",
    "\n",
    "x_train = x_train[np.sum(y_train != 0, axis=1) > 2]\n",
    "y_train = y_train[np.sum(y_train != 0, axis=1) > 2]\n",
    "\n",
    "x_val = x_val[np.sum(y_val != 0, axis=1) > 2]\n",
    "y_val = y_val[np.sum(y_val != 0, axis=1) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d6041",
   "metadata": {
    "papermill": {
     "duration": 0.005287,
     "end_time": "2025-10-20T11:27:35.661405",
     "exception": false,
     "start_time": "2025-10-20T11:27:35.656118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Seq2seq model using LSTM**\n",
    "\n",
    "### Encoder-Decoder Architecture with LSTM\n",
    "\n",
    "During training, the model takes **two inputs**:  \n",
    "1. The encoder input (`text`) – the original text sequence.  \n",
    "2. The decoder input (`summary`) – the summary shifted by one token (so that the model learns to predict the next word).  \n",
    "\n",
    "The **target output** is the summary sequence shifted forward by one token. The model learns to predict the next word in the summary based on the previous words. During inference, the trained model generates summaries one word at a time, using the previously predicted words as input.\n",
    "\n",
    "---\n",
    "\n",
    "**Encoder**  \n",
    "- The encoder accepts sequences of text with a fixed length (`max_text_len`).  \n",
    "- The text is first passed through an **Embedding layer** that maps each word index to a dense vector of size `(embedding_dim)`.  \n",
    "- The embedded sequence is then processed by **three stacked LSTM layers**:  \n",
    "  - Each layer outputs the **full sequence of hidden states** (for possible attention or stacking) and the **last hidden and cell states**.  \n",
    "  - The last hidden and cell states from the final LSTM are used to initialize the decoder.  \n",
    "- Stacking multiple LSTMs allows the encoder to **capture both local patterns and long-range dependencies** in the text.\n",
    "\n",
    "---\n",
    "\n",
    "**Decoder**  \n",
    "- The decoder input (shifted summary) is passed through an **Embedding layer** of size `(summary vocabulary size x embedding_dim)`.  \n",
    "- A single **LSTM** processes the embedded sequence, using the **encoder's last hidden and cell states** as its initial state.  \n",
    "- The LSTM output is passed through a **TimeDistributed Dense layer** with **softmax activation**, which predicts the probability of each word in the vocabulary at each time step.  \n",
    "\n",
    "This architecture ensures that the decoder can generate the summary step by step, **learning the sequence of words conditioned on the input text**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02158f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:35.673328Z",
     "iopub.status.busy": "2025-10-20T11:27:35.673104Z",
     "iopub.status.idle": "2025-10-20T11:27:37.926701Z",
     "shell.execute_reply": "2025-10-20T11:27:37.926073Z"
    },
    "papermill": {
     "duration": 2.261008,
     "end_time": "2025-10-20T11:27:37.927783",
     "exception": false,
     "start_time": "2025-10-20T11:27:35.666775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1760959656.403905      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,847,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,600,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,913,903</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">13003</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m200\u001b[0m)  │  \u001b[38;5;34m5,847,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m601,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m721,200\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │  \u001b[38;5;34m2,600,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m721,200\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m601,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,913,903\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m13003\u001b[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,006,903</span> (57.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,006,903\u001b[0m (57.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,006,903</span> (57.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,006,903\u001b[0m (57.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len, ))\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb = Embedding(x_voc_size, embedding_dim,\n",
    "                    trainable=True)(encoder_inputs)\n",
    "\n",
    "# Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_voc_size, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0.2)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978acd3",
   "metadata": {
    "papermill": {
     "duration": 0.005911,
     "end_time": "2025-10-20T11:27:37.940110",
     "exception": false,
     "start_time": "2025-10-20T11:27:37.934199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Training the model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c21b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:37.952767Z",
     "iopub.status.busy": "2025-10-20T11:27:37.952527Z",
     "iopub.status.idle": "2025-10-20T11:27:39.650390Z",
     "shell.execute_reply": "2025-10-20T11:27:39.649558Z"
    },
    "papermill": {
     "duration": 1.706388,
     "end_time": "2025-10-20T11:27:39.652357",
     "exception": false,
     "start_time": "2025-10-20T11:27:37.945969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_lstm = x_train\n",
    "x_val_lstm = x_val\n",
    "y_train_lstm = y_train\n",
    "y_val_lstm = y_val\n",
    "\n",
    "MODEL_INPUT_PATH = \"/kaggle/input/lstm-keras-summarization/keras/default/1/model_lstm.keras\" \n",
    "MODEL_PATH = \"/kaggle/working/model_lstm.keras\" \n",
    "\n",
    "# retrain the model\n",
    "if os.path.exists(MODEL_INPUT_PATH):\n",
    "    model = load_model(MODEL_INPUT_PATH)\n",
    "    history = None\n",
    "\n",
    "else:\n",
    "    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "    history = model.fit(\n",
    "        [x_train, y_train[:, :-1]],\n",
    "        y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n",
    "        epochs=50,\n",
    "        callbacks=[es],\n",
    "        batch_size=128,\n",
    "        validation_data=(\n",
    "            [x_val, y_val[:, :-1]],\n",
    "            y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623935e",
   "metadata": {
    "papermill": {
     "duration": 0.005817,
     "end_time": "2025-10-20T11:27:39.665016",
     "exception": false,
     "start_time": "2025-10-20T11:27:39.659199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Predict**\n",
    "\n",
    "Once the Seq2Seq model has been trained, we can use it to **generate summaries** for new input texts.  \n",
    "This stage is known as **inference**, the model no longer learns, but uses its learned parameters to predict the most likely output sequence (summary).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Preparing the Mapping Dictionaries\n",
    "Before generating predictions, we rebuild the word–token mappings from the tokenizers:\n",
    "- `reverse_x_word_index`: converts article tokens → words  \n",
    "- `reverse_y_word_index`: converts summary tokens → words  \n",
    "- `y_word_index`: converts summary words → tokens  \n",
    "\n",
    "These dictionaries let us translate between the model’s numeric predictions and readable text.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Building Inference Models\n",
    "During training, the encoder and decoder work together in a single model.  \n",
    "At inference time, we separate them:\n",
    "\n",
    "- The **encoder model** processes the input text once and produces context vectors (`encoder_outputs`, `state_h`, `state_c`) — a compressed representation of the input.  \n",
    "- The **decoder model** generates the summary **one word at a time**, taking as input the previous word and its previous internal states.\n",
    "\n",
    "This setup allows the decoder to iteratively predict each next token until the end-of-sequence marker (`eostok`) is reached.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. The Decoding Process\n",
    "The function `decode_sequence()` handles the actual text generation:\n",
    "\n",
    "1. **Encode the input sequence** using the encoder model to obtain its internal states.  \n",
    "2. **Initialize** the decoder with the special start token (`sostok`).  \n",
    "3. **Iteratively predict** the next word:\n",
    "   - Feed the previous word and the latest decoder states into the model.\n",
    "   - Pick the word with the highest probability (`argmax`).\n",
    "   - Stop when the `eostok` token is predicted or the maximum summary length is reached.\n",
    "4. **Concatenate** all predicted tokens into a readable summary.\n",
    "\n",
    "This process simulates how the model “writes” one word at a time, using its internal memory to maintain context.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Converting Sequences to Text\n",
    "Two helper functions make the predictions human-readable:\n",
    "- `seq2text()` converts numeric article sequences back into words.\n",
    "- `seq2summary()` converts numeric summary sequences back into words, excluding special tokens (`sostok`, `eostok`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e000cd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:39.677830Z",
     "iopub.status.busy": "2025-10-20T11:27:39.677580Z",
     "iopub.status.idle": "2025-10-20T11:27:39.680986Z",
     "shell.execute_reply": "2025-10-20T11:27:39.680473Z"
    },
    "papermill": {
     "duration": 0.010995,
     "end_time": "2025-10-20T11:27:39.681941",
     "exception": false,
     "start_time": "2025-10-20T11:27:39.670946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reverse_y_word_index: summary token → word\n",
    "# reverse_x_word_index: article token → word\n",
    "# y_word_index: summary word → token\n",
    "\n",
    "reverse_y_word_index = y_tokenizer.index_word\n",
    "reverse_x_word_index = x_tokenizer.index_word\n",
    "y_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "163d4cab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:39.694792Z",
     "iopub.status.busy": "2025-10-20T11:27:39.694586Z",
     "iopub.status.idle": "2025-10-20T11:27:39.704635Z",
     "shell.execute_reply": "2025-10-20T11:27:39.704107Z"
    },
    "papermill": {
     "duration": 0.017723,
     "end_time": "2025-10-20T11:27:39.705663",
     "exception": false,
     "start_time": "2025-10-20T11:27:39.687940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inference Models\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
    "                      state_h, state_c])\n",
    "\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27f4d775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:39.718514Z",
     "iopub.status.busy": "2025-10-20T11:27:39.718302Z",
     "iopub.status.idle": "2025-10-20T11:27:39.724337Z",
     "shell.execute_reply": "2025-10-20T11:27:39.723856Z"
    },
    "papermill": {
     "duration": 0.013569,
     "end_time": "2025-10-20T11:27:39.725267",
     "exception": false,
     "start_time": "2025-10-20T11:27:39.711698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert sequence to summary\n",
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0 and i != y_word_index['sostok'] and i \\\n",
    "            != y_word_index['eostok']:\n",
    "            newString = newString + reverse_y_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "# Convert sequence to text\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + reverse_x_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    y_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    y_seq[0, 0] = y_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([y_seq]\n",
    "                + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_y_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find the stop word.\n",
    "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
    "            >= max_summary_len - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        y_seq = np.zeros((1, 1))\n",
    "        y_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "208de046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T11:27:39.737931Z",
     "iopub.status.busy": "2025-10-20T11:27:39.737729Z",
     "iopub.status.idle": "2025-10-20T11:28:11.561893Z",
     "shell.execute_reply": "2025-10-20T11:28:11.561226Z"
    },
    "papermill": {
     "duration": 31.831769,
     "end_time": "2025-10-20T11:28:11.563035",
     "exception": false,
     "start_time": "2025-10-20T11:27:39.731266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: the upgradation of the delhi chandigarh corridor for allowing trains to ply on a speed of 200 kilometres per hour will cost 11 218 crore a french railways report has revealed the corridor which will be built in collaboration with france is expected to reduce the travel time between the cities from 3 hours and 30 minutes to around 2 hours \n",
      "Original summary: start delhi chandigarh 200 kmph rail corridor may cost 11 000 cr end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: on being asked about the proposed abolition of the coin toss in test cricket former indian captain sourav ganguly said that personally he is not in favour of scrapping the coin toss meanwhile former pakistan captain javed miandad said that there is no harm in trying to experiment with the abolition of coin toss \n",
      "Original summary: start not in favour of scrapping coin toss in tests ganguly end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: the supreme court on tuesday asked the centre to inform it about how many special courts have been constituted to exclusively hear and decide cases against politicians december 2017 the apex court had ordered setting up of 12 special courts to deal with such cases and said that these should start functioning from march 1 2018 nnnnn \n",
      "Original summary: start sc seeks status of special courts set up to try politicians end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: two former south korean spy chiefs have been formally charged with bribing former president park geun hye the officials reportedly took money from the spy agency s funds and gave it to park s close aides for appointing them as intelligence chiefs park was formally charged with corruption earlier this year and became south korea s first democratically elected leader to be impeached \n",
      "Original summary: start south korea charges 2 ex spy chiefs for bribing former prez end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n",
      "Review: the total market capitalisation of all bse listed companies soared by more than 2 6 lakh crore to 146 74 lakh crore on thursday after the rbi kept the repo rate unchanged at 6 the benchmark index sensex climbed 577 points to close at 33 the rbi also cut the inflation forecast for first half of the fiscal year to a range of 4 7 5 1 \n",
      "Original summary: start investors add 2 6 lakh cr wealth as sensex rallies pts end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: a us senator had asked facebook if taylor swift s cover of a song named september qualified as hate speech a document has revealed the senator also asked if a statement reading taylor swift needs her falls in the category facebook replied it defines hate speech as an attack on people based on characteristics including race and national origin \n",
      "Original summary: start facebook questioned by us over lyrics of taylor swift s song end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: talking about their process of developing and launching products apple ceo tim cook said the company takes its time to get every product right because we don t believe in using our customers as a laboratory what we have that i think is unique is patience we have patience to wait until something is great before we ship it he added \n",
      "Original summary: start we don t believe in using customers as apple ceo end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: a faraday future employee has been accused by a former security guard of sexual harassment and online stalking in a lawsuit filed in june she alleged that the employee repeatedly approached her at night and asked her for her personal information the plaintiff also claims the company dismissed multiple reports about the alleged actions of the accused employee \n",
      "Original summary: start faraday future employee accused of sexual harassment end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n",
      "Review: the supreme court on tuesday directed the karnataka government to supply 2 000 cusecs of cauvery water to tamil nadu every day the matter will be next heard on july 11 the court had earlier dismissed a petition seeking compensation from both the states for the loss of property during the cauvery water related dispute between karnataka and tamil nadu \n",
      "Original summary: start sc directs k taka to release 2 000 water to tn end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: billionaire elon musk on friday announced that x com the domain name of his 18 year old startup that he recently purchased is now live visiting the website shows just the character x which he claims will be fixed in a day musk hasn t revealed how he plans to use the domain name which is estimated to be worth close to 65 crore \n",
      "Original summary: start elon musk launches website which has just 1 letter end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: five time grand slam winner russian tennis player maria sharapova will be making her first grand slam appearance in over 18 months after being handed a wildcard invitation for the us open s main draw the 30 year old russian had returned from a 15 month doping ban earlier this year and was denied a wildcard at this year s french open \n",
      "Original summary: start sharapova to make first grand slam appearance in 18 months end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n",
      "Review: kerala police on wednesday released cctv images of 210 men suspected to have indulged in violence during the protests at sabarimala temple last week and issued a lookout notice against them more than 10 women were reportedly stopped from entering the temple while female journalists were also heckled and beaten up by people protesting the supreme court s verdict \n",
      "Original summary: start police release cctv images of 210 men over sabarimala violence end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: ukraine has banned american actor steven seagal for five years with security services labelling him a threat to national security the latest of blacklisted cultural figures he had recently received russian citizenship seagal whose grandparents from russia had also called russia s annexation of crimea from ukraine very reasonable and performed at a pro putin biker club concert \n",
      "Original summary: start ukraine bans steven as threat to national security end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: a team of artists and palaeontologists has created an image of the t rex which shows that the dinosaur had smooth skin and no feathers it is the most accurately reconstructed image of the dinosaur the researchers claimed they added that the predator walked with its stomach very low to the ground due to its low centre of gravity \n",
      "Original summary: start t rex image shows it had skin no end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n",
      "Review: microsoft has announced a 1 million ai for earth innovation grant in partnership with national geographic for ai projects addressing environmental issues between five and 15 projects will be selected as recipients and the winners will receive funding and access to microsoft cloud and ai tools the project will focus on biodiversity conservation climate change agriculture and water \n",
      "Original summary: start microsoft announces 1mn ai grant for environmental issues end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: following heavy rainfall in the city on monday a portion of the road at marg in mumbai caved in the rains also led to waterlogging in several areas including east matunga sion colaba chembur east and santacruz a compound wall of an under construction building had also collapsed and around 15 cars were stuck in the debris \n",
      "Original summary: start of road in mumbai caves in due to heavy rainfall end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n",
      "Review: amid rising temperatures and heatwave in the santa city have been urged to stay cool by avoiding sex during the day the city s health secretary called it logical and also suggested the locals to stay and wear loose clothes therefore it is better to do it at night when the temperature is lower he said \n",
      "Original summary: start urged not to have sex during day amid heatwave end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n",
      "Review: karan adani son of adani group chairman gautam adani has said his father knew prime minister narendra modi much before he was gujarat s chief minister it s more of a personal relationship they enjoy each other s ideology he added karan further said adani group invested more outside of gujarat when modi was cm and most of the investments were in congress governed states \n",
      "Original summary: start dad knew pm modi even before he was gujarat cm karan adani end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: talking about the enforcement agencies seizing his uk assets vijay mallya said i ll physically hand them over tell me the time date and place mallya assured he will comply fully with officers seeking to seize his assets there s a few cars a few items of jewellery you don t have to bother to come to my house to seize them mallya added \n",
      "Original summary: start i ll hand them over tell time place mallya on uk assets end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Predicted summary:  dirt dj successor kyi hindustan pig banana reluctant fantasy fantasy parrot routine behaved approaching\n",
      "\n",
      "\n",
      "Review: actor salman khan s rumoured girlfriend iulia vantur took to instagram to share pictures from his mother salma khan s birthday celebration iulia captioned the pictures friends the celebration which took place at salman s adopted sister arpita khan sharma s residence was attended by jacqueline fernandez and sajid nadiadwala apart from family members including arbaaz khan and malaika arora \n",
      "Original summary: start iulia shares pics from salman s mother s b day celebration end \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted summary:  lava streets attempting monetary monetary dancing monetary dancing catholic catholic guilty guilty refugees propose\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "    print ('Review:', seq2text(x_train[i]))\n",
    "    print ('Original summary:', seq2summary(y_train[i]))\n",
    "    print ('Predicted summary:', decode_sequence(x_train[i].reshape(1, max_text_len)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6200bc",
   "metadata": {
    "papermill": {
     "duration": 0.077323,
     "end_time": "2025-10-20T11:28:11.672774",
     "exception": false,
     "start_time": "2025-10-20T11:28:11.595451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Credits\n",
    "\n",
    "- **\"Implementing Seq2Seq Models for Text Summarization With Keras\"**  \n",
    "  *by Samhita Alla* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878ccee2",
   "metadata": {
    "papermill": {
     "duration": 0.030376,
     "end_time": "2025-10-20T11:28:11.734092",
     "exception": false,
     "start_time": "2025-10-20T11:28:11.703716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1895,
     "sourceId": 791838,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 477297,
     "modelInstanceId": 461540,
     "sourceId": 614196,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 79.286446,
   "end_time": "2025-10-20T11:28:14.889472",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-20T11:26:55.603026",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
