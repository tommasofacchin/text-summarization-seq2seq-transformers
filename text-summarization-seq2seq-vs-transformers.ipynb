{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tommasofacchin/text-summarization-seq2seq-vs-transformers?scriptVersionId=279611524\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"f6a827c7","metadata":{"papermill":{"duration":0.009434,"end_time":"2025-11-18T16:33:13.718591","exception":false,"start_time":"2025-11-18T16:33:13.709157","status":"completed"},"tags":[]},"source":["# Project Overview\n","\n","This project focuses on **text summarization** using two approaches: a traditional **Seq2Seq model** with LSTM and a **Transformer-based model**. The goal is to see how each model performs and understand the difference between step-by-step sequence processing and attention-based processing.\n","\n","### Steps in the Project\n","1. **Dataset Preparation**  \n","   - Load the XSum dataset with articles and summaries.  \n","   - Tokenize and pad sequences so they can be fed into the models.\n","\n","2. **Seq2Seq Model (LSTM)**  \n","   - Build an encoder-decoder model without attention.\n","   - Train it to generate summaries from the input articles.  \n","\n","3. **Transformer Model**  \n","   - Build a Transformer-based encoder-decoder model.  \n","   - Use self-attention to capture relationships between all tokens.  \n","   - Train on the same dataset to generate summaries.\n","\n","4. **Comparison**  \n","   - Compare the two models using metrics like ROUGE.  \n","   - Look at differences in summary quality, speed, and how well they handle long sequences.\n"]},{"cell_type":"markdown","id":"3cb3ba95","metadata":{"papermill":{"duration":0.00806,"end_time":"2025-11-18T16:33:13.735289","exception":false,"start_time":"2025-11-18T16:33:13.727229","status":"completed"},"tags":[]},"source":["# Seq2Seq and Encoder-Decoder\n","\n","## What is a Seq2Seq Model\n","A sequence-to-sequence (Seq2Seq) model is designed to take an input sequence and produce an output sequence. It’s widely used in tasks like machine translation, text summarization, and chatbots.\n","\n","**Example:**  \n","Input: \"Hello, how are you?\"  \n","Output: \"Ciao, come stai?\"\n","\n","---\n","\n","## Encoder-Decoder Architecture (Expanded)\n","\n","A typical Seq2Seq model has two main parts: the **encoder** and the **decoder**. The design allows the model to process sequences of variable length.  \n","\n","### Encoder\n","The encoder reads the input sequence and compresses it into a set of hidden states or a context vector. This vector captures the important information from the input and has a fixed size, though it does not need to match the decoder's size. The hidden states can either be passed as a whole to the decoder or connected at every decoding step.  \n","\n","At each step, the encoder updates its hidden state based on the previous hidden state and the current input. In mathematical terms, for a simple RNN:\n","\n","$$\n","H_t^{encoder} = \\phi(W_{HH} \\cdot H_{t-1}^{encoder} + W_{HX} \\cdot X_t)\n","$$\n","\n","Where:  \n","- $H_t^{encoder}$ = hidden state at time $t$ in the encoder  \n","- $X_t$ = input at time $t$  \n","- $W_{HH}$ = weight matrix connecting hidden states  \n","- $W_{HX}$ = weight matrix connecting input to hidden states  \n","- $\\phi$ = activation function (e.g., tanh or ReLU)\n","\n","---\n","\n","### Decoder\n","The decoder generates the output sequence one token at a time. Its initial hidden state is set to the final hidden state of the encoder. For a simple RNN decoder:\n","\n","$$\n","H_t^{decoder} = \\phi(W_{HH} \\cdot H_{t-1}^{decoder} + W_{HY} \\cdot Y_{t-1})\n","$$\n","\n","The output at each step is computed as:\n","\n","$$\n","Y_t = W_{HY} \\cdot H_t^{decoder}\n","$$\n","\n","Where:  \n","- $H_t^{decoder}$ = hidden state at time $t$ in the decoder  \n","- $Y_t$ = output at time $t$  \n","- $W_{HY}$ = weight matrix connecting decoder hidden state to output  \n","\n","### Implementation Notes\n","- Encoders and decoders are typically implemented with **RNNs, LSTMs, or GRUs**.  \n","- The input and output vectors are of fixed size, but the encoder and decoder can have different hidden dimensions.  \n","- During training, **teacher forcing** is often used, providing the correct previous token to the decoder instead of its own prediction.  \n","\n","---\n","\n","## Tokenization\n","\n","Before feeding text into a Seq2Seq or Transformer model, the raw text must be converted into numerical form.  \n","This is done through **tokenization**, which splits text into smaller units (tokens) such as words or subwords.  \n","\n","Each token is then mapped to a unique integer using a **vocabulary** built from the dataset.  \n","The model processes these integers rather than the raw text.\n","\n","**Example:**\n","\n","Input text: `\"Transformers improve summarization.\"`  \n","Tokens: `[\"transformers\", \"improve\", \"summarization\", \".\"]`  \n","Token IDs: `[201, 57, 1342, 4]`\n","\n","### Why Tokenization Matters\n","- Converts variable-length text into consistent, model-readable sequences.  \n","- Helps capture word frequency and context relationships.  \n","- Reduces vocabulary size when using subword tokenization (e.g., Byte Pair Encoding).  \n","\n","In this project, tokenization is part of preprocessing and includes:\n","- **Lowercasing** the text  \n","- **Removing special characters and URLs**  \n","- **Splitting into tokens by spaces**  \n","- Adding **start (`sostok`)** and **end (`eostok`)** tokens to mark summary boundaries  \n","\n","After tokenization, sequences will later be converted to integer IDs, padded or truncated to a fixed length\n","\n","---\n","\n","# Transformers\n","Transformers can be seen as an evolution of Seq2Seq models. Instead of processing sequences step by step like LSTMs or GRUs, they rely entirely on **attention mechanisms** to process all tokens in parallel and capture relationships between them.\n","\n","### Attention in Transformers\n","Attention is the core mechanism that allows Transformers to focus on relevant parts of the input sequence when producing a representation for each token. It works by comparing each token to all others and weighting them according to importance.\n","\n","#### How Attention Works\n","Each token in the sequence is represented by three vectors:\n","- **Query (Q):** what this token is looking for  \n","- **Key (K):** what information this token contains  \n","- **Value (V):** the actual information of the token  \n","\n","The attention score between two tokens is computed as the similarity between the Query of one token and the Key of another. This determines how much attention one token should pay to another. Mathematically, the attention weights are computed using a scaled dot-product:\n","\n","$$\n","\\text{Attention}(Q, K, V) = \\text{softmax}\\Big(\\frac{QK^T}{\\sqrt{d_k}}\\Big) V\n","$$\n","\n","Where $d_k$ is the dimensionality of the Key vectors.\n","\n","- The **softmax** ensures that the weights sum to 1.  \n","- Each token’s output is a weighted sum of all Value vectors, allowing it to incorporate context from the entire sequence.\n","\n","#### Multi-Head Attention\n","Instead of computing attention just once, Transformers use **multiple attention heads** in parallel. Each head can learn to focus on different types of relationships, such as:\n","- Syntactic relationships (e.g., subject-verb connections)  \n","- Semantic relationships (e.g., synonyms or related concepts)  \n","\n","The outputs of all heads are concatenated and projected to form the final representation for each token.\n","\n","#### Intuition\n","Imagine reading a sentence and highlighting all the words that are important for understanding each token. Each word “attends” to other words in the sentence that matter most for its meaning. Multi-head attention lets the model do this from multiple perspectives simultaneously.\n","\n","### Key Components of Transformers\n","- **Encoder-Decoder Structure:** Like Seq2Seq models, Transformers have an encoder that processes the input and a decoder that generates the output. Both use layers of self-attention and feed-forward networks.  \n","- **Positional Encoding:** Since Transformers don’t process tokens sequentially, they add positional information so the model knows the order of tokens.  \n","- **Feed-Forward Layers:** After attention, each token passes through fully connected layers for additional transformation.\n","\n","### Advantages over LSTM/GRU Seq2Seq\n","- Processes sequences **in parallel**, speeding up training.  \n","- Handles **long sequences** more effectively with attention.  \n","- Captures **complex relationships** between tokens regardless of distance.  \n","- Scales easily to **very deep models** and large datasets.\n","\n","### Use Cases\n","Transformers are the backbone of many state-of-the-art models for tasks such as:\n","- Machine translation (e.g., T5, MarianMT)  \n","- Text summarization (e.g., BART, Pegasus)  \n","- Question answering and chatbots (e.g., GPT, BERT-based models)"]},{"cell_type":"code","execution_count":1,"id":"c29edb28","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:13.752698Z","iopub.status.busy":"2025-11-18T16:33:13.752299Z","iopub.status.idle":"2025-11-18T16:33:21.692204Z","shell.execute_reply":"2025-11-18T16:33:21.691051Z"},"papermill":{"duration":7.951425,"end_time":"2025-11-18T16:33:21.694519","exception":false,"start_time":"2025-11-18T16:33:13.743094","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\r\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\r\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\r\n"]}],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","!pip install openpyxl\n","!pip install sentencepiece"]},{"cell_type":"markdown","id":"e57685c1","metadata":{"papermill":{"duration":0.00806,"end_time":"2025-11-18T16:33:21.7117","exception":false,"start_time":"2025-11-18T16:33:21.70364","status":"completed"},"tags":[]},"source":["# Data Preparation\n","\n","Prepare and clean the dataset for the summarization model:\n","\n","- **Load datasets:** Read two CSV files containing news articles and their summaries.\n","- **Combine datasets:** Merge datasets while selecting relevant `text` and `summary` columns.\n","- **Text cleaning:**  \n","  - Convert text to lowercase.  \n","  - Remove special characters.  \n","  - Replace URLs with domain names.  \n","  - Reduce multiple spaces.\n","- **Tokenization:** Split cleaned text into tokens (words) and add `_START_` and `_END_` tokens for summaries.\n","- **Handle missing values:** Drop rows with missing `text` values.\n","- **Analyze sequence lengths:** Calculate word counts for texts and summaries.\n","- **Limit sequence lengths:** Restrict `text` to 100 words and `summary` to 15 words.\n","- **Add model tokens:** Prepend `sostok` and append `eostok` to all summaries to mark start and end for the model.\n"]},{"cell_type":"code","execution_count":2,"id":"42d0cb8d","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:21.72944Z","iopub.status.busy":"2025-11-18T16:33:21.729124Z","iopub.status.idle":"2025-11-18T16:33:30.488928Z","shell.execute_reply":"2025-11-18T16:33:30.488024Z"},"papermill":{"duration":8.770301,"end_time":"2025-11-18T16:33:30.490147","exception":false,"start_time":"2025-11-18T16:33:21.719846","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["(4514, 6)\n","(98401, 2)\n","(55104, 5)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","pd.set_option('display.max_colwidth', None)\n","\n","summary = pd.read_csv('/kaggle/input/news-summary/news_summary.csv', encoding='iso-8859-1')\n","summary_more = pd.read_csv('/kaggle/input/news-summary/news_summary_more.csv', encoding='iso-8859-1')\n","summary_ind = pd.read_excel(\"/kaggle/input/inshorts-news-data/Inshorts Cleaned Data.xlsx\")\n","\n","print(summary.shape)\n","print(summary_more.shape)\n","print(summary_ind.shape)"]},{"cell_type":"code","execution_count":3,"id":"8de68cd8","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:30.507632Z","iopub.status.busy":"2025-11-18T16:33:30.506988Z","iopub.status.idle":"2025-11-18T16:33:30.530398Z","shell.execute_reply":"2025-11-18T16:33:30.529542Z"},"papermill":{"duration":0.033396,"end_time":"2025-11-18T16:33:30.53181","exception":false,"start_time":"2025-11-18T16:33:30.498414","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>date</th>\n","      <th>headlines</th>\n","      <th>read_more</th>\n","      <th>text</th>\n","      <th>ctext</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Chhavi Tyagi</td>\n","      <td>03 Aug 2017,Thursday</td>\n","      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in offices order</td>\n","      <td>http://www.hindustantimes.com/india-news/rakshabandhan-compulsory-in-daman-and-diu-women-employees-to-tie-rakhis-to-male-colleagues/story-E5h5U1ZDJii5zFpLXWRkhJ.html?utm_source=inshorts&amp;utm_medium=referral&amp;utm_campaign=fullarticle</td>\n","      <td>The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.</td>\n","      <td>The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media.The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace.?It has been decided to celebrate the festival of Rakshabandhan on August 7. In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said.To ensure that no one skipped office, an attendance report was to be sent to the government the next evening.The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart. The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms.?The circular is ridiculous. There are sensitivities involved. How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day. She refused to be identified.The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said.Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies.In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?. The RSS is the ideological parent of the ruling BJP.Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers. A year before, all cabinet ministers were asked to go to their constituencies for the festival.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         author                  date  \\\n","0  Chhavi Tyagi  03 Aug 2017,Thursday   \n","\n","                                                      headlines  \\\n","0  Daman & Diu revokes mandatory Rakshabandhan in offices order   \n","\n","                                                                                                                                                                                                                                 read_more  \\\n","0  http://www.hindustantimes.com/india-news/rakshabandhan-compulsory-in-daman-and-diu-women-employees-to-tie-rakhis-to-male-colleagues/story-E5h5U1ZDJii5zFpLXWRkhJ.html?utm_source=inshorts&utm_medium=referral&utm_campaign=fullarticle    \n","\n","                                                                                                                                                                                                                                                                                                                                                                     text  \\\n","0  The Administration of Union Territory Daman and Diu has revoked its order that made it compulsory for women to tie rakhis to their male colleagues on the occasion of Rakshabandhan on August 7. The administration was forced to withdraw the decision within 24 hours of issuing the circular after it received flak from employees and was slammed on social media.   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ctext  \n","0  The Daman and Diu administration on Wednesday withdrew a circular that asked women staff to tie rakhis on male colleagues after the order triggered a backlash from employees and was ripped apart on social media.The union territory?s administration was forced to retreat within 24 hours of issuing the circular that made it compulsory for its staff to celebrate Rakshabandhan at workplace.?It has been decided to celebrate the festival of Rakshabandhan on August 7. In this connection, all offices/ departments shall remain open and celebrate the festival collectively at a suitable time wherein all the lady staff shall tie rakhis to their colleagues,? the order, issued on August 1 by Gurpreet Singh, deputy secretary (personnel), had said.To ensure that no one skipped office, an attendance report was to be sent to the government the next evening.The two notifications ? one mandating the celebration of Rakshabandhan (left) and the other withdrawing the mandate (right) ? were issued by the Daman and Diu administration a day apart. The circular was withdrawn through a one-line order issued late in the evening by the UT?s department of personnel and administrative reforms.?The circular is ridiculous. There are sensitivities involved. How can the government dictate who I should tie rakhi to? We should maintain the professionalism of a workplace? an official told Hindustan Times earlier in the day. She refused to be identified.The notice was issued on Daman and Diu administrator and former Gujarat home minister Praful Kodabhai Patel?s direction, sources said.Rakshabandhan, a celebration of the bond between brothers and sisters, is one of several Hindu festivities and rituals that are no longer confined of private, family affairs but have become tools to push politic al ideologies.In 2014, the year BJP stormed to power at the Centre, Rashtriya Swayamsevak Sangh (RSS) chief Mohan Bhagwat said the festival had ?national significance? and should be celebrated widely ?to protect Hindu culture and live by the values enshrined in it?. The RSS is the ideological parent of the ruling BJP.Last year, women ministers in the Modi government went to the border areas to celebrate the festival with soldiers. A year before, all cabinet ministers were asked to go to their constituencies for the festival.  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["summary.head(1)"]},{"cell_type":"code","execution_count":4,"id":"dcec63f1","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:30.549957Z","iopub.status.busy":"2025-11-18T16:33:30.549447Z","iopub.status.idle":"2025-11-18T16:33:30.557589Z","shell.execute_reply":"2025-11-18T16:33:30.556745Z"},"papermill":{"duration":0.018435,"end_time":"2025-11-18T16:33:30.558961","exception":false,"start_time":"2025-11-18T16:33:30.540526","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>upGrad learner switches to career in ML &amp; Al with 90% salary hike</td>\n","      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                           headlines  \\\n","0  upGrad learner switches to career in ML & Al with 90% salary hike   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                      text  \n","0  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["summary_more.head(1)"]},{"cell_type":"code","execution_count":5,"id":"10e39df0","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:30.577151Z","iopub.status.busy":"2025-11-18T16:33:30.576472Z","iopub.status.idle":"2025-11-18T16:33:30.588932Z","shell.execute_reply":"2025-11-18T16:33:30.588029Z"},"papermill":{"duration":0.022564,"end_time":"2025-11-18T16:33:30.590309","exception":false,"start_time":"2025-11-18T16:33:30.567745","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Headline</th>\n","      <th>Short</th>\n","      <th>Source</th>\n","      <th>Time</th>\n","      <th>Publish Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4 ex-bank officials booked for cheating bank of ₹209 crore</td>\n","      <td>The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.</td>\n","      <td>The New Indian Express</td>\n","      <td>09:25:00</td>\n","      <td>2017-03-26</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     Headline  \\\n","0  4 ex-bank officials booked for cheating bank of ₹209 crore   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                         Short  \\\n","0  The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.   \n","\n","                  Source      Time  Publish Date  \n","0  The New Indian Express  09:25:00   2017-03-26  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["summary_ind.head(1)"]},{"cell_type":"code","execution_count":6,"id":"34a9c4ac","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:30.608951Z","iopub.status.busy":"2025-11-18T16:33:30.608295Z","iopub.status.idle":"2025-11-18T16:33:30.625188Z","shell.execute_reply":"2025-11-18T16:33:30.624358Z"},"papermill":{"duration":0.027796,"end_time":"2025-11-18T16:33:30.626605","exception":false,"start_time":"2025-11-18T16:33:30.598809","status":"completed"},"tags":[]},"outputs":[],"source":["def clean_text(t):\n","    if isinstance(t, float):\n","        return \"\"\n","    t = re.sub(r\"http\\S+\", \"\", t)\n","    t = re.sub(r\"[^A-Za-z0-9 ,.'’\\-?()]\", \" \", t)\n","    t = re.sub(r\"\\s+\", \" \", t).strip()\n","    return t\n","\n","def is_bad_summary(text, summary):\n","    if not isinstance(text, str) or not isinstance(summary, str):\n","        return True\n","\n","    if len(summary.split()) < 4:\n","        return True\n","\n","    if summary.lower() in text.lower():\n","        return True\n","\n","    if 'Ã' in text or 'Ã' in summary:\n","        return True\n","\n","    return False"]},{"cell_type":"code","execution_count":7,"id":"226406ef","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:30.64422Z","iopub.status.busy":"2025-11-18T16:33:30.64394Z","iopub.status.idle":"2025-11-18T16:33:36.86686Z","shell.execute_reply":"2025-11-18T16:33:36.865848Z"},"papermill":{"duration":6.233224,"end_time":"2025-11-18T16:33:36.868286","exception":false,"start_time":"2025-11-18T16:33:30.635062","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["(143409, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.</td>\n","      <td>Army was cheated to pay rent for land in PoK Arun Jaitley</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others.</td>\n","      <td>Edtech startup Qonfuse raises seed funding</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n","0                                        Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.   \n","1  Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others.   \n","\n","                                                     summary  \n","0  Army was cheated to pay rent for land in PoK Arun Jaitley  \n","1                 Edtech startup Qonfuse raises seed funding  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["summary = summary.iloc[:, 0:6]\n","summary_more = summary_more.iloc[:, 0:2]\n","\n","summary['text'] = (\n","    summary['author'].astype(str) + ' ' +\n","    summary['date'].astype(str) + ' ' +\n","    summary['read_more'].astype(str) + ' ' +\n","    summary['text'].astype(str) + ' ' +\n","    summary['ctext'].astype(str)\n",")\n","\n","\n","summary_more = summary_more[\n","    ~summary_more.apply(lambda r: is_bad_summary(r['text'], r['headlines']), axis=1)\n","]\n","\n","summary['text'] = summary['text'].apply(clean_text)\n","summary['headlines'] = summary['headlines'].apply(clean_text)\n","\n","summary_more['text'] = summary_more['text'].apply(clean_text)\n","summary_more['headlines'] = summary_more['headlines'].apply(clean_text)\n","\n","summary_ind['Short'] = summary_ind['Short'].apply(clean_text)\n","summary_ind['Headline'] = summary_ind['Headline'].apply(clean_text)\n","\n","\n","df = pd.DataFrame()\n","\n","df['text'] = pd.concat([summary_more['text'], summary['text'], summary_ind['Short']], ignore_index=True)\n","df['summary'] = pd.concat([summary_more['headlines'], summary['headlines'], summary_ind['Headline']], ignore_index=True)\n","\n","df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","df_trans = df\n","\n","print(df.shape)\n","df.head(2)"]},{"cell_type":"code","execution_count":8,"id":"ef232444","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:36.888849Z","iopub.status.busy":"2025-11-18T16:33:36.888528Z","iopub.status.idle":"2025-11-18T16:33:37.650825Z","shell.execute_reply":"2025-11-18T16:33:37.64986Z"},"papermill":{"duration":0.773715,"end_time":"2025-11-18T16:33:37.652368","exception":false,"start_time":"2025-11-18T16:33:36.878653","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Text\n","count    143409.000000\n","mean         70.333159\n","std          87.460616\n","min          37.000000\n","25%          58.000000\n","50%          60.000000\n","75%          61.000000\n","90%          65.000000\n","95%          69.000000\n","max       12265.000000\n","Name: text_len, dtype: float64\n","\n","Summary\n","count    143409.000000\n","mean          9.273198\n","std           1.654586\n","min           1.000000\n","25%           8.000000\n","50%           9.000000\n","75%          10.000000\n","90%          11.000000\n","95%          12.000000\n","max          19.000000\n","Name: summary_len, dtype: float64\n"]}],"source":["df['text_len'] = df['text'].apply(lambda x: len(x.split()))\n","df['summary_len'] = df['summary'].apply(lambda x: len(x.split()))\n","\n","text_stats = df['text_len'].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95])\n","summary_stats = df['summary_len'].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95])\n","\n","print(\"Text\")\n","print(text_stats)\n","print(\"\\nSummary\")\n","print(summary_stats)"]},{"cell_type":"code","execution_count":9,"id":"9d37fe20","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:37.670815Z","iopub.status.busy":"2025-11-18T16:33:37.670579Z","iopub.status.idle":"2025-11-18T16:33:43.873319Z","shell.execute_reply":"2025-11-18T16:33:43.872658Z"},"papermill":{"duration":6.213599,"end_time":"2025-11-18T16:33:43.874871","exception":false,"start_time":"2025-11-18T16:33:37.661272","status":"completed"},"tags":[]},"outputs":[],"source":["# Tokenization: split text by spaces\n","def tokenize_texts(texts):\n","    return [' '.join(clean_text(t).split()) for t in texts]\n","\n","\n","processed_text = tokenize_texts(df['text'])\n","#processed_summary = ['_START_ ' + s + ' _END_' for s in tokenize_texts(df['summary'])]\n","processed_summary = ['sostok ' + s + ' eostok' for s in tokenize_texts(df['summary'])]\n","\n","\n","df['cleaned_text'] = pd.Series(processed_text)\n","df['cleaned_summary'] = pd.Series(processed_summary)"]},{"cell_type":"code","execution_count":10,"id":"7eb31ad3","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:43.89353Z","iopub.status.busy":"2025-11-18T16:33:43.893265Z","iopub.status.idle":"2025-11-18T16:33:44.337299Z","shell.execute_reply":"2025-11-18T16:33:44.336411Z"},"papermill":{"duration":0.454871,"end_time":"2025-11-18T16:33:44.338815","exception":false,"start_time":"2025-11-18T16:33:43.883944","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["NaN dropped: 0\n","(143029, 6)\n"]}],"source":["print(f\"NaN dropped: {df.isna().sum().sum()}\")\n","\n","#df = df.dropna(subset=['text'])\n","df = df.dropna(subset=['cleaned_text', 'cleaned_summary'])\n","df = df.drop_duplicates(subset=['cleaned_text', 'cleaned_summary'])\n","\n","print(df.shape)"]},{"cell_type":"code","execution_count":11,"id":"dc57da79","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:44.357313Z","iopub.status.busy":"2025-11-18T16:33:44.357057Z","iopub.status.idle":"2025-11-18T16:33:45.623035Z","shell.execute_reply":"2025-11-18T16:33:45.622141Z"},"papermill":{"duration":1.276971,"end_time":"2025-11-18T16:33:45.62453","exception":false,"start_time":"2025-11-18T16:33:44.347559","status":"completed"},"tags":[]},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","text_count = []\n","summary_count = []\n","\n","for sent in df['cleaned_text']:\n","    text_count.append(len(sent.split()))\n","    \n","for sent in df['cleaned_summary']:\n","    summary_count.append(len(sent.split()))\n","\n","graph_df = pd.DataFrame() \n","\n","graph_df['text'] = text_count\n","graph_df['summary'] = summary_count\n","\n","graph_df.hist(bins = 30)\n","plt.show()"]},{"cell_type":"code","execution_count":12,"id":"5a6f305d","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:45.643781Z","iopub.status.busy":"2025-11-18T16:33:45.64353Z","iopub.status.idle":"2025-11-18T16:33:46.267221Z","shell.execute_reply":"2025-11-18T16:33:46.266263Z"},"papermill":{"duration":0.63473,"end_time":"2025-11-18T16:33:46.268719","exception":false,"start_time":"2025-11-18T16:33:45.633989","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Percentage of texts with less than 100 words : 0.9696495116375001\n"]}],"source":["cnt = 0\n","for i in df['cleaned_text']:\n","    if len(i.split()) <= 100:\n","        cnt = cnt + 1\n","print(f\"Percentage of texts with less than 100 words : {cnt / len(df['cleaned_text'])}\")"]},{"cell_type":"code","execution_count":13,"id":"146fe993","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:46.345088Z","iopub.status.busy":"2025-11-18T16:33:46.344812Z","iopub.status.idle":"2025-11-18T16:33:49.082196Z","shell.execute_reply":"2025-11-18T16:33:49.081343Z"},"papermill":{"duration":2.805255,"end_time":"2025-11-18T16:33:49.08362","exception":false,"start_time":"2025-11-18T16:33:46.278365","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","      <th>text_len</th>\n","      <th>summary_len</th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.</td>\n","      <td>Army was cheated to pay rent for land in PoK Arun Jaitley</td>\n","      <td>59</td>\n","      <td>12</td>\n","      <td>Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.</td>\n","      <td>sostok sostok Army was cheated to pay rent for land in PoK Arun Jaitley eostok eostok</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others.</td>\n","      <td>Edtech startup Qonfuse raises seed funding</td>\n","      <td>59</td>\n","      <td>6</td>\n","      <td>Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others.</td>\n","      <td>sostok sostok Edtech startup Qonfuse raises seed funding eostok eostok</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n","0                                        Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.   \n","1  Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others.   \n","\n","                                                     summary  text_len  \\\n","0  Army was cheated to pay rent for land in PoK Arun Jaitley        59   \n","1                 Edtech startup Qonfuse raises seed funding        59   \n","\n","   summary_len  \\\n","0           12   \n","1            6   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                               cleaned_text  \\\n","0                                        Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.   \n","1  Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others.   \n","\n","                                                                         cleaned_summary  \n","0  sostok sostok Army was cheated to pay rent for land in PoK Arun Jaitley eostok eostok  \n","1                 sostok sostok Edtech startup Qonfuse raises seed funding eostok eostok  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["max_text_len = 100\n","max_summary_len = 20\n","\n","df['cleaned_text'] = df['cleaned_text'].astype(str)\n","df['cleaned_summary'] = df['cleaned_summary'].astype(str)\n","\n","mask = (df['cleaned_text'].str.split().str.len() <= max_text_len) & \\\n","       (df['cleaned_summary'].str.split().str.len() <= max_summary_len)\n","\n","df = df.loc[mask].reset_index(drop=True)\n","\n","# Add start and end tokens to each summary\n","df['cleaned_summary'] = df['cleaned_summary'].apply(lambda x: 'sostok ' + x + ' eostok')\n","\n","df.head(2)"]},{"cell_type":"markdown","id":"fe593f03","metadata":{"papermill":{"duration":0.011115,"end_time":"2025-11-18T16:33:49.107727","exception":false,"start_time":"2025-11-18T16:33:49.096612","status":"completed"},"tags":[]},"source":["# **Tokenization**\n","\n","This block prepares the text data for a sequence-to-sequence model:\n","\n","- **Split dataset**: Separates `text` and `summary` into training and validation sets to evaluate model performance on unseen data.  \n","- **Initialize tokenizers**: Converts words into integer indices, which neural networks can process.  \n","- **Analyze rare words**: Computes the percentage of words appearing less than `thresh` times to identify infrequent words that might add noise.  \n","- **Limit vocabulary to frequent words**: Reduces vocabulary size by ignoring rare words, which improves training efficiency and prevents overfitting.  \n","- **Convert texts to sequences**: Maps each word in the texts to its corresponding integer index.  \n","- **Pad sequences**: Ensures all sequences have the same length, necessary for batch processing in neural networks.  \n","- **Compute final vocabulary size**: Includes the padding token to correctly define the input dimension for the model embedding layer."]},{"cell_type":"code","execution_count":14,"id":"5b164d3b","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:33:49.129432Z","iopub.status.busy":"2025-11-18T16:33:49.128477Z","iopub.status.idle":"2025-11-18T16:34:11.619187Z","shell.execute_reply":"2025-11-18T16:34:11.618415Z"},"papermill":{"duration":22.503053,"end_time":"2025-11-18T16:34:11.620839","exception":false,"start_time":"2025-11-18T16:33:49.117786","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-11-18 16:33:51.893867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1763483632.108571      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1763483632.169376      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer \n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","x_train, x_val, y_train, y_val = train_test_split(\n","    np.array(df[\"cleaned_text\"]),\n","    np.array(df[\"cleaned_summary\"]),\n","    test_size=0.1,\n","    random_state=0,\n","    shuffle=True,\n",")\n","\n","x_tokenizer = Tokenizer(oov_token=\"<unk>\") \n","x_tokenizer.fit_on_texts(list(x_train))\n","\n","y_tokenizer = Tokenizer(oov_token=\"<unk>\")   \n","y_tokenizer.fit_on_texts(list(y_train))"]},{"cell_type":"code","execution_count":15,"id":"145efe57","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:11.641483Z","iopub.status.busy":"2025-11-18T16:34:11.640463Z","iopub.status.idle":"2025-11-18T16:34:11.689538Z","shell.execute_reply":"2025-11-18T16:34:11.688524Z"},"papermill":{"duration":0.06015,"end_time":"2025-11-18T16:34:11.690872","exception":false,"start_time":"2025-11-18T16:34:11.630722","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["% of rare words in X vocabulary: 55.25%\n","% of rare words in Y vocabulary: 54.98%\n"]}],"source":["thresh = 3\n","\n","def rare_word_stats(tokenizer, thresh):\n","    \"\"\"Return total and rare word counts for a given tokenizer.\"\"\"\n","    total_cnt = len(tokenizer.word_counts)\n","    rare_cnt = sum(1 for word, count in tokenizer.word_counts.items() if count < thresh)\n","    return total_cnt, rare_cnt\n","\n","\n","x_tot_cnt, x_cnt = rare_word_stats(x_tokenizer, thresh)\n","y_tot_cnt, y_cnt = rare_word_stats(y_tokenizer, thresh)\n","\n","print(f\"% of rare words in X vocabulary: {(x_cnt / x_tot_cnt) * 100:.2f}%\")\n","print(f\"% of rare words in Y vocabulary: {(y_cnt / y_tot_cnt) * 100:.2f}%\")"]},{"cell_type":"code","execution_count":16,"id":"3b6eec95","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:11.711Z","iopub.status.busy":"2025-11-18T16:34:11.710745Z","iopub.status.idle":"2025-11-18T16:34:25.459855Z","shell.execute_reply":"2025-11-18T16:34:25.458982Z"},"papermill":{"duration":13.760959,"end_time":"2025-11-18T16:34:25.461486","exception":false,"start_time":"2025-11-18T16:34:11.700527","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of vocabulary in X = 49955\n","Size of vocabulary in Y = 21387\n"]}],"source":["# Create tokenizers considering only frequent words\n","x_tokenizer = Tokenizer(num_words = x_tot_cnt - x_cnt) \n","x_tokenizer.fit_on_texts(list(x_train))\n","\n","y_tokenizer = Tokenizer(num_words=y_tot_cnt-y_cnt) \n","y_tokenizer.fit_on_texts(list(y_train))\n","\n","# Convert text to sequences of integers\n","x_train_seq = x_tokenizer.texts_to_sequences(x_train) \n","x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n","\n","y_train_seq = y_tokenizer.texts_to_sequences(y_train) \n","y_val_seq = y_tokenizer.texts_to_sequences(y_val) \n","\n","# Pad sequences\n","x_train = pad_sequences(x_train_seq,  maxlen=max_text_len, padding='post')\n","x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n","\n","y_train = pad_sequences(y_train_seq, maxlen=max_summary_len, padding='post')\n","y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n","\n","# Vocab. size (+1 for padding token)\n","x_voc_size = x_tokenizer.num_words + 1\n","y_voc_size = y_tokenizer.num_words + 1\n","\n","print(f\"Size of vocabulary in X = {x_voc_size}\")\n","print(f\"Size of vocabulary in Y = {y_voc_size}\")"]},{"cell_type":"code","execution_count":17,"id":"0d1eeda8","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:25.482783Z","iopub.status.busy":"2025-11-18T16:34:25.482131Z","iopub.status.idle":"2025-11-18T16:34:25.544831Z","shell.execute_reply":"2025-11-18T16:34:25.544092Z"},"papermill":{"duration":0.074733,"end_time":"2025-11-18T16:34:25.546334","exception":false,"start_time":"2025-11-18T16:34:25.471601","status":"completed"},"tags":[]},"outputs":[],"source":["# Finally remove from the dataset empty summaries that contain only the 'START' and 'END' tokens\n","\n","x_train = x_train[np.sum(y_train != 0, axis=1) > 2]\n","y_train = y_train[np.sum(y_train != 0, axis=1) > 2]\n","\n","x_val = x_val[np.sum(y_val != 0, axis=1) > 2]\n","y_val = y_val[np.sum(y_val != 0, axis=1) > 2]"]},{"cell_type":"markdown","id":"23d9bc4c","metadata":{"papermill":{"duration":0.009335,"end_time":"2025-11-18T16:34:25.566114","exception":false,"start_time":"2025-11-18T16:34:25.556779","status":"completed"},"tags":[]},"source":["# **Seq2seq model using LSTM**\n","\n","### Encoder-Decoder Architecture with LSTM\n","\n","During training, the model takes **two inputs**:  \n","1. The encoder input (`text`) – the original text sequence.  \n","2. The decoder input (`summary`) – the summary shifted by one token (so that the model learns to predict the next word).  \n","\n","The **target output** is the summary sequence shifted forward by one token. The model learns to predict the next word in the summary based on the previous words. During inference, the trained model generates summaries one word at a time, using the previously predicted words as input.\n","\n","---\n","\n","**Encoder**  \n","- The encoder accepts sequences of text with a fixed length (`max_text_len`).  \n","- The text is first passed through an **Embedding layer** that maps each word index to a dense vector of size `(embedding_dim)`.  \n","- The embedded sequence is then processed by **three stacked LSTM layers**:  \n","  - Each layer outputs the **full sequence of hidden states** (for possible attention or stacking) and the **last hidden and cell states**.  \n","  - The last hidden and cell states from the final LSTM are used to initialize the decoder.  \n","- Stacking multiple LSTMs allows the encoder to **capture both local patterns and long-range dependencies** in the text.\n","\n","---\n","\n","**Decoder**  \n","- The decoder input (shifted summary) is passed through an **Embedding layer** of size `(summary vocabulary size x embedding_dim)`.  \n","- A single **LSTM** processes the embedded sequence, using the **encoder's last hidden and cell states** as its initial state.  \n","- The LSTM output is passed through a **TimeDistributed Dense layer** with **softmax activation**, which predicts the probability of each word in the vocabulary at each time step.  \n","\n","This architecture ensures that the decoder can generate the summary step by step, **learning the sequence of words conditioned on the input text**.\n"]},{"cell_type":"code","execution_count":18,"id":"d38befeb","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:25.587036Z","iopub.status.busy":"2025-11-18T16:34:25.586755Z","iopub.status.idle":"2025-11-18T16:34:28.023504Z","shell.execute_reply":"2025-11-18T16:34:28.022814Z"},"papermill":{"duration":2.448761,"end_time":"2025-11-18T16:34:28.024728","exception":false,"start_time":"2025-11-18T16:34:25.575967","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["I0000 00:00:1763483666.358405      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,991,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,277,400</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │                   │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,437,487</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">21387</span>)            │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m200\u001b[0m)  │  \u001b[38;5;34m9,991,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m601,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n","│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m721,200\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n","│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │  \u001b[38;5;34m4,277,400\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m,      │    \u001b[38;5;34m721,200\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │                   │\n","│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m601,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n","│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n","│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m6,437,487\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m21387\u001b[0m)            │            │                   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,350,687</span> (89.08 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,350,687\u001b[0m (89.08 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,350,687</span> (89.08 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,350,687\u001b[0m (89.08 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import EarlyStopping\n","#from tensorflow.keras import mixed_precision\n","\n","#mixed_precision.set_global_policy('mixed_float16')\n","\n","latent_dim = 300\n","embedding_dim = 200\n","\n","# Encoder\n","encoder_inputs = Input(shape=(max_text_len, ))\n","\n","# Embedding layer\n","enc_emb = Embedding(x_voc_size, embedding_dim,\n","                    trainable=True)(encoder_inputs)\n","\n","# Encoder LSTM 1\n","encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n","                     return_state=True, dropout=0.4,\n","                     recurrent_dropout=0.4)\n","(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n","\n","# Encoder LSTM 2\n","encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n","                     return_state=True, dropout=0.4,\n","                     recurrent_dropout=0.4)\n","(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n","\n","# Encoder LSTM 3\n","encoder_lstm3 = LSTM(latent_dim, return_state=True,\n","                     return_sequences=True, dropout=0.4,\n","                     recurrent_dropout=0.4)\n","(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n","\n","# Decoder\n","decoder_inputs = Input(shape=(None, ))\n","\n","# Embedding layer\n","dec_emb_layer = Embedding(y_voc_size, embedding_dim, trainable=True)\n","dec_emb = dec_emb_layer(decoder_inputs)\n","\n","# Decoder LSTM\n","decoder_lstm = LSTM(latent_dim, return_sequences=True,\n","                    return_state=True, dropout=0.4,\n","                    recurrent_dropout=0.2)\n","(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n","    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n","\n","# Dense layer\n","decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.summary()"]},{"cell_type":"markdown","id":"aed77e0f","metadata":{"papermill":{"duration":0.011038,"end_time":"2025-11-18T16:34:28.048746","exception":false,"start_time":"2025-11-18T16:34:28.037708","status":"completed"},"tags":[]},"source":["## **Training the model** "]},{"cell_type":"code","execution_count":19,"id":"5e02a3fb","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:28.072195Z","iopub.status.busy":"2025-11-18T16:34:28.071428Z","iopub.status.idle":"2025-11-18T16:34:29.849933Z","shell.execute_reply":"2025-11-18T16:34:29.849229Z"},"papermill":{"duration":1.791659,"end_time":"2025-11-18T16:34:29.851329","exception":false,"start_time":"2025-11-18T16:34:28.05967","status":"completed"},"tags":[]},"outputs":[],"source":["x_train_lstm = x_train\n","x_val_lstm = x_val\n","y_train_lstm = y_train\n","y_val_lstm = y_val\n","\n","MODEL_INPUT_PATH = \"/kaggle/input/lstm-keras-summarization/keras/default/1/model_lstm.keras\" \n","MODEL_PATH = \"/kaggle/working/model_lstm.keras\" \n","\n","\n","if os.path.exists(MODEL_INPUT_PATH):\n","    model = load_model(MODEL_INPUT_PATH)\n","\n","else:\n","    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n","    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n","\n","    history = model.fit(\n","        [x_train, y_train[:, :-1]],\n","        y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:],\n","        epochs=50,\n","        callbacks=[es],\n","        batch_size=128,\n","        validation_data=(\n","            [x_val, y_val[:, :-1]],\n","            y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]\n","        )\n","    )\n","\n","    model.save(MODEL_PATH)\n","\n","    plt.plot(history.history['loss'], label='train')\n","    plt.plot(history.history['val_loss'], label='test')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"markdown","id":"1ab71e83","metadata":{"papermill":{"duration":0.01039,"end_time":"2025-11-18T16:34:29.872638","exception":false,"start_time":"2025-11-18T16:34:29.862248","status":"completed"},"tags":[]},"source":["## **Predict**\n","\n","Once the Seq2Seq model has been trained, we can use it to **generate summaries** for new input texts.  \n","This stage is known as **inference**, the model no longer learns, but uses its learned parameters to predict the most likely output sequence (summary).\n","\n","---\n","\n","### 1. Preparing the Mapping Dictionaries\n","Before generating predictions, we rebuild the word–token mappings from the tokenizers:\n","- `reverse_x_word_index`: converts article tokens → words  \n","- `reverse_y_word_index`: converts summary tokens → words  \n","- `y_word_index`: converts summary words → tokens  \n","\n","These dictionaries let us translate between the model’s numeric predictions and readable text.\n","\n","---\n","\n","### 2. Building Inference Models\n","During training, the encoder and decoder work together in a single model.  \n","At inference time, we separate them:\n","\n","- The **encoder model** processes the input text once and produces context vectors (`encoder_outputs`, `state_h`, `state_c`) — a compressed representation of the input.  \n","- The **decoder model** generates the summary **one word at a time**, taking as input the previous word and its previous internal states.\n","\n","This setup allows the decoder to iteratively predict each next token until the end-of-sequence marker (`eostok`) is reached.\n","\n","---\n","\n","### 3. The Decoding Process\n","The function `decode_sequence()` handles the actual text generation:\n","\n","1. **Encode the input sequence** using the encoder model to obtain its internal states.  \n","2. **Initialize** the decoder with the special start token (`sostok`).  \n","3. **Iteratively predict** the next word:\n","   - Feed the previous word and the latest decoder states into the model.\n","   - Pick the word with the highest probability (`argmax`).\n","   - Stop when the `eostok` token is predicted or the maximum summary length is reached.\n","4. **Concatenate** all predicted tokens into a readable summary.\n","\n","This process simulates how the model “writes” one word at a time, using its internal memory to maintain context.\n","\n","---\n","\n","### 4. Converting Sequences to Text\n","Two helper functions make the predictions human-readable:\n","- `seq2text()` converts numeric article sequences back into words.\n","- `seq2summary()` converts numeric summary sequences back into words, excluding special tokens (`sostok`, `eostok`).\n"]},{"cell_type":"code","execution_count":20,"id":"f5e2a1dc","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:29.894984Z","iopub.status.busy":"2025-11-18T16:34:29.894218Z","iopub.status.idle":"2025-11-18T16:34:29.89819Z","shell.execute_reply":"2025-11-18T16:34:29.897579Z"},"papermill":{"duration":0.016306,"end_time":"2025-11-18T16:34:29.899227","exception":false,"start_time":"2025-11-18T16:34:29.882921","status":"completed"},"tags":[]},"outputs":[],"source":["# reverse_y_word_index: summary token → word\n","# reverse_x_word_index: article token → word\n","# y_word_index: summary word → token\n","\n","reverse_y_word_index = y_tokenizer.index_word\n","reverse_x_word_index = x_tokenizer.index_word\n","y_word_index = y_tokenizer.word_index"]},{"cell_type":"code","execution_count":21,"id":"6477fdf4","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:29.921099Z","iopub.status.busy":"2025-11-18T16:34:29.920836Z","iopub.status.idle":"2025-11-18T16:34:29.932227Z","shell.execute_reply":"2025-11-18T16:34:29.931613Z"},"papermill":{"duration":0.023728,"end_time":"2025-11-18T16:34:29.933698","exception":false,"start_time":"2025-11-18T16:34:29.90997","status":"completed"},"tags":[]},"outputs":[],"source":["# Inference Models\n","encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n","                      state_h, state_c])\n","\n","# Below tensors will hold the states of the previous time step\n","decoder_state_input_h = Input(shape=(latent_dim, ))\n","decoder_state_input_c = Input(shape=(latent_dim, ))\n","decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n","\n","# Get the embeddings of the decoder sequence\n","dec_emb2 = dec_emb_layer(decoder_inputs)\n","\n","# To predict the next word in the sequence, set the initial states to the states from the previous time step\n","(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n","        initial_state=[decoder_state_input_h, decoder_state_input_c])\n","\n","# A dense softmax layer to generate prob dist. over the target vocabulary\n","decoder_outputs2 = decoder_dense(decoder_outputs2)\n","\n","# Final decoder model\n","#decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n","#                       decoder_state_input_h, decoder_state_input_c],\n","#                       [decoder_outputs2] + [state_h2, state_c2])\n","#TPU error\n","decoder_model = Model(\n","    [decoder_inputs, decoder_state_input_h, decoder_state_input_c],\n","    [decoder_outputs2, state_h2, state_c2]\n",")\n"]},{"cell_type":"code","execution_count":22,"id":"fd6c54d9","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:29.955649Z","iopub.status.busy":"2025-11-18T16:34:29.955335Z","iopub.status.idle":"2025-11-18T16:34:29.962936Z","shell.execute_reply":"2025-11-18T16:34:29.962248Z"},"papermill":{"duration":0.020106,"end_time":"2025-11-18T16:34:29.96421","exception":false,"start_time":"2025-11-18T16:34:29.944104","status":"completed"},"tags":[]},"outputs":[],"source":["# Convert sequence to summary\n","def seq2summary(input_seq):\n","    newString = ''\n","    for i in input_seq:\n","        if i != 0 and i != y_word_index['sostok'] and i \\\n","            != y_word_index['eostok']:\n","            newString = newString + reverse_y_word_index[i] + ' '\n","\n","    return newString\n","\n","# Convert sequence to text\n","def seq2text(input_seq):\n","    newString = ''\n","    for i in input_seq:\n","        if i != 0:\n","            newString = newString + reverse_x_word_index[i] + ' '\n","\n","    return newString\n","\n","def decode_sequence(input_seq):\n","\n","    # Encode the input as state vectors.\n","    (e_out, e_h, e_c) = encoder_model.predict(input_seq, verbose=0)\n","\n","    # Generate empty target sequence of length 1\n","    y_seq = np.zeros((1, 1))\n","\n","    # Populate the first word of target sequence with the start word.\n","    y_seq[0, 0] = y_word_index['sostok']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","\n","    while not stop_condition:\n","        (output_tokens, h, c) = decoder_model.predict([y_seq]\n","                + [e_out, e_h, e_c], verbose=0)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_token = reverse_y_word_index[sampled_token_index]\n","\n","        if sampled_token != 'eostok':\n","            decoded_sentence += ' ' + sampled_token\n","\n","        # Exit condition: either hit max length or find the stop word.\n","        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n","            >= max_summary_len - 1:\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1)\n","        y_seq = np.zeros((1, 1))\n","        y_seq[0, 0] = sampled_token_index\n","\n","        # Update internal states\n","        (e_h, e_c) = (h, c)\n","\n","    return decoded_sentence"]},{"cell_type":"code","execution_count":23,"id":"6eff3257","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:29.986122Z","iopub.status.busy":"2025-11-18T16:34:29.98585Z","iopub.status.idle":"2025-11-18T16:34:29.989297Z","shell.execute_reply":"2025-11-18T16:34:29.988738Z"},"papermill":{"duration":0.015675,"end_time":"2025-11-18T16:34:29.990455","exception":false,"start_time":"2025-11-18T16:34:29.97478","status":"completed"},"tags":[]},"outputs":[],"source":["# for i in range(0, 5):\n","#     print ('Review:', seq2text(x_train[i]))\n","#     print ('Original summary:', seq2summary(y_train[i]))\n","#     print ('Predicted summary:', decode_sequence(x_train[i].reshape(1, max_text_len)))\n","#     print('\\n')"]},{"cell_type":"markdown","id":"4cb85322","metadata":{"papermill":{"duration":0.01051,"end_time":"2025-11-18T16:34:30.011655","exception":false,"start_time":"2025-11-18T16:34:30.001145","status":"completed"},"tags":[]},"source":["# Transformer Model with Self-Attention\n","\n","Similar to the Seq2Seq architecture, the Transformer follows an **encoder–decoder structure**, but instead of recurrent layers it relies entirely on **Multi-Head Self-Attention**.  \n","This allows the model to process all tokens **in parallel** and learn relationships between words regardless of their distance in the sequence.\n","\n","During training, the model takes **two inputs**:  \n","1. The encoder input (`text`) – the tokenized article.  \n","2. The decoder input (`summary`) – the summary shifted by one token.  \n","\n","The **target output** is the summary shifted forward by one position. The decoder learns to predict each word based on the previously generated ones and the encoded representation of the full text.\n","\n","---\n","\n","**Encoder**  \n","- The input article sequence (`max_text_len`) is first transformed using an **Embedding layer**.  \n","- A **Positional Encoding** is added to preserve the order of words (since attention has no notion of sequence order by itself).  \n","- The embedded input is processed by one or more **Multi-Head Self-Attention** blocks:\n","  - Each word attends to **all other words** in the input\n","  - Relationships between distant tokens are captured more effectively than in RNNs  \n","- A **Feed-Forward Network** (FFN) refines the contextual representations.\n","- **Residual connections** and **Layer Normalization** improve gradient flow and training stability.\n","\n","---\n","\n","**Decoder**  \n","- Similar positional embeddings are applied to the shifted summary tokens.  \n","- The decoder uses two attention mechanisms:\n","  1. **Masked Self-Attention**: ensures the model cannot “peek” at future words when predicting the next token.\n","  2. **Encoder-Decoder Attention**: allows the decoder to focus on relevant parts of the input article.\n","- A **Feed-Forward Network** further processes the attended features.\n","- A final **Dense layer with Softmax** outputs a probability distribution over all words in the vocabulary at each time step.\n","\n","---\n","\n","**sostok and eostok**  \n","In sequence-to-sequence tasks such as abstractive text summarization, **special tokens** are essential for controlling how a model generates text:\n","\n","- `<sostok>` → marks the **start** of the output sequence  \n","- `<eostok>` → marks the **end** of the sequence  \n","\n","However, these tokens **do not** play the same role during training across different architectures.\n","\n","Transformers use **masked self-attention** in the decoder, meaning that at time *t* the model can only attend to **previous tokens**.\n","Therefore:\n","\n","- `<sostok>` must be present **only in the decoder input**  \n","- `<sostok>` must be removed from the decoder target  \n","\n","Predicting a start token would make no sense and causes failure modes such as:\n","\n","- the model repeatedly outputting `<sostok>`\n","- inability to begin sequences with meaningful content\n","\n","The EOS token **must remain in the targets**, because:\n","\n","- it teaches the model **when to stop writing**\n","- without it, generation may become too long or infinite\n","\n","LSTM encoder-decoder models:\n","\n","- receive the final hidden state as initial context\n","- do **not** use masked attention\n","- often ignore the first timestep in loss computation\n","\n","So `<sostok>` in targets is less harmful there.\n","\n","---\n","\n","Thanks to the Self-Attention mechanism, Transformers **capture global context efficiently** and typically produce **more coherent and fluent summaries**, especially for longer texts."]},{"cell_type":"markdown","id":"45cd4dad","metadata":{"papermill":{"duration":0.010103,"end_time":"2025-11-18T16:34:30.032022","exception":false,"start_time":"2025-11-18T16:34:30.021919","status":"completed"},"tags":[]},"source":["### Preparing Transformer Inputs\n","\n","To train the Transformer in an encoder–decoder setup, we need to properly structure the input data:\n","\n","- The **encoder input** is the full tokenized article (`x_train`)\n","- The **decoder input** is the summary sequence **shifted right**, starting with `<sostok>`\n","- The **decoder target** is the same summary **shifted left**, ending with `<eostok>`\n","\n","This shifting ensures that at each timestep the decoder learns to predict the **next** word using:\n","1. The previously processed summary tokens  \n","2. Attention over the encoder output  "]},{"cell_type":"markdown","id":"0d0bcc25","metadata":{"papermill":{"duration":0.010436,"end_time":"2025-11-18T16:34:30.054967","exception":false,"start_time":"2025-11-18T16:34:30.044531","status":"completed"},"tags":[]},"source":["In text summarization, token-level accuracy can be misleading because it only measures whether each predicted token matches the ground truth at the same position. It does not capture semantic meaning, fluency, word order, or relevance, and it can be inflated by common tokens like padding or start/end markers. A model can have high accuracy while producing poor summaries. Better evaluation uses metrics like ROUGE-1, ROUGE-2, and ROUGE-L, which measure overlap of unigrams, bigrams, and longest common subsequences between generated and reference summaries. During training, it is better to monitor validation loss and evaluate summaries qualitatively or with ROUGE rather than relying on token accuracy."]},{"cell_type":"markdown","id":"99649afa","metadata":{"papermill":{"duration":0.009967,"end_time":"2025-11-18T16:34:30.075066","exception":false,"start_time":"2025-11-18T16:34:30.065099","status":"completed"},"tags":[]},"source":["## Predict"]},{"cell_type":"markdown","id":"0b0fbe14","metadata":{"papermill":{"duration":0.009942,"end_time":"2025-11-18T16:34:30.095309","exception":false,"start_time":"2025-11-18T16:34:30.085367","status":"completed"},"tags":[]},"source":["Note importanti:\n","\n","Look-ahead mask a inference non serve se generi un token alla volta (greedy decoding step-by-step).\n","\n","Padding mask dell’encoder serve al decoder per ignorare i pad token dell’input.\n","\n","Quando fai l’inference dovrai generare token uno per uno, aggiornando dec_input_inf ad ogni step."]},{"cell_type":"markdown","id":"e561e21c","metadata":{"papermill":{"duration":0.009874,"end_time":"2025-11-18T16:34:30.115104","exception":false,"start_time":"2025-11-18T16:34:30.10523","status":"completed"},"tags":[]},"source":["Generated summary: ripete continuamente parole (cannot cannot cannot, power power power…) → questo è un loop di ripetizione, tipico dei modelli seq2seq che non hanno abbastanza regolarizzazione sulla generazione.\n","\n","Generated beam search summary: testo quasi completamente fuori tema → indica che il modello non ha appreso bene il contenuto semantico e il beam search amplifica le frasi che appaiono più “probabili” a livello di token, ma non corrette.\n"]},{"cell_type":"markdown","id":"67402d69","metadata":{"papermill":{"duration":0.010042,"end_time":"2025-11-18T16:34:30.13523","exception":false,"start_time":"2025-11-18T16:34:30.125188","status":"completed"},"tags":[]},"source":["Limiting the vocabulary in a Transformer is important because it reduces the size of the embedding matrices and the final softmax layer, making the model faster and lighter. It also helps prevent overfitting by removing extremely rare words that add noise rather than useful information. A smaller vocabulary uses less memory and often leads to more stable training, which can be important when working with limited hardware. However, reducing the vocabulary also means losing information, because words outside the limit are replaced with an unknown token. This can harm tasks like summarization, where specific terms, names, or technical words matter. A limited vocabulary also restricts what the model can generate, since it can only output words it knows.\n","\n","I tried limiting the vocabulary, but it ended up harming the model’s performance."]},{"cell_type":"markdown","id":"6d411709","metadata":{"papermill":{"duration":0.010204,"end_time":"2025-11-18T16:34:30.155703","exception":false,"start_time":"2025-11-18T16:34:30.145499","status":"completed"},"tags":[]},"source":["We wanted to continue training a Transformer model after the first epoch without losing the optimizer state. The issue was that creating a new optimizer reset the step count, making the learning rate extremely small due to the warmup schedule. To fix this, we restored a full checkpoint including both the model and optimizer. This ensures the weights, optimizer moments, and step count are preserved, so the learning rate continues correctly. Training can now continue from where it left off, and checkpoints can be saved after each epoch to resume seamlessly in future sessions."]},{"cell_type":"markdown","id":"4a5ff18a","metadata":{"papermill":{"duration":0.010394,"end_time":"2025-11-18T16:34:30.176305","exception":false,"start_time":"2025-11-18T16:34:30.165911","status":"completed"},"tags":[]},"source":["When resuming training from a checkpoint, the Transformer seems to start from zero only because the first batches always show very low accuracy. This is normal and not a sign of lost weights. The decoder struggles with the first tokens due to masking, so accuracy is naturally low at the start of each epoch. If the dataset uses a fixed shuffle and the same examples appear first every time, you will always see the same low accuracy at the beginning. The proof that the checkpoint is restored correctly is that the accuracy rises quickly after a few hundred batches, which would not happen if the model had really restarted from scratch."]},{"cell_type":"code","execution_count":24,"id":"95b21a15","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:30.198849Z","iopub.status.busy":"2025-11-18T16:34:30.19856Z","iopub.status.idle":"2025-11-18T16:34:30.207476Z","shell.execute_reply":"2025-11-18T16:34:30.206715Z"},"papermill":{"duration":0.02157,"end_time":"2025-11-18T16:34:30.20865","exception":false,"start_time":"2025-11-18T16:34:30.18708","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","      <th>text_len</th>\n","      <th>summary_len</th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.</td>\n","      <td>Army was cheated to pay rent for land in PoK Arun Jaitley</td>\n","      <td>59</td>\n","      <td>12</td>\n","      <td>Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.</td>\n","      <td>sostok Army was cheated to pay rent for land in PoK Arun Jaitley eostok</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                 text  \\\n","0  Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.   \n","\n","                                                     summary  text_len  \\\n","0  Army was cheated to pay rent for land in PoK Arun Jaitley        59   \n","\n","   summary_len  \\\n","0           12   \n","\n","                                                                                                                                                                                                                                                                                                                                                         cleaned_text  \\\n","0  Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession.   \n","\n","                                                           cleaned_summary  \n","0  sostok Army was cheated to pay rent for land in PoK Arun Jaitley eostok  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_tmp = df_trans\n","df_tmp.head(1)"]},{"cell_type":"code","execution_count":25,"id":"c6b712c3","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:30.230204Z","iopub.status.busy":"2025-11-18T16:34:30.229894Z","iopub.status.idle":"2025-11-18T16:34:30.233458Z","shell.execute_reply":"2025-11-18T16:34:30.232801Z"},"papermill":{"duration":0.015654,"end_time":"2025-11-18T16:34:30.234562","exception":false,"start_time":"2025-11-18T16:34:30.218908","status":"completed"},"tags":[]},"outputs":[],"source":["df_trans = df_tmp"]},{"cell_type":"code","execution_count":26,"id":"414106ad","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:34:30.25683Z","iopub.status.busy":"2025-11-18T16:34:30.256555Z","iopub.status.idle":"2025-11-18T16:35:15.087666Z","shell.execute_reply":"2025-11-18T16:35:15.085995Z"},"papermill":{"duration":44.860273,"end_time":"2025-11-18T16:35:15.10534","exception":false,"start_time":"2025-11-18T16:34:30.245067","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["text_sample.txt loaded\n","summary_sample.txt loaded\n","sp_text.model loaded\n","sp_summary.model loaded\n","Size of vocabulary in X = 20000\n","Size of vocabulary in Y = 20000\n"]}],"source":["import tensorflow as tf\n","import sentencepiece as spm\n","\n","text_file = \"text_sample.txt\"\n","summary_file = \"summary_sample.txt\"\n","text_model_file = \"sp_text.model\"\n","summary_model_file = \"sp_summary.model\"\n","\n","\n","# Text\n","if os.path.exists(f\"/kaggle/input/sentencepiece4/{text_file}\"):\n","    print(f\"{text_file} loaded\")\n","    text_path = f\"/kaggle/input/sentencepiece4/{text_file}\"\n","else:\n","    text_path = f\"/kaggle/working/{text_file}\"\n","    with open(text_path, \"w\", encoding=\"utf-8\") as f:\n","        for t in df_trans['text']:\n","            f.write(t + \"\\n\")\n","\n","# Summary\n","if os.path.exists(f\"/kaggle/input/sentencepiece4/{summary_file}\"):\n","    print(f\"{summary_file} loaded\")\n","    summary_path = f\"/kaggle/input/sentencepiece4/{summary_file}\"\n","else:\n","    summary_path = f\"/kaggle/working/{summary_file}\"\n","    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n","        for t in df_trans['summary']:\n","            f.write(t + \"\\n\")\n","\n","# Text model\n","if os.path.exists(f\"/kaggle/input/sentencepiece4/{text_model_file}\"):\n","    print(f\"{text_model_file} loaded\")\n","    text_model_path = f\"/kaggle/input/sentencepiece4/{text_model_file}\"\n","else:\n","    text_model_path = f\"/kaggle/working/{text_model_file}\"\n","    spm.SentencePieceTrainer.Train(\n","        f'--input={text_path} '\n","        f'--model_prefix=/kaggle/working/sp_text '\n","        '--vocab_size=20000 --model_type=bpe '\n","        '--user_defined_symbols=<SOS>,<EOS> --num_threads=8'\n","    )\n","\n","# Summary model\n","if os.path.exists(f\"/kaggle/input/sentencepiece4/{summary_model_file}\"):\n","    print(f\"{summary_model_file} loaded\")\n","    summary_model_path = f\"/kaggle/input/sentencepiece4/{summary_model_file}\"\n","else:\n","    summary_model_path = f\"/kaggle/working/{summary_model_file}\"\n","    spm.SentencePieceTrainer.Train(\n","        f'--input={summary_path} '\n","        f'--model_prefix=/kaggle/working/sp_summary '\n","        '--vocab_size=20000 --model_type=bpe '\n","        '--user_defined_symbols=<SOS>,<EOS> --num_threads=8'\n","    )\n","\n","sp_text = spm.SentencePieceProcessor()\n","sp_text.load(text_model_path)\n","\n","sp_summary = spm.SentencePieceProcessor()\n","sp_summary.load(summary_model_path)\n","\n","inputs = [sp_text.encode_as_ids(t) for t in df_trans['text']]\n","#targets = [sp_summary.encode_as_ids(t) for t in df_trans['summary']]\n","targets = [[sp_summary.piece_to_id(\"<SOS>\")] + sp_summary.encode_as_ids(t) + [sp_summary.piece_to_id(\"<EOS>\")] \n","           for t in df_trans['summary']]\n","\n","\n","inputs = pad_sequences(inputs, maxlen=max_text_len, padding='post', truncating='post')\n","targets = pad_sequences(targets, maxlen=max_summary_len, padding='post', truncating='post')\n","\n","inputs = tf.cast(inputs, dtype=tf.int64)\n","targets = tf.cast(targets, dtype=tf.int64)\n","\n","x_voc_size = sp_text.get_piece_size()\n","y_voc_size = sp_summary.get_piece_size()\n","\n","print(f\"Size of vocabulary in X = {x_voc_size}\")\n","print(f\"Size of vocabulary in Y = {y_voc_size}\")"]},{"cell_type":"code","execution_count":27,"id":"39a584f5","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:35:15.129531Z","iopub.status.busy":"2025-11-18T16:35:15.129218Z","iopub.status.idle":"2025-11-18T16:35:16.396247Z","shell.execute_reply":"2025-11-18T16:35:16.395329Z"},"papermill":{"duration":1.281144,"end_time":"2025-11-18T16:35:16.398003","exception":false,"start_time":"2025-11-18T16:35:15.116859","status":"completed"},"tags":[]},"outputs":[],"source":["dataset = (tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(10000, seed=42, reshuffle_each_iteration=False).batch(32))\n","\n","\n","def get_angles(position, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return position * angle_rates\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(\n","        np.arange(position)[:, np.newaxis],\n","        np.arange(d_model)[np.newaxis, :],\n","        d_model\n","    )\n","\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    return seq[:, tf.newaxis, tf.newaxis, :]\n","\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask\n","\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    #dk = tf.cast(tf.shape(k)[-1], q.dtype)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)  \n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","        \n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        \n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","        output = self.dense(concat_attention)\n","            \n","        return output, attention_weights\n","    \n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),\n","        tf.keras.layers.Dense(d_model)\n","    ])\n","\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, training=False, mask=None):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","    \n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","    \n","        return out2\n","\n","\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","    \n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","    \n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","    \n","        return out3, attn_weights_block1, attn_weights_block2\n","\n","\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","    def call(self, x, training=False, mask=None):\n","        seq_len = tf.shape(x)[1]\n","    \n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        #x *= tf.math.sqrt(tf.cast(self.d_model, x.dtype)) \n","        #x += tf.cast(self.pos_encoding[:, :seq_len, :], x.dtype)\n","\n","        x = self.dropout(x, training=training)\n","    \n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training=training, mask=mask)\n","    \n","        return x\n","    \n","class Decoder(tf.keras.layers.Layer):\n","        \n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","    \n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        #x *= tf.math.sqrt(tf.cast(self.d_model, x.dtype))              \n","        #x += tf.cast(self.pos_encoding[:, :seq_len, :], x.dtype)      \n","\n","    \n","        x = self.dropout(x, training=training)\n","    \n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](\n","                x, \n","                enc_output, \n","                training=training, \n","                look_ahead_mask=look_ahead_mask, \n","                padding_mask=padding_mask\n","            )\n","            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n","            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n","    \n","        return x, attention_weights\n","\n","\n","\n","\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","    def call(self, inp, tar, training=False, enc_padding_mask=None, look_ahead_mask=None, dec_padding_mask=None):\n","        enc_output = self.encoder(x=inp, training=training, mask=enc_padding_mask)\n","        dec_output, attention_weights = self.decoder(x=tar, enc_output=enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n","        final_output = self.final_layer(dec_output)\n","        return final_output, attention_weights"]},{"cell_type":"code","execution_count":28,"id":"e482ea55","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:35:16.422045Z","iopub.status.busy":"2025-11-18T16:35:16.421754Z","iopub.status.idle":"2025-11-18T16:35:16.432546Z","shell.execute_reply":"2025-11-18T16:35:16.431766Z"},"papermill":{"duration":0.024215,"end_time":"2025-11-18T16:35:16.434051","exception":false,"start_time":"2025-11-18T16:35:16.409836","status":"completed"},"tags":[]},"outputs":[],"source":["import time\n","\n","def smooth_labels(labels, vocab_size, smoothing=0.05):\n","    confidence = 1.0 - smoothing\n","    low_conf = smoothing / tf.cast(vocab_size - 1, tf.float32)\n","    labels_one_hot = tf.one_hot(labels, depth=vocab_size)\n","    return labels_one_hot * confidence + low_conf\n","\n","def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    smoothed_labels = smooth_labels(real, y_voc_size, smoothing=0)\n","    \n","    loss_ = tf.keras.losses.categorical_crossentropy(smoothed_labels, pred, from_logits=True)\n","    \n","    loss_ *= tf.cast(mask, dtype=loss_.dtype)\n","    return tf.reduce_sum(loss_) / tf.reduce_sum(tf.cast(mask, dtype=loss_.dtype))\n","\n","\n","def accuracy_function(real, pred):\n","    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n","    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n","\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    accuracies = tf.math.logical_and(mask, accuracies)\n","\n","    accuracies = tf.cast(accuracies, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n","\n","def create_masks(inp, tar):\n","    enc_padding_mask = create_padding_mask(inp)\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","    return enc_padding_mask, combined_mask, dec_padding_mask\n","\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=500, factor=1.0):\n","        super(CustomSchedule, self).__init__()\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","        self.warmup_steps = warmup_steps\n","        self.factor = factor\n","    \n","    def __call__(self, step):\n","        step = tf.cast(step, tf.float32) \n","        step = tf.maximum(step, 1.0)\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2) * self.factor"]},{"cell_type":"code","execution_count":29,"id":"be91d305","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:35:16.457403Z","iopub.status.busy":"2025-11-18T16:35:16.457117Z","iopub.status.idle":"2025-11-18T16:35:20.371901Z","shell.execute_reply":"2025-11-18T16:35:20.371251Z"},"papermill":{"duration":3.927455,"end_time":"2025-11-18T16:35:20.373141","exception":false,"start_time":"2025-11-18T16:35:16.445686","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,956,544</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,089,152</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,000</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │     \u001b[38;5;34m2,956,544\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │     \u001b[38;5;34m3,089,152\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20000\u001b[0m)         │     \u001b[38;5;34m2,580,000\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,625,696</span> (32.90 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,625,696\u001b[0m (32.90 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,625,696</span> (32.90 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,625,696\u001b[0m (32.90 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["num_layers = 2    \n","d_model = 128        \n","dff = 512            \n","num_heads = 4        \n","dropout_rate = 0.1   \n","\n","\n","\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=x_voc_size,\n","    target_vocab_size=y_voc_size,\n","    pe_input=1000,\n","    pe_target=1000,\n","    rate=dropout_rate\n",")\n","\n","dummy_input = tf.constant([[1]*max_text_len], dtype=tf.int64)\n","dummy_target = tf.constant([[1]*max_summary_len], dtype=tf.int64)\n","_ = transformer(dummy_input, dummy_target, training=False)\n","transformer.summary()"]},{"cell_type":"code","execution_count":30,"id":"dd1b05a3","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:35:20.399857Z","iopub.status.busy":"2025-11-18T16:35:20.399224Z","iopub.status.idle":"2025-11-18T16:35:21.543863Z","shell.execute_reply":"2025-11-18T16:35:21.543045Z"},"papermill":{"duration":1.159379,"end_time":"2025-11-18T16:35:21.545108","exception":false,"start_time":"2025-11-18T16:35:20.385729","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Checkpoint restored from /kaggle/input/checkpoint162/ckpt-162\n","Learning rate: 0.000207436358\n","Optimizer step: 726240\n"]}],"source":["first_epoch = 0\n","\n","learning_rate = CustomSchedule(d_model, factor=2.0)\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate=learning_rate,\n","    beta_1=0.9,\n","    beta_2=0.98,\n","    epsilon=1e-9\n",")\n","\n","\n","checkpoint_path = \"/kaggle/working/checkpoints\"\n","ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","\n","curr_ckpt = 162\n","checkpoint_path_input = f\"/kaggle/input/checkpoint{curr_ckpt}/ckpt-{curr_ckpt}\"\n","if os.path.exists(checkpoint_path_input + \".index\"):\n","    status = ckpt.restore(checkpoint_path_input)\n","    status.assert_existing_objects_matched()\n","    print(f\"Checkpoint restored from {checkpoint_path_input}\")\n","    first_epoch = curr_ckpt\n","\n","tf.print(\"Learning rate:\", optimizer.learning_rate)\n","print(\"Optimizer step:\", optimizer.iterations.numpy())\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n","\n","\n","@tf.function\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(\n","            inp, \n","            tar_inp, \n","            training=True, \n","            enc_padding_mask=enc_padding_mask, \n","            look_ahead_mask=combined_mask, \n","            dec_padding_mask=dec_padding_mask\n","        )\n","\n","\n","        loss = loss_function(tar_real, predictions)\n","\n","    gradients = tape.gradient(loss, transformer.trainable_variables)    \n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    train_loss.update_state(loss)\n","    train_accuracy.update_state(accuracy_function(tar_real, predictions))"]},{"cell_type":"code","execution_count":31,"id":"feb6ca2a","metadata":{"execution":{"iopub.execute_input":"2025-11-18T16:35:21.569519Z","iopub.status.busy":"2025-11-18T16:35:21.569211Z","iopub.status.idle":"2025-11-18T18:20:08.951038Z","shell.execute_reply":"2025-11-18T18:20:08.950254Z"},"papermill":{"duration":6287.406545,"end_time":"2025-11-18T18:20:08.963668","exception":false,"start_time":"2025-11-18T16:35:21.557123","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 163 Accuracy 0.2058 Loss 6.2346 Time 208.33 seconds\n","Epoch 164 Accuracy 0.3247 Loss 4.8995 Time 181.78 seconds\n","Epoch 165 Accuracy 0.3984 Loss 4.2106 Time 181.54 seconds\n","Epoch 166 Accuracy 0.4441 Loss 3.7911 Time 181.23 seconds\n","Epoch 167 Accuracy 0.4733 Loss 3.5334 Time 181.74 seconds\n","Epoch 168 Accuracy 0.4929 Loss 3.3668 Time 181.59 seconds\n","Epoch 169 Accuracy 0.5072 Loss 3.2524 Time 179.47 seconds\n","Epoch 170 Accuracy 0.5186 Loss 3.1698 Time 180.66 seconds\n","Epoch 171 Accuracy 0.5273 Loss 3.1079 Time 179.10 seconds\n","Epoch 172 Accuracy 0.5346 Loss 3.0565 Time 179.24 seconds\n","Epoch 173 Accuracy 0.5411 Loss 3.0129 Time 179.10 seconds\n","Epoch 174 Accuracy 0.5464 Loss 2.9740 Time 179.67 seconds\n","Epoch 175 Accuracy 0.5513 Loss 2.9379 Time 179.24 seconds\n","Epoch 176 Accuracy 0.5557 Loss 2.9059 Time 179.17 seconds\n","Epoch 177 Accuracy 0.5596 Loss 2.8755 Time 179.27 seconds\n","Epoch 178 Accuracy 0.5631 Loss 2.8489 Time 179.12 seconds\n","Epoch 179 Accuracy 0.5664 Loss 2.8243 Time 178.67 seconds\n","Epoch 180 Accuracy 0.5697 Loss 2.7994 Time 178.72 seconds\n","Epoch 181 Accuracy 0.5720 Loss 2.7789 Time 177.46 seconds\n","Epoch 182 Accuracy 0.5751 Loss 2.7572 Time 177.98 seconds\n","Epoch 183 Accuracy 0.5775 Loss 2.7376 Time 178.69 seconds\n","Epoch 184 Accuracy 0.5797 Loss 2.7197 Time 180.38 seconds\n","Epoch 185 Accuracy 0.5820 Loss 2.7024 Time 179.86 seconds\n","Epoch 186 Accuracy 0.5844 Loss 2.6854 Time 179.65 seconds\n","Epoch 187 Accuracy 0.5865 Loss 2.6680 Time 179.92 seconds\n","Epoch 188 Accuracy 0.5882 Loss 2.6525 Time 179.69 seconds\n","Epoch 189 Accuracy 0.5898 Loss 2.6403 Time 179.06 seconds\n","Epoch 190 Accuracy 0.5919 Loss 2.6245 Time 177.28 seconds\n","Epoch 191 Accuracy 0.5935 Loss 2.6109 Time 176.11 seconds\n","Epoch 192 Accuracy 0.5950 Loss 2.5991 Time 175.99 seconds\n","Epoch 193 Accuracy 0.5969 Loss 2.5866 Time 175.55 seconds\n","Epoch 194 Accuracy 0.5983 Loss 2.5762 Time 175.42 seconds\n","Epoch 195 Accuracy 0.5997 Loss 2.5631 Time 175.72 seconds\n","Epoch 196 Accuracy 0.6012 Loss 2.5538 Time 175.50 seconds\n","Epoch 197 Accuracy 0.6026 Loss 2.5443 Time 175.48 seconds\n"]}],"source":["patience = 3  \n","best_loss = float('inf')\n","wait = 0\n","total_batches = tf.data.experimental.cardinality(dataset).numpy()\n","epochs = 35\n","\n","\n","for epoch in range(first_epoch, first_epoch + epochs):\n","    start = time.time()\n","    start_epoch = time.time()\n","    train_loss.reset_state()\n","    train_accuracy.reset_state()\n","\n","\n","    for (batch, (inp, tar)) in enumerate(dataset):\n","        start_batch = time.time()\n","        train_step(inp, tar)\n","        \n","        if (batch + 1) % 100 == 0 or (batch + 1) == total_batches:\n","            elapsed_batch = time.time() - start_epoch\n","            #print(f\"Epoch {epoch+1} Batch {batch+1}/{total_batches} \"\n","            #      f\"Accuracy {train_accuracy.result():.4f} \"\n","            #      f\"Loss {train_loss.result():.4f} \"\n","            #      f\"Time elapsed {elapsed_batch:.2f}s\")\n","\n","    current_loss = train_loss.result()\n","    \n","    if current_loss < best_loss:\n","        best_loss = current_loss\n","        wait = 0\n","        ckpt_save_path = ckpt_manager.save()\n","    else:\n","        wait += 1\n","        if wait >= patience:\n","            print(f\"Early stopping triggered at epoch {epoch+1}\")\n","            break\n","\n","    print(f'Epoch {epoch + 1} Accuracy {train_accuracy.result():.4f} Loss {current_loss:.4f} Time {time.time() - start:.2f} seconds')"]},{"cell_type":"code","execution_count":32,"id":"54e424aa","metadata":{"execution":{"iopub.execute_input":"2025-11-18T18:20:08.98709Z","iopub.status.busy":"2025-11-18T18:20:08.98686Z","iopub.status.idle":"2025-11-18T18:20:08.995101Z","shell.execute_reply":"2025-11-18T18:20:08.994389Z"},"papermill":{"duration":0.020979,"end_time":"2025-11-18T18:20:08.996174","exception":false,"start_time":"2025-11-18T18:20:08.975195","status":"completed"},"tags":[]},"outputs":[],"source":["def summarize(input_article, beam_width=3):\n","    input_article = sp_text.encode_as_ids(input_article)\n","    input_article = tf.keras.preprocessing.sequence.pad_sequences([input_article], maxlen=max_text_len, padding='post', truncating='post')\n","    encoder_input = tf.expand_dims(input_article[0], 0)\n","\n","    sos_id = sp_summary.piece_to_id('<SOS>')\n","    eos_id = sp_summary.piece_to_id('<EOS>')\n","\n","    sequences = [([sos_id], 0.0)]\n","    completed_sequences = []\n","\n","    for _ in range(max_summary_len):\n","        all_candidates = []\n","        for seq, score in sequences:\n","            if seq[-1] == eos_id:\n","                completed_sequences.append((seq, score))\n","                continue\n","\n","            output = tf.expand_dims(seq, 0)\n","            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n","\n","            predictions, _ = transformer(\n","                encoder_input, \n","                output,\n","                training=False,\n","                enc_padding_mask=enc_padding_mask,\n","                look_ahead_mask=combined_mask,\n","                dec_padding_mask=dec_padding_mask\n","            )\n","\n","            logits = predictions[:, -1, :]\n","            log_probs = tf.nn.log_softmax(logits)\n","            top_k = tf.math.top_k(log_probs, k=beam_width)\n","\n","            for i in range(beam_width):\n","                token = int(top_k.indices[0, i])\n","                candidate_score = score + float(top_k.values[0, i])\n","                candidate_seq = seq + [token]\n","                \n","                length_penalty = ((5 + len(candidate_seq)) / 6) ** 0.6\n","                normalized_score = candidate_score / length_penalty\n","\n","                \n","                all_candidates.append((candidate_seq, normalized_score))\n","\n","        sequences = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)[:beam_width]\n","\n","        if not sequences:\n","            break\n","\n","    completed_sequences.extend(sequences)\n","    best_seq = max(completed_sequences, key=lambda tup: tup[1])[0]\n","\n","    decoded = sp_summary.decode_ids(best_seq)\n","    decoded = decoded.replace(\"<SOS>\", \"\").replace(\"<EOS>\", \"\").strip()\n","    decoded = decoded.replace(\"&#39;\", \"'\").replace(\"&amp;\", \"&\")\n","    \n","    return decoded\n"]},{"cell_type":"code","execution_count":33,"id":"5a1c2d40","metadata":{"execution":{"iopub.execute_input":"2025-11-18T18:20:09.019338Z","iopub.status.busy":"2025-11-18T18:20:09.018865Z","iopub.status.idle":"2025-11-18T18:20:48.983556Z","shell.execute_reply":"2025-11-18T18:20:48.982626Z"},"papermill":{"duration":39.977764,"end_time":"2025-11-18T18:20:48.984933","exception":false,"start_time":"2025-11-18T18:20:09.007169","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Text : Defence Minister Arun Jaitley on Tuesday said the Army was allegedly cheated by revenue officials into paying rent for land which was in Pakistan-occupied Kashmir. Nine such instances have come to light, and the CBI has filed FIRs in two cases, Jaitley added. A probe found that documents were allegedly forged to show the land was in India's possession. \n","Real Headline : Army was cheated to pay rent for land in PoK Arun Jaitley \n","Summary : Army was accused of paying rent for land in PoK FM\n","\n","Text : Education technology startup Qonfuse on Monday raised an undisclosed amount in seed funding from CureInstant Founder Hamraj Kumar. Founded by Mahesh Gaur, Shivraj Dhusariya and Himanshu Srivastava, Qonfuse helps users prepare for competitive and other exams through an online exam interface similar to the actual one. It currently helps users to prepare for CAT, GATE, SSC exams among others. \n","Real Headline : Edtech startup Qonfuse raises seed funding \n","Summary : Startup Zonfuse raises seed funding\n","\n","Text : The 'Parthenon of Books', an art installation which is a replica of The Parthenon temple in Acropolis, Greece, has been created in Germany using about 1 lakh banned books to protest censorship. Created by Argentinian artist Marta Minujin, the installation is at the same site where Nazis set fire to books by Jewish and Marxist writers in 1933. \n","Real Headline : 'Parthenon' of 1L banned books created to protest censorship \n","Summary : Art of Book of Book of Book of Bookets temple created\n","\n","Text : A football match between clubs PSV Eindhoven and AFC Ajax in Netherlands' top division football league was halted as fans let off smoke bombs in the stands. The referee halted play five minutes into the second half as black smoke filled the stadium, with people having eye and respiratory problems. A 35-year-old man was reportedly arrested as a suspect. \n","Real Headline : Football match halted as fans let off smoke bombs in stands \n","Summary : Football match halts as fans allow smoke bombs in the stands\n","\n","Text : Barcelona came from behind to defeat 10-man Atl tico Madrid 2-1 in the first leg of the Champions League quarter-finals on Tuesday. Fernando Torres scored for Atl tico on 25 minutes, before getting sent-off in the 35th-minute for two bookable offences. A brace from Luis Su rez in the second-half gave Bar a the advantage going into the second leg on 13th April. \n","Real Headline : Barcelona defeat 10-man Atl tico Madrid 2-1 \n","Summary : Barcelona defeat Atlanta 2-1 in Champions League quarters\n","\n","Text : A Bengaluru police inspector has been suspended for allegedly refusing to file an FIR in a child sexual abuse case, saying that the boy would be traumatised with unnecessary tests and questions. The 16-year-old boy's parents had alleged that an air-conditioner repairman had tried to sexually assault the boy. The inspector later denied that the incident took place. \n","Real Headline : Policeman suspended for not registering child sexual abuse \n","Summary : B'luru policeman suspended for not to file FIR on child sexual abuse case\n","\n","Text : Six people were killed and five others were injured after a boiler blast occurred in a sugar factory in Karnataka's Bagalkot district on Sunday. The three-storey building collapsed as the boiler exploded and the cause of the explosion is yet to be known. The factory is reportedly owned by former BJP minister and Bilgi MLA Murugesh Nirani. \n","Real Headline : 6 killed, 5 injured after explosion in K'taka sugar factory \n","Summary : 6 killed, 5 injured after blast in sugar factory in K'taka\n","\n","Text : A Dinosaur-like creature's fossil was found during an excavation on Sunday in Uttarakhand's Jaspur, a small city 110 km from Nainital. The fossil's hind legs measure around 29 cm while the tail is around 5 cm long. Found at an abandoned electricity department land, the authorities would be sending the remains to Dehradun-based Wildlife Institute of India for further investigation. \n","Real Headline : Dinosaur-like animal's fossil found in Uttarakhand \n","Summary : World's first-like fossil found in U'khand\n","\n","Text : Choreographer Terence Lewis has jokingly said that he is not on drugs as dance itself gives him a high. When you start dancing, the internal chemistry of your body changes, your mind changes. You feel very powerful. It's like the biggest drug, he added. The choreographer was speaking on the occasion of World Dance Day. \n","Real Headline : I'm not on drugs as dance itself gives me a high Terence \n","Summary : Won't on drugs as dance itself, jokes, jokes Chore it is a high\n","\n","Text : Heavy rains and hailstorms in Maharashtra have claimed lives of 271 people since April this year, with 377 houses in the state completely damaged and 16,477 houses partially damaged. The rains also claimed 1,417 small domestic animals and 1,593 large cattle like cows, bulls and buffalos. The figures are compiled for the period from April 1, 2016 till date. \n","Real Headline : Heavy rains claimed 271 lives in Maharashtra since April \n","Summary : Death toll from 271 houses damaged in Maha this year\n"]}],"source":["for i in range(10):\n","    text = df_trans['text'][i]\n","    real_summary = df_trans['summary'][i]\n","    print(f\"\\nText : {text} \\nReal Headline : {real_summary} \\nSummary : {summarize(text)}\")"]},{"cell_type":"code","execution_count":34,"id":"0e7f758a","metadata":{"execution":{"iopub.execute_input":"2025-11-18T18:20:49.0105Z","iopub.status.busy":"2025-11-18T18:20:49.010239Z","iopub.status.idle":"2025-11-18T18:21:14.05392Z","shell.execute_reply":"2025-11-18T18:21:14.05321Z"},"papermill":{"duration":25.057327,"end_time":"2025-11-18T18:21:14.055061","exception":false,"start_time":"2025-11-18T18:20:48.997734","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Text : Apple Inc. announced a new campus in Austin, Texas, expected to create over 5,000 jobs by 2026, focusing on hardware R&D. CEO Tim Cook emphasized innovation and community commitment. \n","Summary : Apple to create new campus in US new websites\n","\n","Text : The Prime Minister held a press conference on Tuesday, unveiling new economic reforms aimed at boosting small businesses and creating job opportunities across the country. \n","Summary : New economic reforms to boost jobs across India\n","\n","Text : In yesterday’s football match, Barcelona defeated Real Madrid 3-1, with Messi scoring a hat-trick. The victory gives Barcelona an edge in the league standings. \n","Summary : Real Madrid defeat Real Madrid 3-1 in football match, beat Messi's hat-trick\n","\n","Text : A new study revealed that regular exercise and a balanced diet can significantly reduce the risk of heart disease and improve overall life expectancy. \n","Summary : 39 A man drill can reduce heart disease risk of heart disease 39\n","\n","Text : The latest Marvel movie broke box office records over the weekend, earning over $200 million globally in its opening weekend. \n","Summary : 39 Marvel break world records over weekend records weekend records over weekend records\n","\n","Text : Scientists discovered a new species of dolphin in the Pacific Ocean, highlighting the importance of marine conservation and biodiversity protection. \n","Summary : New species of dolphins discovered in Earth 39 s Ocean\n","\n","Text : The stock market saw a sharp increase today, with tech stocks leading the gains as investors responded positively to quarterly earnings reports. \n","Summary : What were the stock market rose today, says investors's stock market\n"]}],"source":["texts = [\n","    \"Apple Inc. announced a new campus in Austin, Texas, expected to create over 5,000 jobs by 2026, focusing on hardware R&D. CEO Tim Cook emphasized innovation and community commitment.\",\n","    \n","    \"The Prime Minister held a press conference on Tuesday, unveiling new economic reforms aimed at boosting small businesses and creating job opportunities across the country.\",\n","\n","    \"In yesterday’s football match, Barcelona defeated Real Madrid 3-1, with Messi scoring a hat-trick. The victory gives Barcelona an edge in the league standings.\",\n","    \n","    \"A new study revealed that regular exercise and a balanced diet can significantly reduce the risk of heart disease and improve overall life expectancy.\",\n","    \n","    \"The latest Marvel movie broke box office records over the weekend, earning over $200 million globally in its opening weekend.\",\n","    \n","    \"Scientists discovered a new species of dolphin in the Pacific Ocean, highlighting the importance of marine conservation and biodiversity protection.\",\n","    \n","    \"The stock market saw a sharp increase today, with tech stocks leading the gains as investors responded positively to quarterly earnings reports.\"\n","]\n","\n","for text in texts:\n","    print(f\"\\nText : {text} \\nSummary : {summarize(text)}\")"]},{"cell_type":"code","execution_count":35,"id":"818e54d4","metadata":{"execution":{"iopub.execute_input":"2025-11-18T18:21:14.080908Z","iopub.status.busy":"2025-11-18T18:21:14.080286Z","iopub.status.idle":"2025-11-18T18:21:18.955825Z","shell.execute_reply":"2025-11-18T18:21:18.955136Z"},"papermill":{"duration":4.88941,"end_time":"2025-11-18T18:21:18.957025","exception":false,"start_time":"2025-11-18T18:21:14.067615","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working/checkpoints/ckpt-197.data-00000-of-00001\n","/kaggle/working/checkpoints/ckpt-197.index\n","/kaggle/working/checkpoints/checkpoint\n"]},{"data":{"text/plain":["'/kaggle/working/checkpoints_backup.zip'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import shutil\n","\n","checkpoint_dir = '/kaggle/working/checkpoints'\n","for root, dirs, files in os.walk(checkpoint_dir):\n","    for file in files:\n","        print(os.path.join(root, file))\n","        \n","shutil.make_archive('/kaggle/working/checkpoints_backup', 'zip', '/kaggle/working/checkpoints')"]},{"cell_type":"markdown","id":"b6fda60d","metadata":{"papermill":{"duration":0.011712,"end_time":"2025-11-18T18:21:18.981651","exception":false,"start_time":"2025-11-18T18:21:18.969939","status":"completed"},"tags":[]},"source":["# Credits\n","\n","- **\"Implementing Seq2Seq Models for Text Summarization With Keras\"**  \n","  *by Samhita Alla* "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":33526,"isSourceIdPinned":false,"sourceId":44284,"sourceType":"datasetVersion"},{"datasetId":1895,"sourceId":791838,"sourceType":"datasetVersion"},{"datasetId":8762550,"sourceId":13768267,"sourceType":"datasetVersion"},{"datasetId":8768550,"sourceId":13776476,"sourceType":"datasetVersion"},{"datasetId":8771027,"sourceId":13779835,"sourceType":"datasetVersion"},{"isSourceIdPinned":false,"modelId":477297,"modelInstanceId":461540,"sourceId":614196,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":6493.060708,"end_time":"2025-11-18T18:21:22.198439","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-18T16:33:09.137731","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}