{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tommasofacchin/text-summarization-transformers-from-scratch?scriptVersionId=285162051\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e81a24c7","metadata":{"papermill":{"duration":0.005276,"end_time":"2025-12-10T10:59:26.174856","exception":false,"start_time":"2025-12-10T10:59:26.16958","status":"completed"},"tags":[]},"source":["# Seq2Seq and Encoder-Decoder\n","\n","## What is a Seq2Seq Model\n","A sequence-to-sequence (Seq2Seq) model is designed to take an input sequence and produce an output sequence. It’s widely used in tasks like machine translation, text summarization, and chatbots.\n","\n","**Example:**  \n","Input: \"Hello, how are you?\"  \n","Output: \"Ciao, come stai?\"\n","\n","---\n","\n","## Encoder-Decoder Architecture (Expanded)\n","\n","A typical Seq2Seq model has two main parts: the **encoder** and the **decoder**. The design allows the model to process sequences of variable length.  \n","\n","### Encoder\n","The encoder reads the input sequence and compresses it into a set of hidden states or a context vector. This vector captures the important information from the input and has a fixed size, though it does not need to match the decoder's size. The hidden states can either be passed as a whole to the decoder or connected at every decoding step.  \n","\n","At each step, the encoder updates its hidden state based on the previous hidden state and the current input. In mathematical terms, for a simple RNN:\n","\n","$$\n","H_t^{encoder} = \\phi(W_{HH} \\cdot H_{t-1}^{encoder} + W_{HX} \\cdot X_t)\n","$$\n","\n","Where:  \n","- $H_t^{encoder}$ = hidden state at time $t$ in the encoder  \n","- $X_t$ = input at time $t$  \n","- $W_{HH}$ = weight matrix connecting hidden states  \n","- $W_{HX}$ = weight matrix connecting input to hidden states  \n","- $\\phi$ = activation function (e.g., tanh or ReLU)\n","\n","---\n","\n","### Decoder\n","The decoder generates the output sequence one token at a time. Its initial hidden state is set to the final hidden state of the encoder. For a simple RNN decoder:\n","\n","$$\n","H_t^{decoder} = \\phi(W_{HH} \\cdot H_{t-1}^{decoder} + W_{HY} \\cdot Y_{t-1})\n","$$\n","\n","The output at each step is computed as:\n","\n","$$\n","Y_t = W_{HY} \\cdot H_t^{decoder}\n","$$\n","\n","Where:  \n","- $H_t^{decoder}$ = hidden state at time $t$ in the decoder  \n","- $Y_t$ = output at time $t$  \n","- $W_{HY}$ = weight matrix connecting decoder hidden state to output  \n","\n","### Implementation Notes\n","- Encoders and decoders are typically implemented with **RNNs, LSTMs, or GRUs**.  \n","- The input and output vectors are of fixed size, but the encoder and decoder can have different hidden dimensions.  \n","- During training, **teacher forcing** is often used, providing the correct previous token to the decoder instead of its own prediction.  \n","\n","---\n","\n","## Tokenization\n","\n","Before feeding text into a Seq2Seq or Transformer model, the raw text must be converted into numerical form.  \n","This is done through **tokenization**, which splits text into smaller units (tokens) such as words or subwords.  \n","\n","Each token is then mapped to a unique integer using a **vocabulary** built from the dataset.  \n","The model processes these integers rather than the raw text.\n","\n","**Example:**\n","\n","Input text: `\"Transformers improve summarization.\"`  \n","Tokens: `[\"transformers\", \"improve\", \"summarization\", \".\"]`  \n","Token IDs: `[201, 57, 1342, 4]`\n","\n","### Why Tokenization Matters\n","- Converts variable-length text into consistent, model-readable sequences.  \n","- Helps capture word frequency and context relationships.  \n","- Reduces vocabulary size when using subword tokenization (e.g., Byte Pair Encoding).  \n","\n","In this project, tokenization is part of preprocessing and includes:\n","- **Lowercasing** the text  \n","- **Removing special characters and URLs**  \n","- **Splitting into tokens by spaces**  \n","- Adding **start (`sostok`)** and **end (`eostok`)** tokens to mark summary boundaries  \n","\n","After tokenization, sequences will later be converted to integer IDs, padded or truncated to a fixed length\n","\n","---\n","\n","# Transformers\n","Transformers can be seen as an evolution of Seq2Seq models. Instead of processing sequences step by step like LSTMs or GRUs, they rely entirely on **attention mechanisms** to process all tokens in parallel and capture relationships between them.\n","\n","### Attention in Transformers\n","Attention is the core mechanism that allows Transformers to focus on relevant parts of the input sequence when producing a representation for each token. It works by comparing each token to all others and weighting them according to importance.\n","\n","#### How Attention Works\n","Each token in the sequence is represented by three vectors:\n","- **Query (Q):** what this token is looking for  \n","- **Key (K):** what information this token contains  \n","- **Value (V):** the actual information of the token  \n","\n","The attention score between two tokens is computed as the similarity between the Query of one token and the Key of another. This determines how much attention one token should pay to another. Mathematically, the attention weights are computed using a scaled dot-product:\n","\n","$$\n","\\text{Attention}(Q, K, V) = \\text{softmax}\\Big(\\frac{QK^T}{\\sqrt{d_k}}\\Big) V\n","$$\n","\n","Where $d_k$ is the dimensionality of the Key vectors.\n","\n","- The **softmax** ensures that the weights sum to 1.  \n","- Each token’s output is a weighted sum of all Value vectors, allowing it to incorporate context from the entire sequence.\n","\n","#### Multi-Head Attention\n","Instead of computing attention just once, Transformers use **multiple attention heads** in parallel. Each head can learn to focus on different types of relationships, such as:\n","- Syntactic relationships (e.g., subject-verb connections)  \n","- Semantic relationships (e.g., synonyms or related concepts)  \n","\n","The outputs of all heads are concatenated and projected to form the final representation for each token.\n","\n","#### Intuition\n","Imagine reading a sentence and highlighting all the words that are important for understanding each token. Each word “attends” to other words in the sentence that matter most for its meaning. Multi-head attention lets the model do this from multiple perspectives simultaneously.\n","\n","### Key Components of Transformers\n","- **Encoder-Decoder Structure:** Like Seq2Seq models, Transformers have an encoder that processes the input and a decoder that generates the output. Both use layers of self-attention and feed-forward networks.  \n","- **Positional Encoding:** Since Transformers don’t process tokens sequentially, they add positional information so the model knows the order of tokens.  \n","- **Feed-Forward Layers:** After attention, each token passes through fully connected layers for additional transformation.\n","\n","### Advantages over LSTM/GRU Seq2Seq\n","- Processes sequences **in parallel**, speeding up training.  \n","- Handles **long sequences** more effectively with attention.  \n","- Captures **complex relationships** between tokens regardless of distance.  \n","- Scales easily to **very deep models** and large datasets.\n","\n","### Use Cases\n","Transformers are the backbone of many state-of-the-art models for tasks such as:\n","- Machine translation (e.g., T5, MarianMT)  \n","- Text summarization (e.g., BART, Pegasus)  \n","- Question answering and chatbots (e.g., GPT, BERT-based models)"]},{"cell_type":"code","execution_count":1,"id":"1fb89893","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:26.184654Z","iopub.status.busy":"2025-12-10T10:59:26.1844Z","iopub.status.idle":"2025-12-10T10:59:26.19251Z","shell.execute_reply":"2025-12-10T10:59:26.192Z"},"papermill":{"duration":0.014315,"end_time":"2025-12-10T10:59:26.193563","exception":false,"start_time":"2025-12-10T10:59:26.179248","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","#!pip install sentencepiece"]},{"cell_type":"code","execution_count":2,"id":"23207955","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:26.20247Z","iopub.status.busy":"2025-12-10T10:59:26.202263Z","iopub.status.idle":"2025-12-10T10:59:30.343913Z","shell.execute_reply":"2025-12-10T10:59:30.342874Z"},"papermill":{"duration":4.147553,"end_time":"2025-12-10T10:59:30.345292","exception":false,"start_time":"2025-12-10T10:59:26.197739","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ft_tokenize\r\n","  Downloading ft_tokenize-0.1.8-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\r\n","Downloading ft_tokenize-0.1.8-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (596 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.4/596.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: ft_tokenize\r\n","Successfully installed ft_tokenize-0.1.8\r\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install ft_tokenize"]},{"cell_type":"markdown","id":"38789e41","metadata":{"papermill":{"duration":0.004347,"end_time":"2025-12-10T10:59:30.354438","exception":false,"start_time":"2025-12-10T10:59:30.350091","status":"completed"},"tags":[]},"source":["# Data Preparation\n","\n","Prepare and clean the dataset for the summarization model:\n","\n","- **Load datasets:** Read two CSV files containing news articles and their summaries.\n","- **Combine datasets:** Merge datasets while selecting relevant `text` and `summary` columns.\n","- **Text cleaning:**  \n","  - Convert text to lowercase.  \n","  - Remove special characters.  \n","  - Replace URLs with domain names.  \n","  - Reduce multiple spaces.\n","- **Tokenization:** Split cleaned text into tokens (words) and add `_START_` and `_END_` tokens for summaries.\n","- **Handle missing values:** Drop rows with missing `text` values.\n","- **Analyze sequence lengths:** Calculate word counts for texts and summaries.\n","- **Limit sequence lengths:** Restrict `text` to 100 words and `summary` to 15 words.\n","- **Add model tokens:** Prepend `sostok` and append `eostok` to all summaries to mark start and end for the model.\n"]},{"cell_type":"code","execution_count":3,"id":"101bbf0a","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:30.364303Z","iopub.status.busy":"2025-12-10T10:59:30.364065Z","iopub.status.idle":"2025-12-10T10:59:36.497777Z","shell.execute_reply":"2025-12-10T10:59:36.496953Z"},"papermill":{"duration":6.14018,"end_time":"2025-12-10T10:59:36.499036","exception":false,"start_time":"2025-12-10T10:59:30.358856","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["(55104, 5)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","\n","pd.set_option('display.max_colwidth', None)\n","data = pd.read_excel(\"/kaggle/input/inshorts-news-data/Inshorts Cleaned Data.xlsx\")\n","\n","print(data.shape)"]},{"cell_type":"code","execution_count":4,"id":"7ea8b01c","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:36.510615Z","iopub.status.busy":"2025-12-10T10:59:36.509861Z","iopub.status.idle":"2025-12-10T10:59:36.544466Z","shell.execute_reply":"2025-12-10T10:59:36.543762Z"},"papermill":{"duration":0.041862,"end_time":"2025-12-10T10:59:36.545631","exception":false,"start_time":"2025-12-10T10:59:36.503769","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Headline</th>\n","      <th>Short</th>\n","      <th>Source</th>\n","      <th>Time</th>\n","      <th>Publish Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4 ex-bank officials booked for cheating bank of ₹209 crore</td>\n","      <td>The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.</td>\n","      <td>The New Indian Express</td>\n","      <td>09:25:00</td>\n","      <td>2017-03-26</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Supreme Court to go paperless in 6 months: CJI</td>\n","      <td>Chief Justice JS Khehar has said the Supreme Court will go paperless in six to seven months in a bid to save funds and make the judiciary eco-friendly. He further said the apex court will collect all the records electronically from the lower courts and the high courts so that there is no need to file hard copies.</td>\n","      <td>Outlook</td>\n","      <td>22:18:00</td>\n","      <td>2017-03-25</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>At least 3 killed, 30 injured in blast in Sylhet, Bangladesh</td>\n","      <td>At least three people were killed, including a policeman, while 30 others were wounded on Saturday evening in two explosions in Sylhet, Bangladesh. The explosions were targetted at people and police officials who were witnessing an over 30-hour-long gunfight between extremists and commandos. Earlier on Friday, a man had blown himself up in front of a checkpoint near Dhaka Airport.</td>\n","      <td>Hindustan Times</td>\n","      <td>23:39:00</td>\n","      <td>2017-03-25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Why has Reliance been barred from trading in futures?</td>\n","      <td>Mukesh Ambani-led Reliance Industries (RIL) was barred from trading in futures market for a year over stake sale in Reliance Petroleum (RPL). In 2007, RIL sold 4.1% stake in RPL, but shares were first &amp;#39;short-sold&amp;#39; in futures market to avoid a fall in RPL stocks. Short sale means selling shares with plans to buy them back later at lower prices.</td>\n","      <td>Livemint</td>\n","      <td>23:08:00</td>\n","      <td>2017-03-25</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Was stopped from entering my own studio at Times Now: Arnab</td>\n","      <td>TV news anchor Arnab Goswami has said he was told he could not do the programme two days before leaving Times Now. &amp;#34;18th November was my last day, I was not allowed to enter my own studio,&amp;#34; Goswami added. &amp;#34;When you build an institution and are not allowed to enter your own studio, you feel sad,&amp;#34; the journalist further said.</td>\n","      <td>YouTube</td>\n","      <td>23:24:00</td>\n","      <td>2017-03-25</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                       Headline  \\\n","0    4 ex-bank officials booked for cheating bank of ₹209 crore   \n","1                Supreme Court to go paperless in 6 months: CJI   \n","2  At least 3 killed, 30 injured in blast in Sylhet, Bangladesh   \n","3         Why has Reliance been barred from trading in futures?   \n","4   Was stopped from entering my own studio at Times Now: Arnab   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                             Short  \\\n","0      The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.   \n","1                                                                       Chief Justice JS Khehar has said the Supreme Court will go paperless in six to seven months in a bid to save funds and make the judiciary eco-friendly. He further said the apex court will collect all the records electronically from the lower courts and the high courts so that there is no need to file hard copies.   \n","2  At least three people were killed, including a policeman, while 30 others were wounded on Saturday evening in two explosions in Sylhet, Bangladesh. The explosions were targetted at people and police officials who were witnessing an over 30-hour-long gunfight between extremists and commandos. Earlier on Friday, a man had blown himself up in front of a checkpoint near Dhaka Airport.   \n","3                                Mukesh Ambani-led Reliance Industries (RIL) was barred from trading in futures market for a year over stake sale in Reliance Petroleum (RPL). In 2007, RIL sold 4.1% stake in RPL, but shares were first &#39;short-sold&#39; in futures market to avoid a fall in RPL stocks. Short sale means selling shares with plans to buy them back later at lower prices.   \n","4                                            TV news anchor Arnab Goswami has said he was told he could not do the programme two days before leaving Times Now. &#34;18th November was my last day, I was not allowed to enter my own studio,&#34; Goswami added. &#34;When you build an institution and are not allowed to enter your own studio, you feel sad,&#34; the journalist further said.   \n","\n","                  Source      Time  Publish Date  \n","0  The New Indian Express  09:25:00   2017-03-26  \n","1                 Outlook  22:18:00   2017-03-25  \n","2         Hindustan Times  23:39:00   2017-03-25  \n","3                Livemint  23:08:00   2017-03-25  \n","4                 YouTube  23:24:00   2017-03-25  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head(5)"]},{"cell_type":"code","execution_count":5,"id":"213bd4ef","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:36.556047Z","iopub.status.busy":"2025-12-10T10:59:36.555801Z","iopub.status.idle":"2025-12-10T10:59:36.559609Z","shell.execute_reply":"2025-12-10T10:59:36.559096Z"},"papermill":{"duration":0.01,"end_time":"2025-12-10T10:59:36.56056","exception":false,"start_time":"2025-12-10T10:59:36.55056","status":"completed"},"tags":[]},"outputs":[],"source":["def clean_text(text):\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    text = text.replace(\"39\", \"'\") \n","    text = text.replace(\"34\", '\"') \n","    text = text.replace(\"’\", \"'\")\n","    text = re.sub(r\"[^A-Za-z0-9 ,.'’\\-?()\\\"]\", \" \", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    \n","    return text"]},{"cell_type":"code","execution_count":6,"id":"0ce350ae","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:36.570451Z","iopub.status.busy":"2025-12-10T10:59:36.570252Z","iopub.status.idle":"2025-12-10T10:59:38.415019Z","shell.execute_reply":"2025-12-10T10:59:38.413038Z"},"papermill":{"duration":1.851668,"end_time":"2025-12-10T10:59:38.416803","exception":false,"start_time":"2025-12-10T10:59:36.565135","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["(10000, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Gangster-turned-politician Mukhtar Ansari has won from the Mau constituency in Uttar Pradesh after polling 96,793 votes, defeating the nearest candidate by over 8,000 votes. Ansari, who was the sitting MLA from the constituency, had allied with the Mayawati-led Bahujan Samaj Party before the elections. Ansari has been accused of murdering a BJP MLA.</td>\n","      <td>Gangster-turned-politician Mukhtar Ansari wins by 8000 votes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Indira Gandhi has been the only woman till date to have presented the Union Budget of India in 1970-71. This came after Indira Gandhi, the then Prime Minister, took over the Finance portfolio after Morarji Desai resigned as the Minister of Finance. So far, she has been the only woman Finance Minister of India.</td>\n","      <td>Indira Gandhi only woman to have presented the budget</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                              text  \\\n","0  Gangster-turned-politician Mukhtar Ansari has won from the Mau constituency in Uttar Pradesh after polling 96,793 votes, defeating the nearest candidate by over 8,000 votes. Ansari, who was the sitting MLA from the constituency, had allied with the Mayawati-led Bahujan Samaj Party before the elections. Ansari has been accused of murdering a BJP MLA.   \n","1                                          Indira Gandhi has been the only woman till date to have presented the Union Budget of India in 1970-71. This came after Indira Gandhi, the then Prime Minister, took over the Finance portfolio after Morarji Desai resigned as the Minister of Finance. So far, she has been the only woman Finance Minister of India.   \n","\n","                                                        summary  \n","0  Gangster-turned-politician Mukhtar Ansari wins by 8000 votes  \n","1         Indira Gandhi only woman to have presented the budget  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.DataFrame()\n","\n","df['text'] = data['Short'].apply(clean_text)\n","df['summary'] = data['Headline'].apply(clean_text)\n","\n","df = df.sample(n=10000, random_state=42).reset_index(drop=True)\n","\n","print(df.shape)\n","df.head(2)"]},{"cell_type":"markdown","id":"c50d5c95","metadata":{"papermill":{"duration":0.004804,"end_time":"2025-12-10T10:59:38.430109","exception":false,"start_time":"2025-12-10T10:59:38.425305","status":"completed"},"tags":[]},"source":["# Transformer Model with Self-Attention\n","\n","Similar to the Seq2Seq architecture, the Transformer follows an **encoder–decoder structure**, but instead of recurrent layers it relies entirely on **Multi-Head Self-Attention**.  \n","This allows the model to process all tokens **in parallel** and learn relationships between words regardless of their distance in the sequence.\n","\n","During training, the model takes **two inputs**:  \n","1. The encoder input (`text`) – the tokenized article.  \n","2. The decoder input (`summary`) – the summary shifted by one token.  \n","\n","The **target output** is the summary shifted forward by one position. The decoder learns to predict each word based on the previously generated ones and the encoded representation of the full text.\n","\n","---\n","\n","**Encoder**  \n","- The input article sequence (`max_text_len`) is first transformed using an **Embedding layer**.  \n","- A **Positional Encoding** is added to preserve the order of words (since attention has no notion of sequence order by itself).  \n","- The embedded input is processed by one or more **Multi-Head Self-Attention** blocks:\n","  - Each word attends to **all other words** in the input\n","  - Relationships between distant tokens are captured more effectively than in RNNs  \n","- A **Feed-Forward Network** (FFN) refines the contextual representations.\n","- **Residual connections** and **Layer Normalization** improve gradient flow and training stability.\n","\n","---\n","\n","**Decoder**  \n","- Similar positional embeddings are applied to the shifted summary tokens.  \n","- The decoder uses two attention mechanisms:\n","  1. **Masked Self-Attention**: ensures the model cannot “peek” at future words when predicting the next token.\n","  2. **Encoder-Decoder Attention**: allows the decoder to focus on relevant parts of the input article.\n","- A **Feed-Forward Network** further processes the attended features.\n","- A final **Dense layer with Softmax** outputs a probability distribution over all words in the vocabulary at each time step.\n","\n","---\n","\n","**sostok and eostok**  \n","In sequence-to-sequence tasks such as abstractive text summarization, **special tokens** are essential for controlling how a model generates text:\n","\n","- `<sostok>` → marks the **start** of the output sequence  \n","- `<eostok>` → marks the **end** of the sequence  \n","\n","However, these tokens **do not** play the same role during training across different architectures.\n","\n","Transformers use **masked self-attention** in the decoder, meaning that at time *t* the model can only attend to **previous tokens**.\n","Therefore:\n","\n","- `<sostok>` must be present **only in the decoder input**  \n","- `<sostok>` must be removed from the decoder target  \n","\n","Predicting a start token would make no sense and causes failure modes such as:\n","\n","- the model repeatedly outputting `<sostok>`\n","- inability to begin sequences with meaningful content\n","\n","The EOS token **must remain in the targets**, because:\n","\n","- it teaches the model **when to stop writing**\n","- without it, generation may become too long or infinite\n","\n","LSTM encoder-decoder models:\n","\n","- receive the final hidden state as initial context\n","- do **not** use masked attention\n","- often ignore the first timestep in loss computation\n","\n","So `<sostok>` in targets is less harmful there.\n","\n","---\n","\n","Thanks to the Self-Attention mechanism, Transformers **capture global context efficiently** and typically produce **more coherent and fluent summaries**, especially for longer texts."]},{"cell_type":"markdown","id":"633d5080","metadata":{"papermill":{"duration":0.004513,"end_time":"2025-12-10T10:59:38.439303","exception":false,"start_time":"2025-12-10T10:59:38.43479","status":"completed"},"tags":[]},"source":["### Preparing Transformer Inputs\n","\n","To train the Transformer in an encoder–decoder setup, we need to properly structure the input data:\n","\n","- The **encoder input** is the full tokenized article (`x_train`)\n","- The **decoder input** is the summary sequence **shifted right**, starting with `<sostok>`\n","- The **decoder target** is the same summary **shifted left**, ending with `<eostok>`\n","\n","This shifting ensures that at each timestep the decoder learns to predict the **next** word using:\n","1. The previously processed summary tokens  \n","2. Attention over the encoder output  "]},{"cell_type":"markdown","id":"a6db14f9","metadata":{"papermill":{"duration":0.004526,"end_time":"2025-12-10T10:59:38.448412","exception":false,"start_time":"2025-12-10T10:59:38.443886","status":"completed"},"tags":[]},"source":["In text summarization, token-level accuracy can be misleading because it only measures whether each predicted token matches the ground truth at the same position. It does not capture semantic meaning, fluency, word order, or relevance, and it can be inflated by common tokens like padding or start/end markers. A model can have high accuracy while producing poor summaries. Better evaluation uses metrics like ROUGE-1, ROUGE-2, and ROUGE-L, which measure overlap of unigrams, bigrams, and longest common subsequences between generated and reference summaries. During training, it is better to monitor validation loss and evaluate summaries qualitatively or with ROUGE rather than relying on token accuracy."]},{"cell_type":"markdown","id":"e3156a03","metadata":{"papermill":{"duration":0.004437,"end_time":"2025-12-10T10:59:38.457499","exception":false,"start_time":"2025-12-10T10:59:38.453062","status":"completed"},"tags":[]},"source":["## Predict"]},{"cell_type":"markdown","id":"1f687384","metadata":{"papermill":{"duration":0.004545,"end_time":"2025-12-10T10:59:38.466613","exception":false,"start_time":"2025-12-10T10:59:38.462068","status":"completed"},"tags":[]},"source":["Note importanti:\n","\n","Look-ahead mask a inference non serve se generi un token alla volta (greedy decoding step-by-step).\n","\n","Padding mask dell’encoder serve al decoder per ignorare i pad token dell’input.\n","\n","Quando fai l’inference dovrai generare token uno per uno, aggiornando dec_input_inf ad ogni step."]},{"cell_type":"markdown","id":"be19cd4a","metadata":{"papermill":{"duration":0.004421,"end_time":"2025-12-10T10:59:38.475746","exception":false,"start_time":"2025-12-10T10:59:38.471325","status":"completed"},"tags":[]},"source":["Generated summary: ripete continuamente parole (cannot cannot cannot, power power power…) → questo è un loop di ripetizione, tipico dei modelli seq2seq che non hanno abbastanza regolarizzazione sulla generazione.\n","\n","Generated beam search summary: testo quasi completamente fuori tema → indica che il modello non ha appreso bene il contenuto semantico e il beam search amplifica le frasi che appaiono più “probabili” a livello di token, ma non corrette.\n"]},{"cell_type":"markdown","id":"d867a2c8","metadata":{"papermill":{"duration":0.004552,"end_time":"2025-12-10T10:59:38.48484","exception":false,"start_time":"2025-12-10T10:59:38.480288","status":"completed"},"tags":[]},"source":["Limiting the vocabulary in a Transformer is important because it reduces the size of the embedding matrices and the final softmax layer, making the model faster and lighter. It also helps prevent overfitting by removing extremely rare words that add noise rather than useful information. A smaller vocabulary uses less memory and often leads to more stable training, which can be important when working with limited hardware. However, reducing the vocabulary also means losing information, because words outside the limit are replaced with an unknown token. This can harm tasks like summarization, where specific terms, names, or technical words matter. A limited vocabulary also restricts what the model can generate, since it can only output words it knows.\n","\n","I tried limiting the vocabulary, but it ended up harming the model’s performance."]},{"cell_type":"markdown","id":"b7914a86","metadata":{"papermill":{"duration":0.004448,"end_time":"2025-12-10T10:59:38.493854","exception":false,"start_time":"2025-12-10T10:59:38.489406","status":"completed"},"tags":[]},"source":["We wanted to continue training a Transformer model after the first epoch without losing the optimizer state. The issue was that creating a new optimizer reset the step count, making the learning rate extremely small due to the warmup schedule. To fix this, we restored a full checkpoint including both the model and optimizer. This ensures the weights, optimizer moments, and step count are preserved, so the learning rate continues correctly. Training can now continue from where it left off, and checkpoints can be saved after each epoch to resume seamlessly in future sessions."]},{"cell_type":"markdown","id":"513cd14d","metadata":{"papermill":{"duration":0.004503,"end_time":"2025-12-10T10:59:38.502884","exception":false,"start_time":"2025-12-10T10:59:38.498381","status":"completed"},"tags":[]},"source":["Using a single tokenizer for both input text and summaries is a design choice with clear advantages and trade-offs. The main benefit is consistency: the encoder and decoder operate on the same vocabulary and token representations, which makes cross-attention easier to learn and stabilizes training. The model does not need to internally translate between two different symbolic systems, so convergence is faster and behavior is more predictable. A shared tokenizer also reduces the total number of parameters, avoids duplicated tokens, and improves generalization, especially for named entities, numbers, and rare words that appear in both input and output. Debugging is simpler because there is only one source of truth for tokenization.\n","\n","The main drawback is that a single tokenizer is a compromise between two different distributions. Input texts are long and diverse, while summaries are short and dense. A shared vocabulary may allocate capacity to tokens that are useful for the input but rarely needed in the output, slightly reducing efficiency. It also offers less control over the style and structure of the generated summaries compared to using a specialized tokenizer for the output. In addition, special tokens such as start and end markers must be handled carefully to avoid interfering with the encoder input.\n","\n","In practice, a single tokenizer is usually the better choice for summarization, translation, and other sequence-to-sequence tasks, especially with small or medium datasets and custom or experimental tokenizers. Separate tokenizers can make sense for very large datasets or highly specialized outputs, but they increase complexity and instability. For most practical cases, a shared tokenizer provides better stability, faster learning, and fewer hidden failure modes."]},{"cell_type":"markdown","id":"8b996154","metadata":{"papermill":{"duration":0.004481,"end_time":"2025-12-10T10:59:38.512067","exception":false,"start_time":"2025-12-10T10:59:38.507586","status":"completed"},"tags":[]},"source":["When resuming training from a checkpoint, the Transformer seems to start from zero only because the first batches always show very low accuracy. This is normal and not a sign of lost weights. The decoder struggles with the first tokens due to masking, so accuracy is naturally low at the start of each epoch. If the dataset uses a fixed shuffle and the same examples appear first every time, you will always see the same low accuracy at the beginning. The proof that the checkpoint is restored correctly is that the accuracy rises quickly after a few hundred batches, which would not happen if the model had really restarted from scratch."]},{"cell_type":"code","execution_count":7,"id":"a7bb2ac0","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:38.522563Z","iopub.status.busy":"2025-12-10T10:59:38.522323Z","iopub.status.idle":"2025-12-10T10:59:51.770663Z","shell.execute_reply":"2025-12-10T10:59:51.770041Z"},"papermill":{"duration":13.255459,"end_time":"2025-12-10T10:59:51.772185","exception":false,"start_time":"2025-12-10T10:59:38.516726","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-12-10 10:59:39.906952: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1765364380.096773      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1765364380.148374      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import tensorflow as tf\n","\n","# text_file = \"text.txt\"\n","# summary_file = \"summary.txt\"\n","# text_model_file = \"text_model.model\"\n","# summary_model_file = \"summary_model.model\"\n","\n","\n","# with open(text_file, \"w\", encoding=\"utf-8\") as f:\n","#         for t in df['text']:\n","#             f.write(t + \"\\n\")\n","\n","# with open(summary_file, \"w\", encoding=\"utf-8\") as f:\n","#         for t in df['summary']:\n","#             f.write(t + \"\\n\")\n","\n","with open(\"combined.txt\", \"w\", encoding=\"utf-8\") as f:\n","    for t in df['text']:\n","        f.write(t + \"\\n\")\n","    for s in df['summary']:\n","        f.write(s + \"\\n\")\n"]},{"cell_type":"code","execution_count":8,"id":"75d1b8c3","metadata":{"execution":{"iopub.execute_input":"2025-12-10T10:59:51.784912Z","iopub.status.busy":"2025-12-10T10:59:51.784131Z","iopub.status.idle":"2025-12-10T11:09:35.304101Z","shell.execute_reply":"2025-12-10T11:09:35.303344Z"},"papermill":{"duration":583.532045,"end_time":"2025-12-10T11:09:35.309977","exception":false,"start_time":"2025-12-10T10:59:51.777932","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Start tokenizers training\n","tokenizer trained\n","Size of vocabulary in X = 8003\n","Size of vocabulary in Y = 8003\n"]}],"source":["import ft_tokenize\n","\n","vocab_size = 8000\n","user_defined_symbols = [\"<SOS>\", \"<EOS>\", \" \"] \n","mode = ft_tokenize.TokenizerMode.BPE \n","\n","print(\"Start tokenizers training\")\n","\n","# text_tokenizer = ft_tokenize.TokenizerModel()\n","\n","# if os.path.exists(text_model_file):\n","#     text_tokenizer.load_model(text_model_file)\n","#     print(\"Text tokenizer loaded\")\n","# else:\n","#     text_tokenizer.train_from_textfile(text_file, vocab_size=vocab_size, user_defined_symbols=user_defined_symbols, mode=mode)\n","#     text_tokenizer.save_model(text_model_file)\n","#     print(\"Text tokenizer trained\")\n","\n","\n","# summary_tokenizer = ft_tokenize.TokenizerModel()\n","\n","# if os.path.exists(summary_model_file):\n","#     summary_tokenizer.load_model(summary_model_file)\n","#     print(\"Summary tokenizer loaded\")\n","# else:\n","#     summary_tokenizer.train_from_textfile(summary_file,  vocab_size=vocab_size, user_defined_symbols=user_defined_symbols, mode=mode)\n","#     summary_tokenizer.save_model(summary_model_file)\n","#     print(\"Summary tokenizer trained\")\n","\n","\n","tokenizer = ft_tokenize.TokenizerModel()\n","\n","if os.path.exists(\"combined.model\"):\n","    tokenizer.load_model(\"combined.model\")\n","    print(\"tokenizer loaded\")\n","else:\n","    tokenizer.train_from_textfile(\"combined.txt\",  vocab_size=vocab_size, user_defined_symbols=user_defined_symbols, mode=mode)\n","    tokenizer.save_model(\"combined.model\")\n","    print(\"tokenizer trained\")\n","\n","\n","# x_voc_size = text_tokenizer.get_token_size()\n","# y_voc_size = summary_tokenizer.get_token_size()\n","voc_size = tokenizer.get_token_size()\n","x_voc_size = voc_size\n","y_voc_size = voc_size\n","\n","print(f\"Size of vocabulary in X = {x_voc_size}\")\n","print(f\"Size of vocabulary in Y = {y_voc_size}\")"]},{"cell_type":"code","execution_count":9,"id":"f8bd2327","metadata":{"execution":{"iopub.execute_input":"2025-12-10T11:09:35.320569Z","iopub.status.busy":"2025-12-10T11:09:35.320341Z","iopub.status.idle":"2025-12-10T11:10:01.754559Z","shell.execute_reply":"2025-12-10T11:10:01.753811Z"},"papermill":{"duration":26.440882,"end_time":"2025-12-10T11:10:01.755763","exception":false,"start_time":"2025-12-10T11:09:35.314881","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["I0000 00:00:1765365001.716799      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# inputs = [text_tokenizer.encode_as_ids(t) for t in df['text']]\n","\n","# targets = [\n","#     [summary_tokenizer.token_to_id(\"<SOS>\")] +\n","#     summary_tokenizer.encode_as_ids(t) +\n","#     [summary_tokenizer.token_to_id(\"<EOS>\")]\n","#     for t in df['summary']\n","# ]\n","\n","inputs = [tokenizer.encode_as_ids(t) for t in df['text']]\n","targets = [[tokenizer.token_to_id(\"<SOS>\")] +\n","           tokenizer.encode_as_ids(t) +\n","           [tokenizer.token_to_id(\"<EOS>\")]\n","           for t in df['summary']]\n","\n","\n","max_text_len = 100\n","max_summary_len = 20\n","\n","inputs = pad_sequences(inputs, maxlen=max_text_len, padding='post', truncating='post')\n","targets = pad_sequences(targets, maxlen=max_summary_len, padding='post', truncating='post')\n","\n","inputs = tf.cast(inputs, dtype=tf.int64)\n","targets = tf.cast(targets, dtype=tf.int64)"]},{"cell_type":"code","execution_count":10,"id":"a0826595","metadata":{"execution":{"iopub.execute_input":"2025-12-10T11:10:01.767426Z","iopub.status.busy":"2025-12-10T11:10:01.767192Z","iopub.status.idle":"2025-12-10T11:10:03.205319Z","shell.execute_reply":"2025-12-10T11:10:03.204512Z"},"papermill":{"duration":1.445513,"end_time":"2025-12-10T11:10:03.206726","exception":false,"start_time":"2025-12-10T11:10:01.761213","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 32\n","dataset = (tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(10000, seed=42, reshuffle_each_iteration=False).batch(batch_size))\n","\n","\n","def get_angles(position, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return position * angle_rates\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(\n","        np.arange(position)[:, np.newaxis],\n","        np.arange(d_model)[np.newaxis, :],\n","        d_model\n","    )\n","\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    return seq[:, tf.newaxis, tf.newaxis, :]\n","\n","def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask\n","\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    #dk = tf.cast(tf.shape(k)[-1], q.dtype)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)  \n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","        \n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        \n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","        output = self.dense(concat_attention)\n","            \n","        return output, attention_weights\n","    \n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),\n","        tf.keras.layers.Dense(d_model)\n","    ])\n","\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, training=False, mask=None):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","    \n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","    \n","        return out2\n","\n","\n","\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","    \n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","    \n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","    \n","        return out3, attn_weights_block1, attn_weights_block2\n","\n","\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","    def call(self, x, training=False, mask=None):\n","        seq_len = tf.shape(x)[1]\n","    \n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        #x *= tf.math.sqrt(tf.cast(self.d_model, x.dtype)) \n","        #x += tf.cast(self.pos_encoding[:, :seq_len, :], x.dtype)\n","\n","        x = self.dropout(x, training=training)\n","    \n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training=training, mask=mask)\n","    \n","        return x\n","    \n","class Decoder(tf.keras.layers.Layer):\n","        \n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","    \n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        #x *= tf.math.sqrt(tf.cast(self.d_model, x.dtype))              \n","        #x += tf.cast(self.pos_encoding[:, :seq_len, :], x.dtype)      \n","\n","    \n","        x = self.dropout(x, training=training)\n","    \n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](\n","                x, \n","                enc_output, \n","                training=training, \n","                look_ahead_mask=look_ahead_mask, \n","                padding_mask=padding_mask\n","            )\n","            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n","            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n","    \n","        return x, attention_weights\n","\n","\n","\n","\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","    def call(self, inp, tar, training=False, enc_padding_mask=None, look_ahead_mask=None, dec_padding_mask=None):\n","        enc_output = self.encoder(x=inp, training=training, mask=enc_padding_mask)\n","        dec_output, attention_weights = self.decoder(x=tar, enc_output=enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n","        final_output = self.final_layer(dec_output)\n","        return final_output, attention_weights"]},{"cell_type":"code","execution_count":11,"id":"d1256a56","metadata":{"execution":{"iopub.execute_input":"2025-12-10T11:10:03.218138Z","iopub.status.busy":"2025-12-10T11:10:03.217905Z","iopub.status.idle":"2025-12-10T11:10:03.22621Z","shell.execute_reply":"2025-12-10T11:10:03.225538Z"},"papermill":{"duration":0.015191,"end_time":"2025-12-10T11:10:03.227232","exception":false,"start_time":"2025-12-10T11:10:03.212041","status":"completed"},"tags":[]},"outputs":[],"source":["import time\n","\n","def smooth_labels(labels, vocab_size, smoothing=0.05):\n","    confidence = 1.0 - smoothing\n","    low_conf = smoothing / tf.cast(vocab_size - 1, tf.float32)\n","    labels_one_hot = tf.one_hot(labels, depth=vocab_size)\n","    return labels_one_hot * confidence + low_conf\n","\n","def loss_function(real, pred):\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    smoothed_labels = smooth_labels(real, y_voc_size, smoothing=0)\n","    \n","    loss_ = tf.keras.losses.categorical_crossentropy(smoothed_labels, pred, from_logits=True)\n","    \n","    loss_ *= tf.cast(mask, dtype=loss_.dtype)\n","    return tf.reduce_sum(loss_) / tf.reduce_sum(tf.cast(mask, dtype=loss_.dtype))\n","\n","\n","def accuracy_function(real, pred):\n","    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n","    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n","\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    accuracies = tf.math.logical_and(mask, accuracies)\n","\n","    accuracies = tf.cast(accuracies, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n","\n","def create_masks(inp, tar):\n","    enc_padding_mask = create_padding_mask(inp)\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","    return enc_padding_mask, combined_mask, dec_padding_mask\n","\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=500, factor=1.0):\n","        super(CustomSchedule, self).__init__()\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","        self.warmup_steps = warmup_steps\n","        self.factor = factor\n","    \n","    def __call__(self, step):\n","        step = tf.cast(step, tf.float32) \n","        step = tf.maximum(step, 1.0)\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2) * self.factor"]},{"cell_type":"code","execution_count":12,"id":"efdcf76c","metadata":{"execution":{"iopub.execute_input":"2025-12-10T11:10:03.237679Z","iopub.status.busy":"2025-12-10T11:10:03.237475Z","iopub.status.idle":"2025-12-10T11:10:07.248681Z","shell.execute_reply":"2025-12-10T11:10:07.248004Z"},"papermill":{"duration":4.017678,"end_time":"2025-12-10T11:10:07.249791","exception":false,"start_time":"2025-12-10T11:10:03.232113","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,229,184</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,526,400</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8003</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,544,579</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │     \u001b[38;5;34m2,229,184\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │     \u001b[38;5;34m2,526,400\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m8003\u001b[0m)          │     \u001b[38;5;34m1,544,579\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,300,163</span> (24.03 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,300,163\u001b[0m (24.03 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,300,163</span> (24.03 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,300,163\u001b[0m (24.03 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["num_layers = 2    \n","d_model = 192#128        \n","dff = 512            \n","num_heads = 6#4        \n","dropout_rate = 0.1  \n","\n","\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=x_voc_size,\n","    target_vocab_size=y_voc_size,\n","    pe_input=1000,\n","    pe_target=1000,\n","    rate=dropout_rate\n",")\n","\n","dummy_input = tf.constant([[1]*max_text_len], dtype=tf.int64)\n","dummy_target = tf.constant([[1]*max_summary_len], dtype=tf.int64)\n","_ = transformer(dummy_input, dummy_target, training=False)\n","transformer.summary()"]},{"cell_type":"code","execution_count":13,"id":"2d05a3de","metadata":{"execution":{"iopub.execute_input":"2025-12-10T11:10:07.26226Z","iopub.status.busy":"2025-12-10T11:10:07.26201Z","iopub.status.idle":"2025-12-10T11:10:07.95476Z","shell.execute_reply":"2025-12-10T11:10:07.954127Z"},"papermill":{"duration":0.700105,"end_time":"2025-12-10T11:10:07.95579","exception":false,"start_time":"2025-12-10T11:10:07.255685","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning rate: 6.45497221e-06\n","Optimizer step: 0\n"]}],"source":["first_epoch = 0\n","\n","learning_rate = CustomSchedule(d_model, warmup_steps=500, factor=1.0)\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate=learning_rate,\n","    beta_1=0.9,\n","    beta_2=0.98,\n","    epsilon=1e-9\n",")\n","\n","\n","checkpoint_path = \"/kaggle/working/checkpoints\"\n","ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","\n","curr_ckpt = 0\n","checkpoint_path_input = f\"/kaggle/input/checkpoint{curr_ckpt}/ckpt-{curr_ckpt}\"\n","if os.path.exists(checkpoint_path_input + \".index\"):\n","    status = ckpt.restore(checkpoint_path_input)\n","    status.assert_existing_objects_matched()\n","    print(f\"Checkpoint restored from {checkpoint_path_input}\")\n","    first_epoch = curr_ckpt\n","\n","tf.print(\"Learning rate:\", optimizer.learning_rate)\n","print(\"Optimizer step:\", optimizer.iterations.numpy())\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n","\n","\n","@tf.function\n","def train_step(inp, tar):\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as tape:\n","        predictions, _ = transformer(\n","            inp, \n","            tar_inp, \n","            training=True, \n","            enc_padding_mask=enc_padding_mask, \n","            look_ahead_mask=combined_mask, \n","            dec_padding_mask=dec_padding_mask\n","        )\n","\n","\n","        loss = loss_function(tar_real, predictions)\n","\n","    gradients = tape.gradient(loss, transformer.trainable_variables)    \n","    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","\n","    train_loss.update_state(loss)\n","    train_accuracy.update_state(accuracy_function(tar_real, predictions))"]},{"cell_type":"code","execution_count":14,"id":"731c9e27","metadata":{"execution":{"iopub.execute_input":"2025-12-10T11:10:07.967875Z","iopub.status.busy":"2025-12-10T11:10:07.967633Z","iopub.status.idle":"2025-12-10T12:02:53.94642Z","shell.execute_reply":"2025-12-10T12:02:53.945577Z"},"papermill":{"duration":3165.986034,"end_time":"2025-12-10T12:02:53.947721","exception":false,"start_time":"2025-12-10T11:10:07.961687","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 001 | Accuracy 0.3974 | Loss 5.3115 | Time 33.63s | LR 0.002020\n","Epoch 002 | Accuracy 0.4246 | Loss 4.3335 | Time 10.48s | LR 0.002884\n","Epoch 003 | Accuracy 0.4296 | Loss 4.1054 | Time 10.47s | LR 0.002355\n","Epoch 004 | Accuracy 0.4358 | Loss 3.9415 | Time 10.48s | LR 0.002040\n","Epoch 005 | Accuracy 0.4406 | Loss 3.8203 | Time 10.47s | LR 0.001824\n","Epoch 006 | Accuracy 0.4454 | Loss 3.7234 | Time 10.47s | LR 0.001665\n","Epoch 007 | Accuracy 0.4496 | Loss 3.6412 | Time 10.47s | LR 0.001542\n","Epoch 008 | Accuracy 0.4529 | Loss 3.5772 | Time 10.48s | LR 0.001442\n","Epoch 009 | Accuracy 0.4561 | Loss 3.5175 | Time 10.48s | LR 0.001360\n","Epoch 010 | Accuracy 0.4591 | Loss 3.4669 | Time 10.48s | LR 0.001290\n","Epoch 011 | Accuracy 0.4626 | Loss 3.4154 | Time 10.47s | LR 0.001230\n","Epoch 012 | Accuracy 0.4657 | Loss 3.3581 | Time 10.48s | LR 0.001178\n","Epoch 013 | Accuracy 0.4684 | Loss 3.3039 | Time 10.47s | LR 0.001131\n","Epoch 014 | Accuracy 0.4709 | Loss 3.2480 | Time 10.48s | LR 0.001090\n","Epoch 015 | Accuracy 0.4743 | Loss 3.2113 | Time 10.48s | LR 0.001053\n","Epoch 016 | Accuracy 0.4761 | Loss 3.1754 | Time 10.49s | LR 0.001020\n","Epoch 017 | Accuracy 0.4782 | Loss 3.1400 | Time 10.49s | LR 0.000989\n","Epoch 018 | Accuracy 0.4803 | Loss 3.1136 | Time 10.47s | LR 0.000961\n","Epoch 019 | Accuracy 0.4815 | Loss 3.0968 | Time 10.47s | LR 0.000936\n","Epoch 020 | Accuracy 0.4839 | Loss 3.0763 | Time 10.48s | LR 0.000912\n","Epoch 021 | Accuracy 0.4866 | Loss 3.0389 | Time 10.49s | LR 0.000890\n","Epoch 022 | Accuracy 0.4881 | Loss 3.0105 | Time 10.48s | LR 0.000870\n","Epoch 023 | Accuracy 0.4902 | Loss 2.9863 | Time 10.48s | LR 0.000851\n","Epoch 024 | Accuracy 0.4913 | Loss 2.9627 | Time 10.48s | LR 0.000833\n","Epoch 025 | Accuracy 0.4938 | Loss 2.9292 | Time 10.47s | LR 0.000816\n","Epoch 026 | Accuracy 0.4964 | Loss 2.9042 | Time 10.47s | LR 0.000800\n","Epoch 027 | Accuracy 0.4970 | Loss 2.8865 | Time 10.47s | LR 0.000785\n","Epoch 028 | Accuracy 0.4996 | Loss 2.8649 | Time 10.47s | LR 0.000771\n","Epoch 029 | Accuracy 0.5011 | Loss 2.8392 | Time 10.47s | LR 0.000757\n","Epoch 030 | Accuracy 0.5027 | Loss 2.8207 | Time 10.48s | LR 0.000745\n","Epoch 031 | Accuracy 0.5043 | Loss 2.7979 | Time 10.48s | LR 0.000733\n","Epoch 032 | Accuracy 0.5049 | Loss 2.7828 | Time 10.48s | LR 0.000721\n","Epoch 033 | Accuracy 0.5074 | Loss 2.7545 | Time 10.48s | LR 0.000710\n","Epoch 034 | Accuracy 0.5089 | Loss 2.7414 | Time 10.48s | LR 0.000700\n","Epoch 035 | Accuracy 0.5105 | Loss 2.7230 | Time 10.48s | LR 0.000690\n","Epoch 036 | Accuracy 0.5116 | Loss 2.7071 | Time 10.48s | LR 0.000680\n","Epoch 037 | Accuracy 0.5142 | Loss 2.6797 | Time 10.48s | LR 0.000671\n","Epoch 038 | Accuracy 0.5150 | Loss 2.6607 | Time 10.48s | LR 0.000662\n","Epoch 039 | Accuracy 0.5171 | Loss 2.6369 | Time 10.48s | LR 0.000653\n","Epoch 040 | Accuracy 0.5188 | Loss 2.6288 | Time 10.48s | LR 0.000645\n","Epoch 041 | Accuracy 0.5207 | Loss 2.6071 | Time 10.47s | LR 0.000637\n","Epoch 042 | Accuracy 0.5209 | Loss 2.5876 | Time 10.47s | LR 0.000629\n","Epoch 043 | Accuracy 0.5227 | Loss 2.5713 | Time 10.48s | LR 0.000622\n","Epoch 044 | Accuracy 0.5237 | Loss 2.5553 | Time 10.47s | LR 0.000615\n","Epoch 045 | Accuracy 0.5266 | Loss 2.5333 | Time 10.48s | LR 0.000608\n","Epoch 046 | Accuracy 0.5277 | Loss 2.5193 | Time 10.47s | LR 0.000601\n","Epoch 047 | Accuracy 0.5283 | Loss 2.5138 | Time 10.47s | LR 0.000595\n","Epoch 048 | Accuracy 0.5299 | Loss 2.5022 | Time 10.47s | LR 0.000589\n","Epoch 049 | Accuracy 0.5325 | Loss 2.4785 | Time 10.48s | LR 0.000583\n","Epoch 050 | Accuracy 0.5340 | Loss 2.4576 | Time 10.48s | LR 0.000577\n","Epoch 051 | Accuracy 0.5360 | Loss 2.4387 | Time 10.49s | LR 0.000571\n","Epoch 052 | Accuracy 0.5377 | Loss 2.4168 | Time 10.48s | LR 0.000566\n","Epoch 053 | Accuracy 0.5386 | Loss 2.4035 | Time 10.48s | LR 0.000560\n","Epoch 054 | Accuracy 0.5412 | Loss 2.3858 | Time 10.48s | LR 0.000555\n","Epoch 055 | Accuracy 0.5412 | Loss 2.3765 | Time 10.47s | LR 0.000550\n","Epoch 056 | Accuracy 0.5416 | Loss 2.3676 | Time 10.47s | LR 0.000545\n","Epoch 057 | Accuracy 0.5427 | Loss 2.3604 | Time 10.47s | LR 0.000540\n","Epoch 058 | Accuracy 0.5445 | Loss 2.3453 | Time 10.47s | LR 0.000536\n","Epoch 059 | Accuracy 0.5464 | Loss 2.3298 | Time 10.47s | LR 0.000531\n","Epoch 060 | Accuracy 0.5484 | Loss 2.3158 | Time 10.46s | LR 0.000527\n","Epoch 061 | Accuracy 0.5500 | Loss 2.3005 | Time 10.47s | LR 0.000522\n","Epoch 062 | Accuracy 0.5512 | Loss 2.2951 | Time 10.47s | LR 0.000518\n","Epoch 063 | Accuracy 0.5523 | Loss 2.2784 | Time 10.47s | LR 0.000514\n","Epoch 064 | Accuracy 0.5530 | Loss 2.2728 | Time 10.47s | LR 0.000510\n","Epoch 065 | Accuracy 0.5547 | Loss 2.2486 | Time 10.46s | LR 0.000506\n","Epoch 066 | Accuracy 0.5568 | Loss 2.2378 | Time 10.48s | LR 0.000502\n","Epoch 067 | Accuracy 0.5585 | Loss 2.2259 | Time 10.48s | LR 0.000498\n","Epoch 068 | Accuracy 0.5587 | Loss 2.2171 | Time 10.48s | LR 0.000495\n","Epoch 069 | Accuracy 0.5613 | Loss 2.2053 | Time 10.48s | LR 0.000491\n","Epoch 070 | Accuracy 0.5621 | Loss 2.1932 | Time 10.48s | LR 0.000488\n","Epoch 071 | Accuracy 0.5635 | Loss 2.1798 | Time 10.48s | LR 0.000484\n","Epoch 072 | Accuracy 0.5641 | Loss 2.1729 | Time 10.48s | LR 0.000481\n","Epoch 073 | Accuracy 0.5664 | Loss 2.1570 | Time 10.47s | LR 0.000477\n","Epoch 074 | Accuracy 0.5691 | Loss 2.1459 | Time 10.48s | LR 0.000474\n","Epoch 075 | Accuracy 0.5696 | Loss 2.1406 | Time 10.47s | LR 0.000471\n","Epoch 076 | Accuracy 0.5692 | Loss 2.1339 | Time 10.48s | LR 0.000468\n","Epoch 077 | Accuracy 0.5712 | Loss 2.1279 | Time 10.48s | LR 0.000465\n","Epoch 078 | Accuracy 0.5718 | Loss 2.1103 | Time 10.47s | LR 0.000462\n","Epoch 079 | Accuracy 0.5749 | Loss 2.0869 | Time 10.47s | LR 0.000459\n","Epoch 080 | Accuracy 0.5779 | Loss 2.0722 | Time 10.48s | LR 0.000456\n","Epoch 081 | Accuracy 0.5795 | Loss 2.0604 | Time 10.48s | LR 0.000453\n","Epoch 082 | Accuracy 0.5826 | Loss 2.0428 | Time 10.48s | LR 0.000450\n","Epoch 083 | Accuracy 0.5827 | Loss 2.0305 | Time 10.48s | LR 0.000448\n","Epoch 084 | Accuracy 0.5836 | Loss 2.0245 | Time 10.48s | LR 0.000445\n","Epoch 085 | Accuracy 0.5840 | Loss 2.0222 | Time 10.47s | LR 0.000442\n","Epoch 086 | Accuracy 0.5870 | Loss 2.0043 | Time 10.46s | LR 0.000440\n","Epoch 087 | Accuracy 0.5895 | Loss 1.9880 | Time 10.47s | LR 0.000437\n","Epoch 088 | Accuracy 0.5888 | Loss 1.9870 | Time 10.47s | LR 0.000435\n","Epoch 089 | Accuracy 0.5901 | Loss 1.9782 | Time 10.48s | LR 0.000432\n","Epoch 090 | Accuracy 0.5928 | Loss 1.9612 | Time 10.47s | LR 0.000430\n","Epoch 091 | Accuracy 0.5934 | Loss 1.9548 | Time 10.48s | LR 0.000428\n","Epoch 092 | Accuracy 0.5948 | Loss 1.9450 | Time 10.47s | LR 0.000425\n","Epoch 093 | Accuracy 0.5958 | Loss 1.9371 | Time 10.47s | LR 0.000423\n","Epoch 094 | Accuracy 0.5973 | Loss 1.9299 | Time 10.48s | LR 0.000421\n","Epoch 095 | Accuracy 0.5982 | Loss 1.9157 | Time 10.47s | LR 0.000419\n","Epoch 096 | Accuracy 0.5989 | Loss 1.9153 | Time 10.47s | LR 0.000416\n","Epoch 097 | Accuracy 0.6011 | Loss 1.9063 | Time 10.48s | LR 0.000414\n","Epoch 098 | Accuracy 0.6015 | Loss 1.8980 | Time 10.48s | LR 0.000412\n","Epoch 099 | Accuracy 0.6052 | Loss 1.8827 | Time 10.47s | LR 0.000410\n","Epoch 100 | Accuracy 0.6050 | Loss 1.8733 | Time 10.47s | LR 0.000408\n","Epoch 101 | Accuracy 0.6063 | Loss 1.8739 | Time 10.48s | LR 0.000406\n","Epoch 102 | Accuracy 0.6061 | Loss 1.8697 | Time 10.48s | LR 0.000404\n","Epoch 103 | Accuracy 0.6056 | Loss 1.8763 | Time 10.48s | LR 0.000402\n","Epoch 104 | Accuracy 0.6082 | Loss 1.8616 | Time 10.47s | LR 0.000400\n","Epoch 105 | Accuracy 0.6104 | Loss 1.8446 | Time 10.48s | LR 0.000398\n","Epoch 106 | Accuracy 0.6107 | Loss 1.8402 | Time 10.48s | LR 0.000396\n","Epoch 107 | Accuracy 0.6116 | Loss 1.8357 | Time 10.48s | LR 0.000394\n","Epoch 108 | Accuracy 0.6138 | Loss 1.8261 | Time 10.47s | LR 0.000393\n","Epoch 109 | Accuracy 0.6136 | Loss 1.8226 | Time 10.47s | LR 0.000391\n","Epoch 110 | Accuracy 0.6145 | Loss 1.8155 | Time 10.49s | LR 0.000389\n","Epoch 111 | Accuracy 0.6156 | Loss 1.8090 | Time 10.47s | LR 0.000387\n","Epoch 112 | Accuracy 0.6184 | Loss 1.7976 | Time 10.48s | LR 0.000385\n","Epoch 113 | Accuracy 0.6186 | Loss 1.7914 | Time 10.47s | LR 0.000384\n","Epoch 114 | Accuracy 0.6201 | Loss 1.7851 | Time 10.47s | LR 0.000382\n","Epoch 115 | Accuracy 0.6196 | Loss 1.7821 | Time 10.47s | LR 0.000380\n","Epoch 116 | Accuracy 0.6218 | Loss 1.7752 | Time 10.47s | LR 0.000379\n","Epoch 117 | Accuracy 0.6199 | Loss 1.7844 | Time 10.47s | LR 0.000377\n","Epoch 118 | Accuracy 0.6212 | Loss 1.7744 | Time 10.48s | LR 0.000376\n","Epoch 119 | Accuracy 0.6202 | Loss 1.7838 | Time 10.47s | LR 0.000374\n","Epoch 120 | Accuracy 0.6206 | Loss 1.7710 | Time 10.48s | LR 0.000372\n","Epoch 121 | Accuracy 0.6206 | Loss 1.7799 | Time 10.48s | LR 0.000371\n","Epoch 122 | Accuracy 0.6217 | Loss 1.7708 | Time 10.48s | LR 0.000369\n","Epoch 123 | Accuracy 0.6248 | Loss 1.7543 | Time 10.48s | LR 0.000368\n","Epoch 124 | Accuracy 0.6262 | Loss 1.7517 | Time 10.48s | LR 0.000366\n","Epoch 125 | Accuracy 0.6280 | Loss 1.7355 | Time 10.48s | LR 0.000365\n","Epoch 126 | Accuracy 0.6282 | Loss 1.7354 | Time 10.47s | LR 0.000363\n","Epoch 127 | Accuracy 0.6291 | Loss 1.7278 | Time 10.47s | LR 0.000362\n","Epoch 128 | Accuracy 0.6290 | Loss 1.7284 | Time 10.48s | LR 0.000361\n","Epoch 129 | Accuracy 0.6285 | Loss 1.7255 | Time 10.48s | LR 0.000359\n","Epoch 130 | Accuracy 0.6304 | Loss 1.7189 | Time 10.47s | LR 0.000358\n","Epoch 131 | Accuracy 0.6326 | Loss 1.7077 | Time 10.48s | LR 0.000356\n","Epoch 132 | Accuracy 0.6309 | Loss 1.7133 | Time 10.48s | LR 0.000355\n","Epoch 133 | Accuracy 0.6344 | Loss 1.7002 | Time 10.48s | LR 0.000354\n","Epoch 134 | Accuracy 0.6345 | Loss 1.6956 | Time 10.47s | LR 0.000352\n","Epoch 135 | Accuracy 0.6364 | Loss 1.6840 | Time 10.47s | LR 0.000351\n","Epoch 136 | Accuracy 0.6369 | Loss 1.6821 | Time 10.48s | LR 0.000350\n","Epoch 137 | Accuracy 0.6370 | Loss 1.6825 | Time 10.47s | LR 0.000349\n","Epoch 138 | Accuracy 0.6391 | Loss 1.6666 | Time 10.47s | LR 0.000347\n","Epoch 139 | Accuracy 0.6377 | Loss 1.6730 | Time 10.48s | LR 0.000346\n","Epoch 140 | Accuracy 0.6402 | Loss 1.6601 | Time 10.49s | LR 0.000345\n","Epoch 141 | Accuracy 0.6408 | Loss 1.6563 | Time 10.48s | LR 0.000344\n","Epoch 142 | Accuracy 0.6397 | Loss 1.6609 | Time 10.48s | LR 0.000342\n","Epoch 143 | Accuracy 0.6402 | Loss 1.6612 | Time 10.47s | LR 0.000341\n","Epoch 144 | Accuracy 0.6408 | Loss 1.6592 | Time 10.47s | LR 0.000340\n","Epoch 145 | Accuracy 0.6384 | Loss 1.6683 | Time 10.48s | LR 0.000339\n","Epoch 146 | Accuracy 0.6423 | Loss 1.6496 | Time 10.47s | LR 0.000338\n","Epoch 147 | Accuracy 0.6406 | Loss 1.6603 | Time 10.48s | LR 0.000336\n","Epoch 148 | Accuracy 0.6421 | Loss 1.6533 | Time 10.47s | LR 0.000335\n","Epoch 149 | Accuracy 0.6423 | Loss 1.6516 | Time 10.47s | LR 0.000334\n","Epoch 150 | Accuracy 0.6425 | Loss 1.6462 | Time 10.47s | LR 0.000333\n","Epoch 151 | Accuracy 0.6447 | Loss 1.6338 | Time 10.47s | LR 0.000332\n","Epoch 152 | Accuracy 0.6453 | Loss 1.6339 | Time 10.48s | LR 0.000331\n","Epoch 153 | Accuracy 0.6450 | Loss 1.6315 | Time 10.47s | LR 0.000330\n","Epoch 154 | Accuracy 0.6455 | Loss 1.6352 | Time 10.47s | LR 0.000329\n","Epoch 155 | Accuracy 0.6479 | Loss 1.6241 | Time 10.48s | LR 0.000328\n","Epoch 156 | Accuracy 0.6485 | Loss 1.6160 | Time 10.47s | LR 0.000327\n","Epoch 157 | Accuracy 0.6481 | Loss 1.6188 | Time 10.47s | LR 0.000326\n","Epoch 158 | Accuracy 0.6482 | Loss 1.6166 | Time 10.47s | LR 0.000325\n","Epoch 159 | Accuracy 0.6460 | Loss 1.6241 | Time 10.48s | LR 0.000324\n","Epoch 160 | Accuracy 0.6494 | Loss 1.6102 | Time 10.48s | LR 0.000322\n","Epoch 161 | Accuracy 0.6503 | Loss 1.6078 | Time 10.47s | LR 0.000321\n","Epoch 162 | Accuracy 0.6525 | Loss 1.5975 | Time 10.48s | LR 0.000320\n","Epoch 163 | Accuracy 0.6538 | Loss 1.5909 | Time 10.48s | LR 0.000320\n","Epoch 164 | Accuracy 0.6529 | Loss 1.5884 | Time 10.48s | LR 0.000319\n","Epoch 165 | Accuracy 0.6554 | Loss 1.5796 | Time 10.47s | LR 0.000318\n","Epoch 166 | Accuracy 0.6548 | Loss 1.5817 | Time 10.48s | LR 0.000317\n","Epoch 167 | Accuracy 0.6566 | Loss 1.5731 | Time 10.48s | LR 0.000316\n","Epoch 168 | Accuracy 0.6579 | Loss 1.5645 | Time 10.47s | LR 0.000315\n","Epoch 169 | Accuracy 0.6585 | Loss 1.5570 | Time 10.49s | LR 0.000314\n","Epoch 170 | Accuracy 0.6592 | Loss 1.5562 | Time 10.48s | LR 0.000313\n","Epoch 171 | Accuracy 0.6617 | Loss 1.5450 | Time 10.48s | LR 0.000312\n","Epoch 172 | Accuracy 0.6623 | Loss 1.5445 | Time 10.47s | LR 0.000311\n","Epoch 173 | Accuracy 0.6616 | Loss 1.5413 | Time 10.48s | LR 0.000310\n","Epoch 174 | Accuracy 0.6633 | Loss 1.5309 | Time 10.48s | LR 0.000309\n","Epoch 175 | Accuracy 0.6657 | Loss 1.5245 | Time 10.47s | LR 0.000308\n","Epoch 176 | Accuracy 0.6673 | Loss 1.5186 | Time 10.47s | LR 0.000307\n","Epoch 177 | Accuracy 0.6666 | Loss 1.5178 | Time 10.47s | LR 0.000307\n","Epoch 178 | Accuracy 0.6676 | Loss 1.5100 | Time 10.48s | LR 0.000306\n","Epoch 179 | Accuracy 0.6675 | Loss 1.5136 | Time 10.47s | LR 0.000305\n","Epoch 180 | Accuracy 0.6692 | Loss 1.5023 | Time 10.48s | LR 0.000304\n","Epoch 181 | Accuracy 0.6683 | Loss 1.5037 | Time 10.46s | LR 0.000303\n","Epoch 182 | Accuracy 0.6709 | Loss 1.4928 | Time 10.47s | LR 0.000302\n","Epoch 183 | Accuracy 0.6724 | Loss 1.4831 | Time 10.47s | LR 0.000302\n","Epoch 184 | Accuracy 0.6721 | Loss 1.4846 | Time 10.48s | LR 0.000301\n","Epoch 185 | Accuracy 0.6713 | Loss 1.4868 | Time 10.47s | LR 0.000300\n","Epoch 186 | Accuracy 0.6735 | Loss 1.4801 | Time 10.48s | LR 0.000299\n","Epoch 187 | Accuracy 0.6739 | Loss 1.4758 | Time 10.47s | LR 0.000298\n","Epoch 188 | Accuracy 0.6755 | Loss 1.4685 | Time 10.47s | LR 0.000298\n","Epoch 189 | Accuracy 0.6742 | Loss 1.4730 | Time 10.47s | LR 0.000297\n","Epoch 190 | Accuracy 0.6756 | Loss 1.4630 | Time 10.47s | LR 0.000296\n","Epoch 191 | Accuracy 0.6770 | Loss 1.4582 | Time 10.48s | LR 0.000295\n","Epoch 192 | Accuracy 0.6779 | Loss 1.4520 | Time 10.47s | LR 0.000294\n","Epoch 193 | Accuracy 0.6775 | Loss 1.4545 | Time 10.47s | LR 0.000294\n","Epoch 194 | Accuracy 0.6786 | Loss 1.4464 | Time 10.47s | LR 0.000293\n","Epoch 195 | Accuracy 0.6795 | Loss 1.4439 | Time 10.47s | LR 0.000292\n","Epoch 196 | Accuracy 0.6807 | Loss 1.4368 | Time 10.47s | LR 0.000291\n","Epoch 197 | Accuracy 0.6810 | Loss 1.4383 | Time 10.47s | LR 0.000291\n","Epoch 198 | Accuracy 0.6813 | Loss 1.4323 | Time 10.47s | LR 0.000290\n","Epoch 199 | Accuracy 0.6836 | Loss 1.4262 | Time 10.49s | LR 0.000289\n","Epoch 200 | Accuracy 0.6854 | Loss 1.4180 | Time 10.48s | LR 0.000288\n","Epoch 201 | Accuracy 0.6842 | Loss 1.4202 | Time 10.48s | LR 0.000288\n","Epoch 202 | Accuracy 0.6852 | Loss 1.4114 | Time 10.47s | LR 0.000287\n","Epoch 203 | Accuracy 0.6863 | Loss 1.4093 | Time 10.48s | LR 0.000286\n","Epoch 204 | Accuracy 0.6876 | Loss 1.4036 | Time 10.47s | LR 0.000286\n","Epoch 205 | Accuracy 0.6881 | Loss 1.3969 | Time 10.48s | LR 0.000285\n","Epoch 206 | Accuracy 0.6894 | Loss 1.3939 | Time 10.48s | LR 0.000284\n","Epoch 207 | Accuracy 0.6895 | Loss 1.3926 | Time 10.47s | LR 0.000284\n","Epoch 208 | Accuracy 0.6903 | Loss 1.3880 | Time 10.47s | LR 0.000283\n","Epoch 209 | Accuracy 0.6903 | Loss 1.3853 | Time 10.47s | LR 0.000282\n","Epoch 210 | Accuracy 0.6912 | Loss 1.3862 | Time 10.47s | LR 0.000281\n","Epoch 211 | Accuracy 0.6921 | Loss 1.3829 | Time 10.47s | LR 0.000281\n","Epoch 212 | Accuracy 0.6924 | Loss 1.3746 | Time 10.47s | LR 0.000280\n","Epoch 213 | Accuracy 0.6932 | Loss 1.3712 | Time 10.48s | LR 0.000280\n","Epoch 214 | Accuracy 0.6930 | Loss 1.3759 | Time 10.48s | LR 0.000279\n","Epoch 215 | Accuracy 0.6951 | Loss 1.3649 | Time 10.47s | LR 0.000278\n","Epoch 216 | Accuracy 0.6938 | Loss 1.3660 | Time 10.47s | LR 0.000278\n","Epoch 217 | Accuracy 0.6963 | Loss 1.3592 | Time 10.47s | LR 0.000277\n","Epoch 218 | Accuracy 0.6956 | Loss 1.3538 | Time 10.48s | LR 0.000276\n","Epoch 219 | Accuracy 0.6968 | Loss 1.3563 | Time 10.47s | LR 0.000276\n","Epoch 220 | Accuracy 0.6968 | Loss 1.3523 | Time 10.47s | LR 0.000275\n","Epoch 221 | Accuracy 0.6978 | Loss 1.3472 | Time 10.47s | LR 0.000274\n","Epoch 222 | Accuracy 0.6970 | Loss 1.3463 | Time 10.48s | LR 0.000274\n","Epoch 223 | Accuracy 0.6989 | Loss 1.3423 | Time 10.48s | LR 0.000273\n","Epoch 224 | Accuracy 0.6994 | Loss 1.3353 | Time 10.47s | LR 0.000273\n","Epoch 225 | Accuracy 0.6996 | Loss 1.3349 | Time 10.47s | LR 0.000272\n","Epoch 226 | Accuracy 0.6995 | Loss 1.3350 | Time 10.47s | LR 0.000271\n","Epoch 227 | Accuracy 0.7003 | Loss 1.3320 | Time 10.47s | LR 0.000271\n","Epoch 228 | Accuracy 0.6991 | Loss 1.3298 | Time 10.47s | LR 0.000270\n","Epoch 229 | Accuracy 0.7018 | Loss 1.3245 | Time 10.48s | LR 0.000270\n","Epoch 230 | Accuracy 0.7019 | Loss 1.3220 | Time 10.47s | LR 0.000269\n","Epoch 231 | Accuracy 0.7026 | Loss 1.3230 | Time 10.47s | LR 0.000268\n","Epoch 232 | Accuracy 0.7041 | Loss 1.3107 | Time 10.47s | LR 0.000268\n","Epoch 233 | Accuracy 0.7050 | Loss 1.3066 | Time 10.48s | LR 0.000267\n","Epoch 234 | Accuracy 0.7054 | Loss 1.3051 | Time 10.47s | LR 0.000267\n","Epoch 235 | Accuracy 0.7051 | Loss 1.3065 | Time 10.47s | LR 0.000266\n","Epoch 236 | Accuracy 0.7062 | Loss 1.3026 | Time 10.47s | LR 0.000266\n","Epoch 237 | Accuracy 0.7056 | Loss 1.3022 | Time 10.48s | LR 0.000265\n","Epoch 238 | Accuracy 0.7066 | Loss 1.2988 | Time 10.48s | LR 0.000264\n","Epoch 239 | Accuracy 0.7050 | Loss 1.3023 | Time 10.48s | LR 0.000264\n","Epoch 240 | Accuracy 0.7079 | Loss 1.2903 | Time 10.48s | LR 0.000263\n","Epoch 241 | Accuracy 0.7080 | Loss 1.2897 | Time 10.48s | LR 0.000263\n","Epoch 242 | Accuracy 0.7088 | Loss 1.2858 | Time 10.47s | LR 0.000262\n","Epoch 243 | Accuracy 0.7092 | Loss 1.2858 | Time 10.47s | LR 0.000262\n","Epoch 244 | Accuracy 0.7088 | Loss 1.2792 | Time 10.47s | LR 0.000261\n","Epoch 245 | Accuracy 0.7098 | Loss 1.2789 | Time 10.47s | LR 0.000261\n","Epoch 246 | Accuracy 0.7098 | Loss 1.2784 | Time 10.48s | LR 0.000260\n","Epoch 247 | Accuracy 0.7107 | Loss 1.2765 | Time 10.48s | LR 0.000260\n","Epoch 248 | Accuracy 0.7108 | Loss 1.2764 | Time 10.48s | LR 0.000259\n","Epoch 249 | Accuracy 0.7114 | Loss 1.2744 | Time 10.48s | LR 0.000259\n","Epoch 250 | Accuracy 0.7118 | Loss 1.2722 | Time 10.47s | LR 0.000258\n","Epoch 251 | Accuracy 0.7115 | Loss 1.2722 | Time 10.47s | LR 0.000257\n","Epoch 252 | Accuracy 0.7122 | Loss 1.2672 | Time 10.48s | LR 0.000257\n","Epoch 253 | Accuracy 0.7140 | Loss 1.2597 | Time 10.47s | LR 0.000256\n","Epoch 254 | Accuracy 0.7131 | Loss 1.2593 | Time 10.48s | LR 0.000256\n","Epoch 255 | Accuracy 0.7129 | Loss 1.2590 | Time 10.48s | LR 0.000255\n","Epoch 256 | Accuracy 0.7146 | Loss 1.2534 | Time 10.48s | LR 0.000255\n","Epoch 257 | Accuracy 0.7155 | Loss 1.2497 | Time 10.47s | LR 0.000254\n","Epoch 258 | Accuracy 0.7141 | Loss 1.2533 | Time 10.48s | LR 0.000254\n","Epoch 259 | Accuracy 0.7159 | Loss 1.2499 | Time 10.48s | LR 0.000253\n","Epoch 260 | Accuracy 0.7157 | Loss 1.2469 | Time 10.47s | LR 0.000253\n","Epoch 261 | Accuracy 0.7163 | Loss 1.2415 | Time 10.47s | LR 0.000252\n","Epoch 262 | Accuracy 0.7163 | Loss 1.2447 | Time 10.47s | LR 0.000252\n","Epoch 263 | Accuracy 0.7181 | Loss 1.2371 | Time 10.48s | LR 0.000252\n","Epoch 264 | Accuracy 0.7188 | Loss 1.2356 | Time 10.47s | LR 0.000251\n","Epoch 265 | Accuracy 0.7190 | Loss 1.2321 | Time 10.47s | LR 0.000251\n","Epoch 266 | Accuracy 0.7187 | Loss 1.2332 | Time 10.47s | LR 0.000250\n","Epoch 267 | Accuracy 0.7196 | Loss 1.2284 | Time 10.47s | LR 0.000250\n","Epoch 268 | Accuracy 0.7203 | Loss 1.2222 | Time 10.48s | LR 0.000249\n","Epoch 269 | Accuracy 0.7203 | Loss 1.2240 | Time 10.47s | LR 0.000249\n","Epoch 270 | Accuracy 0.7208 | Loss 1.2230 | Time 10.48s | LR 0.000248\n","Epoch 271 | Accuracy 0.7201 | Loss 1.2221 | Time 10.48s | LR 0.000248\n","Epoch 272 | Accuracy 0.7219 | Loss 1.2212 | Time 10.48s | LR 0.000247\n","Epoch 273 | Accuracy 0.7217 | Loss 1.2182 | Time 10.47s | LR 0.000247\n","Epoch 274 | Accuracy 0.7220 | Loss 1.2140 | Time 10.47s | LR 0.000246\n","Epoch 275 | Accuracy 0.7210 | Loss 1.2179 | Time 10.48s | LR 0.000246\n","Epoch 276 | Accuracy 0.7220 | Loss 1.2118 | Time 10.48s | LR 0.000246\n","Epoch 277 | Accuracy 0.7224 | Loss 1.2082 | Time 10.48s | LR 0.000245\n","Epoch 278 | Accuracy 0.7231 | Loss 1.2062 | Time 10.48s | LR 0.000245\n","Epoch 279 | Accuracy 0.7254 | Loss 1.2014 | Time 10.48s | LR 0.000244\n","Epoch 280 | Accuracy 0.7243 | Loss 1.2024 | Time 10.48s | LR 0.000244\n","Epoch 281 | Accuracy 0.7248 | Loss 1.1992 | Time 10.54s | LR 0.000243\n","Epoch 282 | Accuracy 0.7251 | Loss 1.1990 | Time 10.49s | LR 0.000243\n","Epoch 283 | Accuracy 0.7255 | Loss 1.1992 | Time 10.49s | LR 0.000242\n","Epoch 284 | Accuracy 0.7255 | Loss 1.1997 | Time 10.48s | LR 0.000242\n","Epoch 285 | Accuracy 0.7267 | Loss 1.1903 | Time 10.49s | LR 0.000242\n","Epoch 286 | Accuracy 0.7264 | Loss 1.1924 | Time 10.49s | LR 0.000241\n","Epoch 287 | Accuracy 0.7282 | Loss 1.1870 | Time 10.49s | LR 0.000241\n","Epoch 288 | Accuracy 0.7278 | Loss 1.1847 | Time 10.49s | LR 0.000240\n","Epoch 289 | Accuracy 0.7261 | Loss 1.1873 | Time 10.49s | LR 0.000240\n","Epoch 290 | Accuracy 0.7293 | Loss 1.1807 | Time 10.48s | LR 0.000240\n","Epoch 291 | Accuracy 0.7283 | Loss 1.1857 | Time 10.49s | LR 0.000239\n","Epoch 292 | Accuracy 0.7304 | Loss 1.1758 | Time 10.49s | LR 0.000239\n","Epoch 293 | Accuracy 0.7292 | Loss 1.1780 | Time 10.48s | LR 0.000238\n","Epoch 294 | Accuracy 0.7288 | Loss 1.1761 | Time 10.49s | LR 0.000238\n","Epoch 295 | Accuracy 0.7313 | Loss 1.1722 | Time 10.48s | LR 0.000238\n","Epoch 296 | Accuracy 0.7308 | Loss 1.1718 | Time 10.48s | LR 0.000237\n","Epoch 297 | Accuracy 0.7315 | Loss 1.1651 | Time 10.48s | LR 0.000237\n","Epoch 298 | Accuracy 0.7311 | Loss 1.1689 | Time 10.48s | LR 0.000236\n","Epoch 299 | Accuracy 0.7314 | Loss 1.1661 | Time 10.48s | LR 0.000236\n","Epoch 300 | Accuracy 0.7321 | Loss 1.1614 | Time 10.48s | LR 0.000236\n"]}],"source":["patience = 5 \n","best_loss = float('inf')\n","wait = 0\n","total_batches = tf.data.experimental.cardinality(dataset).numpy()\n","epochs = 300\n","\n","\n","for epoch in range(first_epoch, first_epoch + epochs):\n","    start = time.time()\n","    start_epoch = time.time()\n","    train_loss.reset_state()\n","    train_accuracy.reset_state()\n","\n","\n","    for (batch, (inp, tar)) in enumerate(dataset):\n","        start_batch = time.time()\n","        train_step(inp, tar)\n","        \n","        if (batch + 1) % 100 == 0 or (batch + 1) == total_batches:\n","            elapsed_batch = time.time() - start_epoch\n","            #print(f\"Epoch {epoch+1} Batch {batch+1}/{total_batches} \"\n","            #      f\"Accuracy {train_accuracy.result():.4f} \"\n","            #      f\"Loss {train_loss.result():.4f} \"\n","            #      f\"Time elapsed {elapsed_batch:.2f}s\")\n","\n","    current_loss = train_loss.result()\n","    \n","    if current_loss < best_loss:\n","        best_loss = current_loss\n","        wait = 0\n","        #ckpt_save_path = ckpt_manager.save()\n","    else:\n","        wait += 1\n","        if wait >= patience:\n","            print(f\"Early stopping triggered at epoch {epoch+1}\")\n","            break\n","    \n","    current_lr = learning_rate(optimizer.iterations).numpy()\n","    print(f'Epoch {epoch+1:03d} | Accuracy {train_accuracy.result():.4f} | '\n","      f'Loss {current_loss:.4f} | Time {time.time() - start:.2f}s | LR {current_lr:.6f}')\n"]},{"cell_type":"code","execution_count":15,"id":"b2b733e8","metadata":{"execution":{"iopub.execute_input":"2025-12-10T12:02:53.982048Z","iopub.status.busy":"2025-12-10T12:02:53.981795Z","iopub.status.idle":"2025-12-10T12:02:53.989962Z","shell.execute_reply":"2025-12-10T12:02:53.989418Z"},"papermill":{"duration":0.026309,"end_time":"2025-12-10T12:02:53.990957","exception":false,"start_time":"2025-12-10T12:02:53.964648","status":"completed"},"tags":[]},"outputs":[],"source":["def summarize(input_article, beam_width=3):\n","    # input_article = text_tokenizer.encode_as_ids(input_article)\n","    input_article = tokenizer.encode_as_ids(input_article)\n","    input_article = tf.keras.preprocessing.sequence.pad_sequences([input_article], maxlen=max_text_len, padding='post', truncating='post')\n","    encoder_input = tf.expand_dims(input_article[0], 0)\n","\n","    # sos_id = summary_tokenizer.token_to_id('<SOS>')\n","    # eos_id = summary_tokenizer.token_to_id('<EOS>')\n","    sos_id = tokenizer.token_to_id('<SOS>')\n","    eos_id = tokenizer.token_to_id('<EOS>')\n","\n","    sequences = [([sos_id], 0.0)]\n","    completed_sequences = []\n","\n","    for _ in range(max_summary_len):\n","        all_candidates = []\n","        for seq, score in sequences:\n","            if seq[-1] == eos_id:\n","                completed_sequences.append((seq, score))\n","                continue\n","\n","            output = tf.expand_dims(seq, 0)\n","            enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n","\n","            predictions, _ = transformer(\n","                encoder_input, \n","                output,\n","                training=False,\n","                enc_padding_mask=enc_padding_mask,\n","                look_ahead_mask=combined_mask,\n","                dec_padding_mask=dec_padding_mask \n","            )\n","\n","            logits = predictions[:, -1, :]\n","            log_probs = tf.nn.log_softmax(logits)\n","            top_k = tf.math.top_k(log_probs, k=beam_width)\n","\n","            for i in range(beam_width):\n","                token = int(top_k.indices[0, i])\n","                candidate_score = score + float(top_k.values[0, i])\n","                candidate_seq = seq + [token]\n","                \n","                length_penalty = ((5 + len(candidate_seq)) / 6) ** 0.6\n","                normalized_score = candidate_score / length_penalty\n","\n","                \n","                all_candidates.append((candidate_seq, normalized_score))\n","\n","        sequences = sorted(all_candidates, key=lambda tup: tup[1], reverse=True)[:beam_width]\n","\n","        if not sequences:\n","            break\n","\n","    completed_sequences.extend(sequences)\n","    best_seq = max(completed_sequences, key=lambda tup: tup[1])[0]\n","\n","    # decoded = summary_tokenizer.decode_ids(best_seq)\n","    decoded = tokenizer.decode_ids(best_seq)\n","    decoded = decoded.replace(\"<SOS>\", \"\").replace(\"<EOS>\", \"\").strip()\n","    decoded = decoded.replace(\"&#39;\", \"'\").replace(\"&amp;\", \"&\")\n","    \n","    return decoded\n"]},{"cell_type":"code","execution_count":16,"id":"2aac685a","metadata":{"execution":{"iopub.execute_input":"2025-12-10T12:02:54.024437Z","iopub.status.busy":"2025-12-10T12:02:54.024234Z","iopub.status.idle":"2025-12-10T12:03:44.427765Z","shell.execute_reply":"2025-12-10T12:03:44.427067Z"},"papermill":{"duration":50.421758,"end_time":"2025-12-10T12:03:44.42907","exception":false,"start_time":"2025-12-10T12:02:54.007312","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Text : Gangster-turned-politician Mukhtar Ansari has won from the Mau constituency in Uttar Pradesh after polling 96,793 votes, defeating the nearest candidate by over 8,000 votes. Ansari, who was the sitting MLA from the constituency, had allied with the Mayawati-led Bahujan Samaj Party before the elections. Ansari has been accused of murdering a BJP MLA. \n","Real Headline : Gangster-turned-politician Mukhtar Ansari wins by 8000 votes \n","Summary (transformer) : BJP MP ends hunger strike over dam construction\n","\n","Text : Indira Gandhi has been the only woman till date to have presented the Union Budget of India in 1970-71. This came after Indira Gandhi, the then Prime Minister, took over the Finance portfolio after Morarji Desai resigned as the Minister of Finance. So far, she has been the only woman Finance Minister of India. \n","Real Headline : Indira Gandhi only woman to have presented the budget \n","Summary (transformer) : NBC comedy writer suspended for mocking Trump ' s\n","\n","Text : Actor Adam Sandler brought his 23-year-old doppelg nger Max Kessler for the premiere of his upcoming film ' The Do-Over ' . Sandler noticed Max after the 23-year-old posted a picture of himself alongside Sandler on Reddit. It was captioned, \" The name of Adam Sandler ' s character in... ' The Do-Over ' is Max Kessler. My name is Max Kessler... and I look just like him. \" \n","Real Headline : Sandler brings doppelg nger to film premiere \n","Summary (transformer) : Kangana Ranaut features on October cover of ' Harper '\n","\n","Text : The Supreme Court recently reminded the Centre that Aadhaar cannot be made mandatory for any services. The apex court also ordered the Centre to remove its condition of making Aadhaar mandatory in scholarship schemes for students. \" The Aadhaar card Scheme is purely voluntary and cannot be made mandatory till the matter is finally decided by this Court, \" the SC added. \n","Real Headline : Aadhaar cannot be mandatory, SC reminds govt \n","Summary (transformer) : India ' s largest nuclear weapons as Aleppo nuclear bombs\n","\n","Text : Researchers at the University of Stuttgart have built wall-climbing mini robots that work together to create architecture from carbon fibre. The robots carry carbon fibre thread spools that they pass back and forth after affixing to points on a wall. The researchers are planning to increase the number of robots, allowing them to attach fibre to ceilings and curved walls. \n","Real Headline : Robots create architecture with carbon fibre \n","Summary (transformer) : Shirt changes colour on detecting air pollution\n","\n","Text : Actress-filmmaker Pooja Bhatt while sharing her opinion on Karan Johar ' s row over Ae Dil Hai Mushkil with MNS chief Raj Thackeray called it \" bullying \" and not \" nationalism \" . \" It is schoolyard bullying at its best and worst, \" tweeted Bhatt. She was responding to a tweet by journalist Barkha Dutt, which read, \" Nationalism or Blackmail? karanjohar bullied, Raj Thackeray emboldened. \" \n","Real Headline : Not nationalism, it ' s bullying Pooja on Johar, MNS row \n","Summary (transformer) : JRR Tony Films to be a music\n","\n","Text : Thousands of migrants were evacuated after a fire destroyed tents and makeshift shelters during violence among residents in Greece ' s reportedly biggest migrant camp, on the island of Lesbos, officials said. No one was injured, but the fire destroyed about 60 of the camp ' Moria ' , officials added. Reports suggest clashes erupted following rumours of mass deportations of migrants to Turkey. \n","Real Headline : Migrants evacuated after fire at Greece ' s biggest camp \n","Summary (transformer) : Thailand requests extradition of royal insult suspects\n","\n","Text : The world ' s best-performing initial public offering (IPO) by the Hong Kong-based Luen Wong Group Holdings Limited is currently trading 6,715 above its offer price. The civil engineering company ' s stocks had jumped over 1,400 on the first trading day after its April IPO. Luen Wong had reported sales worth 41 million last year and is currently valued at 2.9 billion. \n","Real Headline : World ' s best-performing IPO this year has gained over 6,000 \n","Summary (transformer) : World ' s largest invests in chief Crysments was\n","\n","Text : An earthquake of magnitude 7.0 shook El Salvador and Nicaragua on Thursday, an hour after a hurricane struck the Caribbean coasts of Nicaragua and Costa Rica. There were no immediate reports of damage following the earthquake, which occurred around 120 kilometres off the El Salvador coast. A tsunami warning was issued in Nicaragua and El Salvador, but later withdrawn. \n","Real Headline : El Salvador struck by 7.0 magnitude earthquake \n","Summary (transformer) : There is pain in the heart of Kashmir Mehbooba\n","\n","Text : Kargil martyr ' s daughter Gurmehar Kaur ' s picture from an old campaign holding placard \" Pakistan did not kill my dad, war killed him \" is being trolled by Twitter users. While one user tweeted Dawood Ibrahim ' s picture that read, \" I didn ' t kill people in 1993, bombs killed them \" , another posted Rahul Gandhi ' s photo stating, \" I did not destroy Congress, my speeches did \" . \n","Real Headline : Twitter trolls Kargil martyr ' s daughter for old campaign pic \n","Summary (transformer) : Twitter reacts to Sangakkara ' s all-time XI\n"]}],"source":["for i in range(10):\n","    text = df['text'][i]\n","    real_summary = df['summary'][i]\n","    print(f\"\\nText : {text} \\nReal Headline : {real_summary} \\nSummary (transformer) : {summarize(text)}\")"]},{"cell_type":"code","execution_count":17,"id":"addedb82","metadata":{"execution":{"iopub.execute_input":"2025-12-10T12:03:44.464955Z","iopub.status.busy":"2025-12-10T12:03:44.46471Z","iopub.status.idle":"2025-12-10T12:04:19.068712Z","shell.execute_reply":"2025-12-10T12:04:19.067949Z"},"papermill":{"duration":34.639736,"end_time":"2025-12-10T12:04:19.086868","exception":false,"start_time":"2025-12-10T12:03:44.447132","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Text : Apple Inc. announced a new campus in Austin, Texas, expected to create over 5,000 jobs by 2026, focusing on hardware R&D. CEO Tim Cook emphasized innovation and community commitment. \n","Summary (transformer) : Startup makes smart belt that tracks fitness\n","\n","Text : The Prime Minister held a press conference on Tuesday, unveiling new economic reforms aimed at boosting small businesses and creating job opportunities across the country. \n","Summary (transformer) : Police probe in Saudi Arabia in Delhi Police Stations\n","\n","Text : In yesterday’s football match, Barcelona defeated Real Madrid 3-1, with Messi scoring a hat-trick. The victory gives Barcelona an edge in the league standings. \n","Summary (transformer) : Indian filmmaker to lead Montreal Pride Parade\n","\n","Text : A new study revealed that regular exercise and a balanced diet can significantly reduce the risk of heart disease and improve overall life expectancy. \n","Summary (transformer) : Police constables held for blackmailing cops\n","\n","Text : The latest Marvel movie broke box office records over the weekend, earning over $200 million globally in its opening weekend. \n","Summary (transformer) : Facebook apologises for inverted Philippine flag\n","\n","Text : Scientists discovered a new species of dolphin in the Pacific Ocean, highlighting the importance of marine conservation and biodiversity protection. \n","Summary (transformer) : New Angola law to regulate press, social media\n","\n","Text : The stock market saw a sharp increase today, with tech stocks leading the gains as investors responded positively to quarterly earnings reports. \n","Summary (transformer) : Apple posts highest ever quarterly profit-200,000 due to\n"]}],"source":["texts = [\n","    \"Apple Inc. announced a new campus in Austin, Texas, expected to create over 5,000 jobs by 2026, focusing on hardware R&D. CEO Tim Cook emphasized innovation and community commitment.\",\n","    \n","    \"The Prime Minister held a press conference on Tuesday, unveiling new economic reforms aimed at boosting small businesses and creating job opportunities across the country.\",\n","\n","    \"In yesterday’s football match, Barcelona defeated Real Madrid 3-1, with Messi scoring a hat-trick. The victory gives Barcelona an edge in the league standings.\",\n","    \n","    \"A new study revealed that regular exercise and a balanced diet can significantly reduce the risk of heart disease and improve overall life expectancy.\",\n","    \n","    \"The latest Marvel movie broke box office records over the weekend, earning over $200 million globally in its opening weekend.\",\n","    \n","    \"Scientists discovered a new species of dolphin in the Pacific Ocean, highlighting the importance of marine conservation and biodiversity protection.\",\n","    \n","    \"The stock market saw a sharp increase today, with tech stocks leading the gains as investors responded positively to quarterly earnings reports.\"\n","]\n","\n","for text in texts:\n","    print(f\"\\nText : {text} \\nSummary (transformer) : {summarize(text)}\")"]},{"cell_type":"code","execution_count":18,"id":"9c5a8100","metadata":{"execution":{"iopub.execute_input":"2025-12-10T12:04:19.122364Z","iopub.status.busy":"2025-12-10T12:04:19.122142Z","iopub.status.idle":"2025-12-10T12:04:19.274167Z","shell.execute_reply":"2025-12-10T12:04:19.273463Z"},"papermill":{"duration":0.17142,"end_time":"2025-12-10T12:04:19.275302","exception":false,"start_time":"2025-12-10T12:04:19.103882","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Nessun carattere non ASCII trovato nella colonna 'text'\n","Nessun carattere non ASCII trovato nella colonna 'summary'\n"]}],"source":["import pandas as pd\n","\n","columns_to_check = ['text', 'summary']\n","\n","def find_non_ascii_chars(text):\n","    if not isinstance(text, str):\n","        return set()\n","    return set(c for c in text if ord(c) > 127)\n","\n","unicode_chars_found = {col: set() for col in columns_to_check}\n","\n","for col in columns_to_check:\n","    for val in df[col]:\n","        unicode_chars_found[col].update(find_non_ascii_chars(val))\n","\n","for col, chars in unicode_chars_found.items():\n","    if chars:\n","        print(f\"Caratteri non ASCII trovati nella colonna '{col}': {chars}\")\n","    else:\n","        print(f\"Nessun carattere non ASCII trovato nella colonna '{col}'\")\n"]},{"cell_type":"markdown","id":"f6a9e24a","metadata":{"papermill":{"duration":0.016994,"end_time":"2025-12-10T12:04:19.30951","exception":false,"start_time":"2025-12-10T12:04:19.292516","status":"completed"},"tags":[]},"source":["# Credits\n","\n","- **\"Implementing Seq2Seq Models for Text Summarization With Keras\"**  \n","  *by Samhita Alla* "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":33526,"isSourceIdPinned":false,"sourceId":44284,"sourceType":"datasetVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":3900.597431,"end_time":"2025-12-10T12:04:22.71266","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-10T10:59:22.115229","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}